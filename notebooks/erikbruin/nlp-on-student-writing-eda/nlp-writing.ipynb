{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b4a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SNAPPY_notebook_path = os.path.join(os.path.abspath(\"\"), \"nlp-writing.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7757e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snappy_jupyter.snappy_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5be5fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "SNAPPY_start_time = time.perf_counter_ns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba289cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.2 µs (started: 2024-05-27 21:15:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a4a62",
   "metadata": {
    "papermill": {
     "duration": 0.043611,
     "end_time": "2022-02-06T13:43:52.364884",
     "exception": false,
     "start_time": "2022-02-06T13:43:52.321273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feedback Prize - Evaluating Student Writing\n",
    "\n",
    "Georgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor’s degrees to African-Americans than any other non-profit college or university in the country. GSU and The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.\n",
    "\n",
    "In this competition, you’ll identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. You'll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing, a fast-growing area of data science.\n",
    "\n",
    "If successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94c71aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:00.763753Z",
     "iopub.status.busy": "2024-04-14T18:44:00.763458Z",
     "iopub.status.idle": "2024-04-14T18:44:01.795399Z",
     "shell.execute_reply": "2024-04-14T18:44:01.795015Z",
     "shell.execute_reply.started": "2024-04-14T18:44:00.763724Z"
    },
    "papermill": {
     "duration": 12.632175,
     "end_time": "2022-02-06T13:44:05.039722",
     "exception": false,
     "start_time": "2022-02-06T13:43:52.407547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 343 ms (started: 2024-05-27 21:15:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# STEFANOS: Conditionally import Modin Pandas\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# import matplotlib.pyplot as plt\n",
    "# # STEFANOS: Disable, can't be parsed. Doesn't change the behavior especially since we've disabled plotting.\n",
    "# # %matplotlib inline\n",
    "# import matplotlib.style as style\n",
    "# style.use('fivethirtyeight')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# STEFANOS: Remove unneeded imports.\n",
    "# import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d56d28ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 467 µs (started: 2024-05-27 21:15:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def hash_anything(obj):\n",
    "    import pandas.util\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        return pandas.util.hash_pandas_object(obj, index=False).to_numpy().data\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.data\n",
    "    elif isinstance(obj, list):\n",
    "        return str(obj).encode()\n",
    "    else:\n",
    "        return str(obj).encode()\n",
    "\n",
    "\n",
    "def hash_dataframe(df):\n",
    "    import xxhash\n",
    "    h = xxhash.xxh64()\n",
    "    for column in df.round(6).columns:\n",
    "        h.update(hash_anything(df[column]))\n",
    "    return h.digest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6eea96",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:01.796331Z",
     "iopub.status.busy": "2024-04-14T18:44:01.796143Z",
     "iopub.status.idle": "2024-04-14T18:44:02.461260Z",
     "shell.execute_reply": "2024-04-14T18:44:02.460857Z",
     "shell.execute_reply.started": "2024-04-14T18:44:01.796319Z"
    },
    "papermill": {
     "duration": 2.786403,
     "end_time": "2022-02-06T13:44:07.86746",
     "exception": false,
     "start_time": "2022-02-06T13:44:05.081057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 423 ms (started: 2024-05-27 21:15:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.abspath('') + '/input/feedback-prize-2021/train.csv')\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    train = train[:5000]\n",
    "\n",
    "train[['discourse_id', 'discourse_start', 'discourse_end']] = train[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n",
    "\n",
    "sample_submission = pd.read_csv(os.path.abspath('') +'/input/feedback-prize-2021/sample_submission.csv')\n",
    "\n",
    "#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "train_txt = glob(os.path.abspath('') +'/input/feedback-prize-2021/train/*.txt')\n",
    "test_txt = glob(os.path.abspath('') +'/input/feedback-prize-2021/test/*.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ac159",
   "metadata": {
    "papermill": {
     "duration": 0.04211,
     "end_time": "2022-02-06T13:44:07.953245",
     "exception": false,
     "start_time": "2022-02-06T13:44:07.911135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction to the competition\n",
    "\n",
    "Basically, we have a bunch of essays written by kids in the age range of about 12-18 years old in which we have to find word sequences that can be classified as one of 7 \"discourse types\". These are:\n",
    "\n",
    "- Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader’s attention and point toward the thesis\n",
    "- Position - an opinion or conclusion on the main question\n",
    "- Claim - a claim that supports the position\n",
    "- Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n",
    "- Rebuttal - a claim that refutes a counterclaim\n",
    "- Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n",
    "- Concluding Statement - a concluding statement that restates the claims\n",
    "\n",
    "Let's look at the full text of one essay first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23bdc86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.462846Z",
     "iopub.status.busy": "2024-04-14T18:44:02.462720Z",
     "iopub.status.idle": "2024-04-14T18:44:02.464676Z",
     "shell.execute_reply": "2024-04-14T18:44:02.464396Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.462834Z"
    },
    "papermill": {
     "duration": 0.837797,
     "end_time": "2022-02-06T13:44:08.832796",
     "exception": false,
     "start_time": "2022-02-06T13:44:07.994999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 157 µs (started: 2024-05-27 21:15:46 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# Disable shell code.\n",
    "# !cat input/feedback-prize-2021/train/423A1CA112E2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b1915",
   "metadata": {
    "papermill": {
     "duration": 0.041503,
     "end_time": "2022-02-06T13:44:08.916502",
     "exception": false,
     "start_time": "2022-02-06T13:44:08.874999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The train dataset gives us the following human annotations that are extracted from this essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cfe1b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.465222Z",
     "iopub.status.busy": "2024-04-14T18:44:02.465131Z",
     "iopub.status.idle": "2024-04-14T18:44:02.476887Z",
     "shell.execute_reply": "2024-04-14T18:44:02.476603Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.465211Z"
    },
    "papermill": {
     "duration": 0.092419,
     "end_time": "2022-02-06T13:44:09.052641",
     "exception": false,
     "start_time": "2022-02-06T13:44:08.960222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627696365</td>\n",
       "      <td>402</td>\n",
       "      <td>758</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627759780</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627780655</td>\n",
       "      <td>887</td>\n",
       "      <td>1150</td>\n",
       "      <td>That's why there's a thing that's called no te...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>163 164 165 166 167 168 169 170 171 172 173 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627811787</td>\n",
       "      <td>1151</td>\n",
       "      <td>1533</td>\n",
       "      <td>Sometimes on the news there is either an accid...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>211 212 213 214 215 216 217 218 219 220 221 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627585180</td>\n",
       "      <td>1534</td>\n",
       "      <td>1602</td>\n",
       "      <td>Phones are fine to use and it's also the best ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>282 283 284 285 286 287 288 289 290 291 292 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627895668</td>\n",
       "      <td>1603</td>\n",
       "      <td>1890</td>\n",
       "      <td>If you go through a problem and you can't find...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 5</td>\n",
       "      <td>297 298 299 300 301 302 303 304 305 306 307 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627628524</td>\n",
       "      <td>1891</td>\n",
       "      <td>2027</td>\n",
       "      <td>The news always updated when people do somethi...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>355 356 357 358 359 360 361 362 363 364 365 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id   discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1622627660524                8            229   \n",
       "1  423A1CA112E2  1622627653021              230            312   \n",
       "2  423A1CA112E2  1622627671020              313            401   \n",
       "3  423A1CA112E2  1622627696365              402            758   \n",
       "4  423A1CA112E2  1622627759780              759            886   \n",
       "5  423A1CA112E2  1622627780655              887           1150   \n",
       "6  423A1CA112E2  1622627811787             1151           1533   \n",
       "7  423A1CA112E2  1622627585180             1534           1602   \n",
       "8  423A1CA112E2  1622627895668             1603           1890   \n",
       "9  423A1CA112E2  1622627628524             1891           2027   \n",
       "\n",
       "                                      discourse_text        discourse_type  \\\n",
       "0  Modern humans today are always on their phone....                  Lead   \n",
       "1  They are some really bad consequences when stu...              Position   \n",
       "2  Some certain areas in the United States ban ph...              Evidence   \n",
       "3  When people have phones, they know about certa...              Evidence   \n",
       "4  Driving is one of the way how to get around. P...                 Claim   \n",
       "5  That's why there's a thing that's called no te...              Evidence   \n",
       "6  Sometimes on the news there is either an accid...              Evidence   \n",
       "7  Phones are fine to use and it's also the best ...                 Claim   \n",
       "8  If you go through a problem and you can't find...              Evidence   \n",
       "9  The news always updated when people do somethi...  Concluding Statement   \n",
       "\n",
       "       discourse_type_num                                   predictionstring  \n",
       "0                  Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1              Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2              Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3              Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4                 Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "5              Evidence 3  163 164 165 166 167 168 169 170 171 172 173 17...  \n",
       "6              Evidence 4  211 212 213 214 215 216 217 218 219 220 221 22...  \n",
       "7                 Claim 2  282 283 284 285 286 287 288 289 290 291 292 29...  \n",
       "8              Evidence 5  297 298 299 300 301 302 303 304 305 306 307 30...  \n",
       "9  Concluding Statement 1  355 356 357 358 359 360 361 362 363 364 365 36...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.5 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train.query('id == \"423A1CA112E2\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd5000",
   "metadata": {
    "papermill": {
     "duration": 0.042381,
     "end_time": "2022-02-06T13:44:09.137617",
     "exception": false,
     "start_time": "2022-02-06T13:44:09.095236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Kaggle gives us the following field descriptions:\n",
    "- id - ID code for essay response\n",
    "- discourse_id - ID code for discourse element\n",
    "- discourse_start - character position where discourse element begins in the essay response\n",
    "- discourse_end - character position where discourse element ends in the essay response\n",
    "- discourse_text - text of discourse element\n",
    "- discourse_type - classification of discourse element\n",
    "- discourse_type_num - enumerated class label of discourse element\n",
    "- predictionstring - the word indices of the training sample, as required for predictions\n",
    "\n",
    "The Ground Truth here is a combination of the discourse type and the prediction string. The predictionstring corresponds to the index of the words in the essay and the predicted discourse type for this sequence of words should be correct. There can be partial matches, if the correct discourse type is predicted but on a longer or shorter sequence of words than specified in the Ground Truth.\n",
    "\n",
    "As we can see, not necessarily all text of an essay is part of a discourse. In this case, the title is not part of any discourse.\n",
    "\n",
    "\n",
    "# Lenght of the discourse_text and predictionstring\n",
    "First, I would like to check if the discourse_text and the predictionstring always have the same number of words (as they should)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0fe5380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.477679Z",
     "iopub.status.busy": "2024-04-14T18:44:02.477532Z",
     "iopub.status.idle": "2024-04-14T18:44:02.875272Z",
     "shell.execute_reply": "2024-04-14T18:44:02.874973Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.477666Z"
    },
    "papermill": {
     "duration": 1.017913,
     "end_time": "2022-02-06T13:44:10.197435",
     "exception": false,
     "start_time": "2022-02-06T13:44:09.179522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_len</th>\n",
       "      <th>pred_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1622627660524</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1622627653021</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622627671020</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1622627696365</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1622627759780</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discourse_id                                     discourse_text  \\\n",
       "0  1622627660524  Modern humans today are always on their phone....   \n",
       "1  1622627653021  They are some really bad consequences when stu...   \n",
       "2  1622627671020  Some certain areas in the United States ban ph...   \n",
       "3  1622627696365  When people have phones, they know about certa...   \n",
       "4  1622627759780  Driving is one of the way how to get around. P...   \n",
       "\n",
       "  discourse_type                                   predictionstring  \\\n",
       "0           Lead  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...   \n",
       "1       Position       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59   \n",
       "2       Evidence    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75   \n",
       "3       Evidence  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...   \n",
       "4          Claim  139 140 141 142 143 144 145 146 147 148 149 15...   \n",
       "\n",
       "   discourse_len  pred_len  \n",
       "0             44        44  \n",
       "1             15        15  \n",
       "2             16        16  \n",
       "3             63        63  \n",
       "4             24        24  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 393 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "#add columns\n",
    "train[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))\n",
    "train[\"pred_len\"] = train[\"predictionstring\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "cols_to_display = ['discourse_id', 'discourse_text', 'discourse_type','predictionstring', 'discourse_len', 'pred_len']\n",
    "train[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55738663",
   "metadata": {
    "papermill": {
     "duration": 0.04285,
     "end_time": "2022-02-06T13:44:10.283414",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.240564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Is this always correct? No, I find 468 discourses where this goes wrong (by one word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e37ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.875901Z",
     "iopub.status.busy": "2024-04-14T18:44:02.875793Z",
     "iopub.status.idle": "2024-04-14T18:44:02.884004Z",
     "shell.execute_reply": "2024-04-14T18:44:02.883679Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.875890Z"
    },
    "papermill": {
     "duration": 0.068268,
     "end_time": "2022-02-06T13:44:10.394488",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.32622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of discourses is 144293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_len</th>\n",
       "      <th>pred_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1622473475289</td>\n",
       "      <td>if we would just make stricker laws for phone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>303 304 305 306 307 308 309 310 311 312 313 31...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1622564912260</td>\n",
       "      <td>for navigation to wherever they are going</td>\n",
       "      <td>Claim</td>\n",
       "      <td>105 106 107 108 109 110 111 112</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1622992466917</td>\n",
       "      <td>People should not be able to use cell phones w...</td>\n",
       "      <td>Position</td>\n",
       "      <td>22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1622992280991</td>\n",
       "      <td>First, cell phones are a benefit and allows ev...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1622992426147</td>\n",
       "      <td>Kids, teenagers, adults, even grandparents hav...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>90 91 92 93 94 95 96 97 98 99 100 101 102 103 ...</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142607</th>\n",
       "      <td>1617826841342</td>\n",
       "      <td>seeking people's opinions on making a choice i...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>563 564 565 566 567 568 569 570 571 572 573 57...</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143191</th>\n",
       "      <td>1617887956153</td>\n",
       "      <td>i feel like for the bst advice ask more then o...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>185 186 187 188 189 190 191 192 193 194 195 19...</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143227</th>\n",
       "      <td>1617652582742</td>\n",
       "      <td>, asking for advice from multiple people will ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>467 468 469 470 471 472 473 474 475 476 477 47...</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143311</th>\n",
       "      <td>1618286838241</td>\n",
       "      <td>Seeking multiple opinions can help make a bett...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>159 160 161 162 163 164 165 166 167 168 169 17...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143843</th>\n",
       "      <td>1617811065126</td>\n",
       "      <td>Asking for advice is a way of getting through ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         discourse_id                                     discourse_text  \\\n",
       "107     1622473475289  if we would just make stricker laws for phone ...   \n",
       "1025    1622564912260        for navigation to wherever they are going     \n",
       "1525    1622992466917  People should not be able to use cell phones w...   \n",
       "1526    1622992280991  First, cell phones are a benefit and allows ev...   \n",
       "1527    1622992426147  Kids, teenagers, adults, even grandparents hav...   \n",
       "...               ...                                                ...   \n",
       "142607  1617826841342  seeking people's opinions on making a choice i...   \n",
       "143191  1617887956153  i feel like for the bst advice ask more then o...   \n",
       "143227  1617652582742  , asking for advice from multiple people will ...   \n",
       "143311  1618286838241  Seeking multiple opinions can help make a bett...   \n",
       "143843  1617811065126  Asking for advice is a way of getting through ...   \n",
       "\n",
       "              discourse_type  \\\n",
       "107     Concluding Statement   \n",
       "1025                   Claim   \n",
       "1525                Position   \n",
       "1526                   Claim   \n",
       "1527                Evidence   \n",
       "...                      ...   \n",
       "142607  Concluding Statement   \n",
       "143191              Evidence   \n",
       "143227  Concluding Statement   \n",
       "143311                 Claim   \n",
       "143843                 Claim   \n",
       "\n",
       "                                         predictionstring  discourse_len  \\\n",
       "107     303 304 305 306 307 308 309 310 311 312 313 31...             19   \n",
       "1025                      105 106 107 108 109 110 111 112              7   \n",
       "1525    22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...             47   \n",
       "1526    69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...             21   \n",
       "1527    90 91 92 93 94 95 96 97 98 99 100 101 102 103 ...             78   \n",
       "...                                                   ...            ...   \n",
       "142607  563 564 565 566 567 568 569 570 571 572 573 57...             51   \n",
       "143191  185 186 187 188 189 190 191 192 193 194 195 19...             83   \n",
       "143227  467 468 469 470 471 472 473 474 475 476 477 47...             84   \n",
       "143311  159 160 161 162 163 164 165 166 167 168 169 17...             15   \n",
       "143843  3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...             21   \n",
       "\n",
       "        pred_len  \n",
       "107           18  \n",
       "1025           8  \n",
       "1525          48  \n",
       "1526          22  \n",
       "1527          79  \n",
       "...          ...  \n",
       "142607        50  \n",
       "143191        82  \n",
       "143227        83  \n",
       "143311        16  \n",
       "143843        22  \n",
       "\n",
       "[468 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.96 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of discourses is {len(train)}\")\n",
    "train.query('discourse_len != pred_len')[cols_to_display]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567059dc",
   "metadata": {
    "papermill": {
     "duration": 0.043749,
     "end_time": "2022-02-06T13:44:10.482174",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.438425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d44a30a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.885413Z",
     "iopub.status.busy": "2024-04-14T18:44:02.884834Z",
     "iopub.status.idle": "2024-04-14T18:44:02.893327Z",
     "shell.execute_reply": "2024-04-14T18:44:02.892889Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.885399Z"
    },
    "papermill": {
     "duration": 0.067548,
     "end_time": "2022-02-06T13:44:10.594895",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.527347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if we would just make stricker laws for phone an driving the people would stop because of the consequences.      \n",
      "['if', 'we', 'would', 'just', 'make', 'stricker', 'laws', 'for', 'phone', 'an', 'driving', 'the', 'people', 'would', 'stop', 'because', 'of', 'the', 'consequences.']\n",
      "19\n",
      "time: 3.56 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print(train.query('discourse_id == 1622473475289')['discourse_text'].values[0])\n",
    "print(train.query('discourse_id == 1622473475289')['discourse_text'].values[0].split())\n",
    "print(len(train.query('discourse_id == 1622473475289')['discourse_text'].values[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746e1062",
   "metadata": {
    "papermill": {
     "duration": 0.043589,
     "end_time": "2022-02-06T13:44:10.683438",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.639849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The length of 19 words seems correct to me, and the length of the predictionstring also really seems to be 18. Something to keep in mind.\n",
    "\n",
    "**Update:** the answers to this can be found in discussion topic: [Mystery Solved - Discrepancy Between PredictionString and DiscourseText](https://www.kaggle.com/c/feedback-prize-2021/discussion/297591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92b3a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.894186Z",
     "iopub.status.busy": "2024-04-14T18:44:02.894029Z",
     "iopub.status.idle": "2024-04-14T18:44:02.902373Z",
     "shell.execute_reply": "2024-04-14T18:44:02.901933Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.894171Z"
    },
    "papermill": {
     "duration": 0.071035,
     "end_time": "2022-02-06T13:44:10.798583",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.727548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320\n",
      "['303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320']\n",
      "18\n",
      "time: 3.35 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print(train.query('discourse_id == 1622473475289')['predictionstring'].values[0])\n",
    "print(train.query('discourse_id == 1622473475289')['predictionstring'].values[0].split())\n",
    "print(len(train.query('discourse_id == 1622473475289')['predictionstring'].values[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223f4b7",
   "metadata": {
    "papermill": {
     "duration": 0.044746,
     "end_time": "2022-02-06T13:44:10.888764",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.844018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Length and frequency and relative position per discourse_type\n",
    "\n",
    "Is there a correlation between the length of a discourse and the class (discourse_type)? Yes, there is. Evidence is the longest discount type on average. When looking at the frequencies of occurence, we see that Counterclaim and Rebuttal are relatively rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae939ad",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.903024Z",
     "iopub.status.busy": "2024-04-14T18:44:02.902901Z",
     "iopub.status.idle": "2024-04-14T18:44:02.919656Z",
     "shell.execute_reply": "2024-04-14T18:44:02.919203Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.903013Z"
    },
    "papermill": {
     "duration": 0.637721,
     "end_time": "2022-02-06T13:44:11.572582",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.934861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.2 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: Disable plotting\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# ax1 = fig.add_subplot(211)\n",
    "# ax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\")\n",
    "ax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values()\n",
    "# ax1.set_title(\"Average number of words versus Discourse Type\", fontsize=14, fontweight = 'bold')\n",
    "# ax1.set_xlabel(\"Average number of words\", fontsize = 10)\n",
    "# ax1.set_ylabel(\"\")\n",
    "\n",
    "# ax2 = fig.add_subplot(212)\n",
    "# ax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values().plot(kind=\"barh\")\n",
    "ax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values()\n",
    "# ax2.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\n",
    "# ax2.set_title(\"Frequency of Discourse Type in all essays\", fontsize=14, fontweight = 'bold')\n",
    "# ax2.set_xlabel(\"Frequency\", fontsize = 10)\n",
    "# ax2.set_ylabel(\"\")\n",
    "\n",
    "# plt.tight_layout(pad=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7cd50",
   "metadata": {
    "papermill": {
     "duration": 0.04586,
     "end_time": "2022-02-06T13:44:11.665568",
     "exception": false,
     "start_time": "2022-02-06T13:44:11.619708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We do have the field discourse_type_num. We see that Evidence1, Position1 and Claim1 are almost always there in an essay. Most students also had at least one Concluding Statement. What's surprising to me is that a Lead is missing in about 40% of the essays (Lead 1 is found in almost 60% of the essays).\n",
    "\n",
    "The graph only plots discourse_type_nums which are found in at least 3% of the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cca9a0be",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.920418Z",
     "iopub.status.busy": "2024-04-14T18:44:02.920241Z",
     "iopub.status.idle": "2024-04-14T18:44:02.934771Z",
     "shell.execute_reply": "2024-04-14T18:44:02.934423Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.920398Z"
    },
    "papermill": {
     "duration": 0.485511,
     "end_time": "2022-02-06T13:44:12.197026",
     "exception": false,
     "start_time": "2022-02-06T13:44:11.711515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.94 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: Disable plotting\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "# av_per_essay = train['discourse_type_num'].value_counts(ascending = True).rename_axis('discourse_type_num').reset_index(name='count')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "av_per_essay = train['discourse_type_num'].value_counts(ascending = True)\n",
    "av_per_essay.index.name = \"discourse_type_num\"\n",
    "av_per_essay = av_per_essay.reset_index(name='count')\n",
    "\n",
    "av_per_essay['perc'] = round((av_per_essay['count'] / train.id.nunique()),3)\n",
    "av_per_essay = av_per_essay.set_index('discourse_type_num')\n",
    "# ax = av_per_essay.query('perc > 0.03')['perc'].plot(kind=\"barh\")\n",
    "ax = av_per_essay.query('perc > 0.03')['perc']\n",
    "# ax.set_title(\"discourse_type_num: Percent present in essays\", fontsize=20, fontweight = 'bold')\n",
    "# ax.bar_label(ax.containers[0], label_type=\"edge\")\n",
    "# ax.set_xlabel(\"Percent\")\n",
    "# ax.set_ylabel(\"\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93059c2f",
   "metadata": {
    "papermill": {
     "duration": 0.049391,
     "end_time": "2022-02-06T13:44:12.295102",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.245711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below you can see a plot with the average positions of the discourse start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d1bf3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.935633Z",
     "iopub.status.busy": "2024-04-14T18:44:02.935435Z",
     "iopub.status.idle": "2024-04-14T18:44:02.944564Z",
     "shell.execute_reply": "2024-04-14T18:44:02.944246Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.935617Z"
    },
    "papermill": {
     "duration": 0.28928,
     "end_time": "2022-02-06T13:44:12.633078",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.343798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.57 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "data = train.groupby(\"discourse_type\")[['discourse_end', 'discourse_start']].mean().reset_index().sort_values(by = 'discourse_start', ascending = False)\n",
    "# data.plot(x='discourse_type',\n",
    "#         kind='barh',\n",
    "#         stacked=False,\n",
    "#         title='Average start and end position absolute',\n",
    "#         figsize=(12,4))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf6a614",
   "metadata": {
    "papermill": {
     "duration": 0.051099,
     "end_time": "2022-02-06T13:44:12.734248",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.683149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am also interested in the relative positions of discourse types with the essays. Below you can see the distributions of the discourse types of the first and last discourses identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c1d0dee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.948170Z",
     "iopub.status.busy": "2024-04-14T18:44:02.947984Z",
     "iopub.status.idle": "2024-04-14T18:44:02.974083Z",
     "shell.execute_reply": "2024-04-14T18:44:02.973733Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.948157Z"
    },
    "papermill": {
     "duration": 0.161208,
     "end_time": "2022-02-06T13:44:12.945746",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.784538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>counts_first</th>\n",
       "      <th>percent_first</th>\n",
       "      <th>counts_last</th>\n",
       "      <th>percent_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead</td>\n",
       "      <td>9298</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Position</td>\n",
       "      <td>5760</td>\n",
       "      <td>0.37</td>\n",
       "      <td>521</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evidence</td>\n",
       "      <td>261</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1609</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claim</td>\n",
       "      <td>255</td>\n",
       "      <td>0.02</td>\n",
       "      <td>285</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12993</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         discourse_type  counts_first  percent_first  counts_last  \\\n",
       "0                  Lead          9298           0.60            3   \n",
       "1              Position          5760           0.37          521   \n",
       "2              Evidence           261           0.02         1609   \n",
       "3                 Claim           255           0.02          285   \n",
       "4          Counterclaim            19           0.00           30   \n",
       "5  Concluding Statement             1           0.00        12993   \n",
       "\n",
       "   percent_last  \n",
       "0          0.00  \n",
       "1          0.03  \n",
       "2          0.10  \n",
       "3          0.02  \n",
       "4          0.00  \n",
       "5          0.83  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.9 ms (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "#train_first = train.drop_duplicates(subset = \"id\", keep = \"first\").discourse_type.value_counts().rename_axis('discourse_type').reset_index(name='counts_first')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "train_first = train.drop_duplicates(subset = \"id\", keep = \"first\").discourse_type.value_counts()\n",
    "train_first.index.name = 'discourse_type'\n",
    "train_first = train_first.reset_index(name='counts_first')\n",
    "\n",
    "train_first['percent_first'] = round((train_first['counts_first']/train.id.nunique()),2)\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "# train_last = train.drop_duplicates(subset = \"id\", keep = \"last\").discourse_type.value_counts().rename_axis('discourse_type').reset_index(name='counts_last')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "train_last = train.drop_duplicates(subset = \"id\", keep = \"last\").discourse_type.value_counts()\n",
    "train_last.index.name = 'discourse_type'\n",
    "train_last = train_last.reset_index(name='counts_last')\n",
    "\n",
    "\n",
    "train_last['percent_last'] = round((train_last['counts_last']/train.id.nunique()),2)\n",
    "train_first_last = train_first.merge(train_last, on = \"discourse_type\", how = \"left\")\n",
    "train_first_last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420dc0b2",
   "metadata": {
    "papermill": {
     "duration": 0.052158,
     "end_time": "2022-02-06T13:44:13.049027",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.996869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also know that a Lead is missing in around 40% of the essays. Below you can see that if there is a Lead, it's almost always the first discourse identified in an essay (Lead 2 is very rare anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "755a9357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:02.974781Z",
     "iopub.status.busy": "2024-04-14T18:44:02.974666Z",
     "iopub.status.idle": "2024-04-14T18:44:14.783881Z",
     "shell.execute_reply": "2024-04-14T18:44:14.783468Z",
     "shell.execute_reply.started": "2024-04-14T18:44:02.974769Z"
    },
    "papermill": {
     "duration": 102.669421,
     "end_time": "2022-02-06T13:45:55.770684",
     "exception": false,
     "start_time": "2022-02-06T13:44:13.101263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7fb647ab33a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.7 s (started: 2024-05-27 21:15:47 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train['discourse_nr'] = 1\n",
    "counter = 1\n",
    "\n",
    "for i in (range(1, len(train))):\n",
    "    if train.loc[i, 'id'] == train.loc[i-1, 'id']:\n",
    "        counter += 1\n",
    "        train.loc[i, 'discourse_nr'] = counter\n",
    "    else:\n",
    "        counter = 1\n",
    "        train.loc[i, 'discourse_nr'] = counter\n",
    "\n",
    "#if you are interested in other discourse_types you can add them to the list in df.query\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "# It seems you cannot call things on top of a groupby.\n",
    "### ORIGINAL\n",
    "# train.query('discourse_type in [\"Lead\"]').groupby('discourse_type_num')['discourse_nr'].value_counts().to_frame('occurences')\n",
    "### COMPATIBLE WITH MODIN:\n",
    "train.query('discourse_type in [\"Lead\"]').groupby('discourse_type_num')['discourse_nr']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76237b6",
   "metadata": {
    "papermill": {
     "duration": 0.052857,
     "end_time": "2022-02-06T13:45:55.87624",
     "exception": false,
     "start_time": "2022-02-06T13:45:55.823383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Investigation the gaps between Annotations (text not used as discourse_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae8347",
   "metadata": {
    "papermill": {
     "duration": 0.052078,
     "end_time": "2022-02-06T13:45:55.98035",
     "exception": false,
     "start_time": "2022-02-06T13:45:55.928272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just taking the last discourse_end in train is not entirely correct as a last piece of text may not have been used as a discourse. Therefore, I will go through the essays to find the real ends. Eh....until I remembered that Rob Mulla already did that in the excellent EDA [Student Writing Competition [Twitch Stream]](https://www.kaggle.com/robikscube/student-writing-competition-twitch) ;-). Please upvote his notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "449a3fbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:14.784891Z",
     "iopub.status.busy": "2024-04-14T18:44:14.784756Z",
     "iopub.status.idle": "2024-04-14T18:44:15.877461Z",
     "shell.execute_reply": "2024-04-14T18:44:15.877113Z",
     "shell.execute_reply.started": "2024-04-14T18:44:14.784878Z"
    },
    "papermill": {
     "duration": 72.576941,
     "end_time": "2022-02-06T13:47:08.610152",
     "exception": false,
     "start_time": "2022-02-06T13:45:56.033211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 420 ms (started: 2024-05-27 21:16:00 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# this code chunk is copied from Rob Mulla\n",
    "len_dict = {}\n",
    "word_dict = {}\n",
    "for t in (train_txt):\n",
    "    with open(t, \"r\") as txt_file:\n",
    "        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "        data = txt_file.read()\n",
    "        mylen = len(data.strip())\n",
    "        myword = len(data.split())\n",
    "        len_dict[myid] = mylen\n",
    "        word_dict[myid] = myword\n",
    "train[\"essay_len\"] = train[\"id\"].map(len_dict)\n",
    "train[\"essay_words\"] = train[\"id\"].map(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e056c9e",
   "metadata": {
    "papermill": {
     "duration": 0.054548,
     "end_time": "2022-02-06T13:47:08.720231",
     "exception": false,
     "start_time": "2022-02-06T13:47:08.665683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When comparing the discourse_end of the last discourse in each essay, we see that the discourse_end is sometimes larger than the essay_len. This cannot be right, but I will assume that those are last pieces of text in the essay indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7da4e95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:15.878194Z",
     "iopub.status.busy": "2024-04-14T18:44:15.878088Z",
     "iopub.status.idle": "2024-04-14T18:44:22.574124Z",
     "shell.execute_reply": "2024-04-14T18:44:22.573735Z",
     "shell.execute_reply.started": "2024-04-14T18:44:15.878182Z"
    },
    "papermill": {
     "duration": 35.284433,
     "end_time": "2022-02-06T13:47:44.056432",
     "exception": false,
     "start_time": "2022-02-06T13:47:08.771999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.81 s (started: 2024-05-27 21:16:00 -04:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#initialize column\n",
    "train['gap_length'] = np.nan\n",
    "\n",
    "#set the first one\n",
    "train.loc[0, 'gap_length'] = 7 #discourse start - 1 (previous end is always -1)\n",
    "\n",
    "#loop over rest\n",
    "for i in (range(1, len(train))):\n",
    "    #gap if difference is not 1 within an essay\n",
    "    if ((train.loc[i, \"id\"] == train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] > 1)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] - 2\n",
    "        #minus 2 as the previous end is always -1 and the previous start always +1\n",
    "    #gap if the first discourse of an new essay does not start at 0\n",
    "    elif ((train.loc[i, \"id\"] != train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] != 0)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] -1\n",
    "\n",
    "\n",
    " #is there any text after the last discourse of an essay?\n",
    "last_ones = train.drop_duplicates(subset=\"id\", keep='last')\n",
    "last_ones['gap_end_length'] = np.where((last_ones.discourse_end < last_ones.essay_len),\\\n",
    "                                       (last_ones.essay_len - last_ones.discourse_end),\\\n",
    "                                       np.nan)\n",
    "\n",
    "cols_to_merge = ['id', 'discourse_id', 'gap_end_length']\n",
    "train = train.merge(last_ones[cols_to_merge], on = [\"id\", \"discourse_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f152cfe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:22.574749Z",
     "iopub.status.busy": "2024-04-14T18:44:22.574644Z",
     "iopub.status.idle": "2024-04-14T18:44:22.586877Z",
     "shell.execute_reply": "2024-04-14T18:44:22.586584Z",
     "shell.execute_reply.started": "2024-04-14T18:44:22.574738Z"
    },
    "papermill": {
     "duration": 0.119834,
     "end_time": "2022-02-06T13:47:44.229623",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.109789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_len</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>gap_end_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>318</td>\n",
       "      <td>515</td>\n",
       "      <td>Position</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>684</td>\n",
       "      <td>692</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>693</td>\n",
       "      <td>710</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>714</td>\n",
       "      <td>724</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144275</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>725</td>\n",
       "      <td>1360</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144276</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1361</td>\n",
       "      <td>1471</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144277</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1472</td>\n",
       "      <td>1881</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144278</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1882</td>\n",
       "      <td>2019</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144279</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2029</td>\n",
       "      <td>2123</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144280</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2123</td>\n",
       "      <td>2702</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144281</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2703</td>\n",
       "      <td>2799</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144282</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2817</td>\n",
       "      <td>2907</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>3140</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2907</td>\n",
       "      <td>3140</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_start  discourse_end        discourse_type  \\\n",
       "144270  AFEC37C2D43F                0            317                  Lead   \n",
       "144271  AFEC37C2D43F              318            515              Position   \n",
       "144272  AFEC37C2D43F              684            692                 Claim   \n",
       "144273  AFEC37C2D43F              693            710                 Claim   \n",
       "144274  AFEC37C2D43F              714            724                 Claim   \n",
       "144275  AFEC37C2D43F              725           1360              Evidence   \n",
       "144276  AFEC37C2D43F             1361           1471                 Claim   \n",
       "144277  AFEC37C2D43F             1472           1881              Evidence   \n",
       "144278  AFEC37C2D43F             1882           2019                 Claim   \n",
       "144279  AFEC37C2D43F             2029           2123                 Claim   \n",
       "144280  AFEC37C2D43F             2123           2702              Evidence   \n",
       "144281  AFEC37C2D43F             2703           2799          Counterclaim   \n",
       "144282  AFEC37C2D43F             2817           2907              Rebuttal   \n",
       "144283  AFEC37C2D43F             2907           3140  Concluding Statement   \n",
       "\n",
       "        essay_len  gap_length  gap_end_length  \n",
       "144270       3140         NaN             NaN  \n",
       "144271       3140         NaN             NaN  \n",
       "144272       3140       167.0             NaN  \n",
       "144273       3140         NaN             NaN  \n",
       "144274       3140         2.0             NaN  \n",
       "144275       3140         NaN             NaN  \n",
       "144276       3140         NaN             NaN  \n",
       "144277       3140         NaN             NaN  \n",
       "144278       3140         NaN             NaN  \n",
       "144279       3140         8.0             NaN  \n",
       "144280       3140         NaN             NaN  \n",
       "144281       3140         NaN             NaN  \n",
       "144282       3140        16.0             NaN  \n",
       "144283       3140         NaN             NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.5 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "#display an example\n",
    "cols_to_display = ['id', 'discourse_start', 'discourse_end', 'discourse_type', 'essay_len', 'gap_length', 'gap_end_length']\n",
    "train[cols_to_display].query('id == \"AFEC37C2D43F\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ec1b9e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:22.587642Z",
     "iopub.status.busy": "2024-04-14T18:44:22.587512Z",
     "iopub.status.idle": "2024-04-14T18:44:22.597311Z",
     "shell.execute_reply": "2024-04-14T18:44:22.596866Z",
     "shell.execute_reply.started": "2024-04-14T18:44:22.587630Z"
    },
    "papermill": {
     "duration": 0.080122,
     "end_time": "2022-02-06T13:47:44.363283",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.283161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Besides the 144293 discourse texts, there are 32162 pieces of text not classified.\n",
      "time: 5.65 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "#how many pieces of tekst are not used as discourses?\n",
    "print(f\"Besides the {len(train)} discourse texts, there are {len(train.query('gap_length.notna()', engine='python'))+ len(train.query('gap_end_length.notna()', engine='python'))} pieces of text not classified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cbf17",
   "metadata": {
    "papermill": {
     "duration": 0.052699,
     "end_time": "2022-02-06T13:47:44.470668",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.417969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Although the gaps in the example above are small, we do have huge gaps in a number of essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e474171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:22.598039Z",
     "iopub.status.busy": "2024-04-14T18:44:22.597918Z",
     "iopub.status.idle": "2024-04-14T18:44:22.619736Z",
     "shell.execute_reply": "2024-04-14T18:44:22.619311Z",
     "shell.execute_reply.started": "2024-04-14T18:44:22.598027Z"
    },
    "papermill": {
     "duration": 0.103633,
     "end_time": "2022-02-06T13:47:44.628562",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.524929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.4 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: We have to change code slightly because we use less data. The original code plugs constant values\n",
    "# which depend on some data existing.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    _IREWR_tmp = train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()\n",
    "    _IREWR_plug_2 = _IREWR_tmp.iloc[0][\"id\"]\n",
    "    _IREWR_tmp\n",
    "else:\n",
    "    # Original\n",
    "    train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6936dc0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:22.620465Z",
     "iopub.status.busy": "2024-04-14T18:44:22.620347Z",
     "iopub.status.idle": "2024-04-14T18:44:22.641293Z",
     "shell.execute_reply": "2024-04-14T18:44:22.640952Z",
     "shell.execute_reply.started": "2024-04-14T18:44:22.620452Z"
    },
    "papermill": {
     "duration": 0.101666,
     "end_time": "2022-02-06T13:47:44.785265",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.683599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: We have to change code slightly because we use less data. The original code plugs constant values\n",
    "# which depend on some data existing.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    _IREWR_tmp2 = train.sort_values(by = \"gap_end_length\", ascending = False)[cols_to_display].head()\n",
    "    _IREWR_plug_1 = _IREWR_tmp2.iloc[1][\"id\"]\n",
    "    _IREWR_tmp2\n",
    "else:\n",
    "    train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfde2f",
   "metadata": {
    "papermill": {
     "duration": 0.056313,
     "end_time": "2022-02-06T13:47:44.897591",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.841278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, you can see a histogram of the length of all gaps with the outliers taken out (all gaps longer than 300 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "636d6403",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-04-14T18:44:37.034041Z",
     "iopub.status.busy": "2024-04-14T18:44:37.033301Z",
     "iopub.status.idle": "2024-04-14T18:44:37.051897Z",
     "shell.execute_reply": "2024-04-14T18:44:37.050980Z",
     "shell.execute_reply.started": "2024-04-14T18:44:37.033989Z"
    },
    "papermill": {
     "duration": 0.440058,
     "end_time": "2022-02-06T13:47:45.392861",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.952803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.14 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "all_gaps = (train.gap_length[~train.gap_length.isna()]).append((train.gap_end_length[~train.gap_end_length.isna()]), ignore_index= True)\n",
    "#filter outliers\n",
    "all_gaps = all_gaps[all_gaps<300]\n",
    "# fig = plt.figure(figsize=(12,6))\n",
    "# all_gaps.plot.hist(bins=100)\n",
    "# plt.title(\"Histogram of gap length (gaps up to 300 characters only)\")\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.xlabel(\"Length of gaps in characters\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f965f28",
   "metadata": {
    "papermill": {
     "duration": 0.056164,
     "end_time": "2022-02-06T13:47:45.505315",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.449151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Are there many really bad essays (large percentage of text not classified)?\n",
    "Yes, we do have those. Some have around 90% of text not classified as one of the discourse types.\n",
    "\n",
    "Regarding the one with gap_end_length 7348: I found out that this student just copied and pasted the same texts multiple times in his/her essay. See discussion topic: [Finding: essay with all text repeated many times](https://www.kaggle.com/c/feedback-prize-2021/discussion/298193)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9d10c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:45:28.494168Z",
     "iopub.status.busy": "2024-04-14T18:45:28.493601Z",
     "iopub.status.idle": "2024-04-14T18:45:28.535430Z",
     "shell.execute_reply": "2024-04-14T18:45:28.534843Z",
     "shell.execute_reply.started": "2024-04-14T18:45:28.494130Z"
    },
    "papermill": {
     "duration": 0.125624,
     "end_time": "2022-02-06T13:47:45.686445",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.560821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_len</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>gap_end_length</th>\n",
       "      <th>perc_not_classified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C278EDC82048</th>\n",
       "      <td>8015</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7348.0</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129497C3E0FC</th>\n",
       "      <td>3616</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3173.0</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5EE08CB44B9</th>\n",
       "      <td>3022</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2669.0</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B7C17E1993BA</th>\n",
       "      <td>3569</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F45B396E0A01</th>\n",
       "      <td>1865</td>\n",
       "      <td>1657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              essay_len  gap_length  gap_end_length  perc_not_classified\n",
       "id                                                                      \n",
       "C278EDC82048       8015        13.0          7348.0                 0.92\n",
       "129497C3E0FC       3616       130.0          3173.0                 0.91\n",
       "F5EE08CB44B9       3022        62.0          2669.0                 0.90\n",
       "B7C17E1993BA       3569      1110.0          2060.0                 0.89\n",
       "F45B396E0A01       1865      1657.0             0.0                 0.89"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.3 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "total_gaps = train.groupby('id').agg({'essay_len': 'first',\\\n",
    "                                               'gap_length': 'sum',\\\n",
    "                                               'gap_end_length': 'sum'})\n",
    "total_gaps['perc_not_classified'] = round(((total_gaps.gap_length + total_gaps.gap_end_length)/total_gaps.essay_len),2)\n",
    "\n",
    "total_gaps.sort_values(by = 'perc_not_classified', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a9385",
   "metadata": {
    "papermill": {
     "duration": 0.057853,
     "end_time": "2022-02-06T13:47:45.801995",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.744142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Color printing essays including the gaps\n",
    "\n",
    "I saw  a very pretty way to do this in the Notebook made by Sanskar Hasija (https://www.kaggle.com/odins0n/feedback-prize-eda). The code is nice but did not print the gaps yet. Below, I make a function that adds all gaps in an essay as rows with discourse type \"Nothing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bcf0d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:45:28.536952Z",
     "iopub.status.busy": "2024-04-14T18:45:28.536559Z",
     "iopub.status.idle": "2024-04-14T18:45:28.541935Z",
     "shell.execute_reply": "2024-04-14T18:45:28.541491Z",
     "shell.execute_reply.started": "2024-04-14T18:45:28.536937Z"
    },
    "papermill": {
     "duration": 0.0748,
     "end_time": "2022-02-06T13:47:45.934099",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.859299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 913 µs (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def add_gap_rows(essay):\n",
    "    cols_to_keep = ['discourse_start', 'discourse_end', 'discourse_type', 'gap_length', 'gap_end_length']\n",
    "    df_essay = train.query('id == @essay')[cols_to_keep].reset_index(drop = True)\n",
    "    \n",
    "    print(df_essay)\n",
    "\n",
    "    #index new row\n",
    "    insert_row = len(df_essay)\n",
    "   \n",
    "    for i in range(1, len(df_essay)):          \n",
    "        if df_essay.loc[i,\"gap_length\"] >0:\n",
    "            if i == 0:\n",
    "                start = 0 #as there is no i-1 for first row\n",
    "                end = df_essay.loc[0, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "            else:\n",
    "                start = df_essay.loc[i-1, \"discourse_end\"] + 1\n",
    "                end = df_essay.loc[i, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "\n",
    "    df_essay = df_essay.sort_values(by = \"discourse_start\").reset_index(drop=True)\n",
    "\n",
    "    #add gap at end\n",
    "    if df_essay.loc[(len(df_essay)-1),'gap_end_length'] > 0:\n",
    "        start = df_essay.loc[(len(df_essay)-1), \"discourse_end\"] + 1\n",
    "        end = start + df_essay.loc[(len(df_essay)-1), 'gap_end_length']\n",
    "        disc_type = \"Nothing\"\n",
    "        gap_end = np.nan\n",
    "        gap = np.nan\n",
    "        df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "        \n",
    "    return(df_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f15134ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:45:28.542991Z",
     "iopub.status.busy": "2024-04-14T18:45:28.542843Z",
     "iopub.status.idle": "2024-04-14T18:45:28.553469Z",
     "shell.execute_reply": "2024-04-14T18:45:28.553023Z",
     "shell.execute_reply.started": "2024-04-14T18:45:28.542978Z"
    },
    "papermill": {
     "duration": 0.096602,
     "end_time": "2022-02-06T13:47:46.088119",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.991517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_start  discourse_end discourse_type  gap_length  gap_end_length\n",
      "0                0             57           Lead         NaN             NaN\n",
      "1               58            111          Claim         NaN             NaN\n",
      "2              121            137          Claim         8.0             NaN\n",
      "3              158            281   Counterclaim        19.0             NaN\n",
      "4              386            443       Position       103.0          3173.0\n",
      "time: 8 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: See above.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    add_gap_rows(_IREWR_plug_1)\n",
    "else:\n",
    "    add_gap_rows(\"129497C3E0FC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eadc423",
   "metadata": {
    "papermill": {
     "duration": 0.058607,
     "end_time": "2022-02-06T13:47:46.204803",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.146196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This enables me to make a function that uses the code made by Sanskar Hasija to color print an essay including the gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9532b18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:45:28.554996Z",
     "iopub.status.busy": "2024-04-14T18:45:28.554863Z",
     "iopub.status.idle": "2024-04-14T18:45:28.558646Z",
     "shell.execute_reply": "2024-04-14T18:45:28.558105Z",
     "shell.execute_reply.started": "2024-04-14T18:45:28.554983Z"
    },
    "papermill": {
     "duration": 0.073031,
     "end_time": "2022-02-06T13:47:46.338095",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.265064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 566 µs (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def print_colored_essay(essay):\n",
    "    df_essay = add_gap_rows(essay)\n",
    "    #code from https://www.kaggle.com/odins0n/feedback-prize-eda, but adjusted to df_essay\n",
    "    essay_file = os.path.abspath('') + \"/input/feedback-prize-2021/train/\" + essay + \".txt\"\n",
    "\n",
    "    ents = []\n",
    "    for i, row in df_essay.iterrows():\n",
    "        ents.append({\n",
    "                        'start': int(row['discourse_start']), \n",
    "                         'end': int(row['discourse_end']), \n",
    "                         'label': row['discourse_type']\n",
    "                    })\n",
    "\n",
    "    with open(essay_file, 'r') as file: data = file.read()\n",
    "\n",
    "    doc2 = {\n",
    "        \"text\": data,\n",
    "        \"ents\": ents,\n",
    "    }\n",
    "\n",
    "    colors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA','Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\n",
    "    options = {\"ents\": df_essay.discourse_type.unique().tolist(), \"colors\": colors}\n",
    "    # STEFANOS: Disable plotting-like code.\n",
    "#     spacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0625cee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:45:28.559348Z",
     "iopub.status.busy": "2024-04-14T18:45:28.559241Z",
     "iopub.status.idle": "2024-04-14T18:45:28.567863Z",
     "shell.execute_reply": "2024-04-14T18:45:28.567205Z",
     "shell.execute_reply.started": "2024-04-14T18:45:28.559337Z"
    },
    "papermill": {
     "duration": 0.086354,
     "end_time": "2022-02-06T13:47:46.483456",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.397102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   discourse_start  discourse_end        discourse_type  gap_length  \\\n",
      "0                0             77              Position         NaN   \n",
      "1               77            455              Evidence         NaN   \n",
      "2              456           1014              Evidence         NaN   \n",
      "3             1015           1130                 Claim         NaN   \n",
      "4             3377           3846  Concluding Statement      2245.0   \n",
      "\n",
      "   gap_end_length  \n",
      "0             NaN  \n",
      "1             NaN  \n",
      "2             NaN  \n",
      "3             NaN  \n",
      "4             NaN  \n",
      "time: 5.45 ms (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: See above.\n",
    "# print_colored_essay(\"7330313ED3F0\")\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    print_colored_essay(_IREWR_plug_2)\n",
    "else:\n",
    "    print_colored_essay(\"7330313ED3F0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e3c63",
   "metadata": {
    "papermill": {
     "duration": 0.05854,
     "end_time": "2022-02-06T13:47:46.600585",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.542045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Most used words per Discourse Type\n",
    "\n",
    "Initially, I did a manual effort to find out which single words were used most often.I took out stopwords, converted all text to lowercase, but left in the punctuation. I also took out some extra words that were all over the place in the figures for each discourse_type. After this effort, I was not sure how useful this is. One thing to notice is that \"however,\" is used a lot in Rebuttal.\n",
    "\n",
    "Later on, I decided that making one function for all n_grams was the way to go. If you are still interested in my manual effort for the single words, you can unhide the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af5f8d4",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-04-14T18:46:06.543553Z",
     "iopub.status.busy": "2024-04-14T18:46:06.542547Z",
     "iopub.status.idle": "2024-04-14T18:46:07.858720Z",
     "shell.execute_reply": "2024-04-14T18:46:07.858228Z",
     "shell.execute_reply.started": "2024-04-14T18:46:06.543515Z"
    },
    "papermill": {
     "duration": 5.749522,
     "end_time": "2022-02-06T13:47:52.41061",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.661088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.26 s (started: 2024-05-27 21:16:08 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.lower()\n",
    "\n",
    "#get stopwords from nltk library\n",
    "stop_english = stopwords.words(\"english\")\n",
    "other_words_to_take_out = ['school', 'students', 'people', 'would', 'could', 'many']\n",
    "stop_english.extend(other_words_to_take_out)\n",
    "\n",
    "#put dataframe of Top-10 words in dict for all discourse types\n",
    "counts_dict = {}\n",
    "for dt in train['discourse_type'].unique():\n",
    "    df = train.query('discourse_type == @dt')\n",
    "    text = df.discourse_text.apply(lambda x: x.split()).tolist()\n",
    "    text = [item for elem in text for item in elem]\n",
    "    df1 = pd.Series(text).value_counts().to_frame().reset_index()\n",
    "    df1.columns = ['Word', 'Frequency']\n",
    "    df1 = df1[~df1.Word.isin(stop_english)].head(10)\n",
    "    df1 = df1.set_index(\"Word\").sort_values(by = \"Frequency\", ascending = True)\n",
    "    counts_dict[dt] = df1\n",
    "\n",
    "# STEFANOS: Disable plotting\n",
    "# plt.figure(figsize=(15, 12))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "keys = list(counts_dict.keys())\n",
    "\n",
    "# STEFANOS: Disable plotting\n",
    "# for n, key in enumerate(keys):\n",
    "#     ax = plt.subplot(4, 2, n + 1)\n",
    "#     ax.set_title(f\"Most used words in {key}\")\n",
    "#     counts_dict[keys[n]].plot(ax=ax, kind = 'barh')\n",
    "#     plt.ylabel(\"\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b8e61",
   "metadata": {
    "papermill": {
     "duration": 0.06137,
     "end_time": "2022-02-06T13:47:52.534893",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.473523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making n_grams for each discourse type\n",
    "\n",
    "After the manual effort above, I was not fully pleased with the result and decided that I wanted to make a function to compose Top-10 n_grams per discount type by using CountVectorizer(). This function should also work for the single words (just run it with n_grams =1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b175ce5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:46:48.999953Z",
     "iopub.status.busy": "2024-04-14T18:46:48.998930Z",
     "iopub.status.idle": "2024-04-14T18:46:49.012927Z",
     "shell.execute_reply": "2024-04-14T18:46:49.011958Z",
     "shell.execute_reply.started": "2024-04-14T18:46:48.999912Z"
    },
    "papermill": {
     "duration": 0.076141,
     "end_time": "2022-02-06T13:47:52.674833",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.598692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 632 µs (started: 2024-05-27 21:16:09 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def get_n_grams(n_grams, top_n = 10):\n",
    "    df_words = pd.DataFrame()\n",
    "    for dt in (train['discourse_type'].unique()):\n",
    "        df = train.query('discourse_type == @dt')\n",
    "        texts = df['discourse_text'].tolist()\n",
    "        vec = CountVectorizer(lowercase = True, stop_words = 'english',\\\n",
    "                              ngram_range=(n_grams, n_grams)).fit(texts)\n",
    "        bag_of_words = vec.transform(texts)\n",
    "        sum_words = bag_of_words.sum(axis=0)\n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "        cvec_df = pd.DataFrame.from_records(words_freq,\\\n",
    "                                            columns= ['words', 'counts']).sort_values(by=\"counts\", ascending=False)\n",
    "        cvec_df.insert(0, \"Discourse_type\", dt)\n",
    "        cvec_df = cvec_df.iloc[:top_n,:]\n",
    "        df_words = df_words.append(cvec_df)\n",
    "    return df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f7544",
   "metadata": {
    "papermill": {
     "duration": 0.062281,
     "end_time": "2022-02-06T13:47:52.799073",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.736792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function return one dataframe with 70 rows (the top 10 most used n-grams for each discourse type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd354a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:46:51.005647Z",
     "iopub.status.busy": "2024-04-14T18:46:51.005007Z",
     "iopub.status.idle": "2024-04-14T18:47:00.256219Z",
     "shell.execute_reply": "2024-04-14T18:47:00.255689Z",
     "shell.execute_reply.started": "2024-04-14T18:46:51.005611Z"
    },
    "papermill": {
     "duration": 25.563253,
     "end_time": "2022-02-06T13:48:18.423732",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.860479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discourse_type</th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73564</th>\n",
       "      <td>Lead</td>\n",
       "      <td>electoral college</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63518</th>\n",
       "      <td>Lead</td>\n",
       "      <td>driverless cars</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lead</td>\n",
       "      <td>cell phones</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>Lead</td>\n",
       "      <td>summer projects</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85397</th>\n",
       "      <td>Lead</td>\n",
       "      <td>distance learning</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Discourse_type              words  counts\n",
       "73564           Lead  electoral college    1179\n",
       "63518           Lead    driverless cars     808\n",
       "55              Lead        cell phones     592\n",
       "19359           Lead    summer projects     513\n",
       "85397           Lead  distance learning     468"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.88 s (started: 2024-05-27 21:16:09 -04:00)\n"
     ]
    }
   ],
   "source": [
    "bigrams = get_n_grams(n_grams = 2, top_n=10)\n",
    "bigrams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70401d3",
   "metadata": {
    "papermill": {
     "duration": 0.063593,
     "end_time": "2022-02-06T13:48:18.552695",
     "exception": false,
     "start_time": "2022-02-06T13:48:18.489102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I have also made a function that prints the results in this dataframe as subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46070fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:47:16.680089Z",
     "iopub.status.busy": "2024-04-14T18:47:16.679458Z",
     "iopub.status.idle": "2024-04-14T18:47:16.696214Z",
     "shell.execute_reply": "2024-04-14T18:47:16.695224Z",
     "shell.execute_reply.started": "2024-04-14T18:47:16.680051Z"
    },
    "papermill": {
     "duration": 1.684094,
     "end_time": "2022-02-06T13:48:20.300811",
     "exception": false,
     "start_time": "2022-02-06T13:48:18.616717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.28 ms (started: 2024-05-27 21:16:19 -04:00)\n"
     ]
    }
   ],
   "source": [
    "def plot_ngram(df, type = \"bigrams\"):\n",
    "# STEFANOS: Disable plotting\n",
    "#     plt.figure(figsize=(15, 12))\n",
    "#     plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#     for n, dt in enumerate(df.Discourse_type.unique()):\n",
    "#         ax = plt.subplot(4, 2, n + 1)\n",
    "#         ax.set_title(f\"Most used {type} in {dt}\")\n",
    "        data = df.query('Discourse_type == @dt')[['words', 'counts']].set_index(\"words\").sort_values(by = \"counts\", ascending = True)\n",
    "#         data.plot(ax=ax, kind = 'barh')\n",
    "#         plt.ylabel(\"\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "plot_ngram(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd1e078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T14:49:19.545062Z",
     "iopub.status.busy": "2021-12-28T14:49:19.543924Z",
     "iopub.status.idle": "2021-12-28T14:49:21.441599Z",
     "shell.execute_reply": "2021-12-28T14:49:21.4376Z",
     "shell.execute_reply.started": "2021-12-28T14:49:19.545018Z"
    },
    "papermill": {
     "duration": 0.069866,
     "end_time": "2022-02-06T13:48:20.440993",
     "exception": false,
     "start_time": "2022-02-06T13:48:20.371127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I am also plotting the trigrams using both functions in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42a5b2f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:47:16.698153Z",
     "iopub.status.busy": "2024-04-14T18:47:16.697826Z",
     "iopub.status.idle": "2024-04-14T18:47:28.225546Z",
     "shell.execute_reply": "2024-04-14T18:47:28.225193Z",
     "shell.execute_reply.started": "2024-04-14T18:47:16.698126Z"
    },
    "papermill": {
     "duration": 32.621724,
     "end_time": "2022-02-06T13:48:53.132923",
     "exception": false,
     "start_time": "2022-02-06T13:48:20.511199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.9 s (started: 2024-05-27 21:16:19 -04:00)\n"
     ]
    }
   ],
   "source": [
    "trigrams = get_n_grams(n_grams = 3, top_n=10)\n",
    "plot_ngram(trigrams, type = \"trigrams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2cd51",
   "metadata": {
    "papermill": {
     "duration": 0.075665,
     "end_time": "2022-02-06T13:48:53.286223",
     "exception": false,
     "start_time": "2022-02-06T13:48:53.210558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NER Introduction\n",
    "\n",
    "Named Entity Recognition (NER) is the technique that works best for this challenge. If you are looking for more info on this, the free course on Hugging Face is strongly recommended. In the section [Token Classification](https://huggingface.co/course/chapter7/2?fw=pt), we can find the following things that are relevant here:\n",
    "- Named entity recognition (NER): Find the entities (such as persons, locations, or organizations) in a sentence. This can be formulated as attributing a label to each token by having one class per entity and one class for “no entity.”\n",
    "- Chunking: Find the tokens that belong to the same entity. This task (which can be combined with POS or NER) can be formulated as attributing one label (usually B-) to any tokens that are at the beginning of a chunk, another label (usually I-) to tokens that are inside a chunk, and a third label (usually O) to tokens that don’t belong to any chunk.\n",
    "\n",
    "Basically, what is being used in this competition is NER Chunking. Darek Kłeczek wrote a great notebook that explains the ideas behind this (please upvote!): [Visual Tutorial NER Chunking Token Classification](https://www.kaggle.com/thedrcat/visual-tutorial-ner-chunking-token-classification).\n",
    "\n",
    "In this section, I am only going to show how these NER labels can be made for this competition. I am basically using the loop found in Chris Deotte's great notebook [PyTorch - BigBird - NER - [CV 0.615]](https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615) (Please upvote his notebook!), but tried to make it a little easier to understand. I am also using df.loc instead of df.iterrows.\n",
    "\n",
    "First, we have to make a dataframe with all full texts of the essays in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44fa0d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:47:28.226268Z",
     "iopub.status.busy": "2024-04-14T18:47:28.226164Z",
     "iopub.status.idle": "2024-04-14T18:47:29.064966Z",
     "shell.execute_reply": "2024-04-14T18:47:29.064668Z",
     "shell.execute_reply.started": "2024-04-14T18:47:28.226257Z"
    },
    "papermill": {
     "duration": 9.970722,
     "end_time": "2022-02-06T13:49:03.335172",
     "exception": false,
     "start_time": "2022-02-06T13:48:53.36445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450531F9573</td>\n",
       "      <td>When asking for advice it is beneficial to ask...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8A9A8B0A3597</td>\n",
       "      <td>Extracurricular activities can give you many b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9230E5F2AC7F</td>\n",
       "      <td>3-2-11\\n\\nDear TEACHER_NAME,\\n\\nI believe that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC71057F9A5</td>\n",
       "      <td>Should students be required to participate in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A156FB0E388E</td>\n",
       "      <td>The author suggest the reader to study Venus i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  7450531F9573  When asking for advice it is beneficial to ask...\n",
       "1  8A9A8B0A3597  Extracurricular activities can give you many b...\n",
       "2  9230E5F2AC7F  3-2-11\\n\\nDear TEACHER_NAME,\\n\\nI believe that...\n",
       "3  BBC71057F9A5  Should students be required to participate in ...\n",
       "4  A156FB0E388E  The author suggest the reader to study Venus i..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 284 ms (started: 2024-05-27 21:16:32 -04:00)\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, train_texts = [], []\n",
    "for f in (list(os.listdir(os.path.abspath('') +'/input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open(os.path.abspath('') +'/input/feedback-prize-2021/train/' + f, 'r').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d710d2c",
   "metadata": {
    "papermill": {
     "duration": 0.085572,
     "end_time": "2022-02-06T13:49:03.515979",
     "exception": false,
     "start_time": "2022-02-06T13:49:03.430407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to add a column with NER entities to this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1202c0d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:47:29.065566Z",
     "iopub.status.busy": "2024-04-14T18:47:29.065470Z",
     "iopub.status.idle": "2024-04-14T18:48:14.824183Z",
     "shell.execute_reply": "2024-04-14T18:48:14.823836Z",
     "shell.execute_reply.started": "2024-04-14T18:47:29.065555Z"
    },
    "papermill": {
     "duration": 153.131048,
     "end_time": "2022-02-06T13:51:36.72673",
     "exception": false,
     "start_time": "2022-02-06T13:49:03.595682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO RETURN {'train_text_df'}\n",
      "USED {'train', 'train_text_df'}\n",
      "Internal time: 35.4 s\n",
      "DS {'shape': (144293, 15), 'column_index': ['- id: string\\n   - Typical length: 12 (avg)', '- discourse_id: integer', '- discourse_start: integer', '- discourse_end: integer', '- discourse_text: string\\n   - Typical length: 240 (avg)', '- discourse_type: string\\n   - Typical length: 7 (avg)', '- discourse_type_num: string\\n   - Typical length: 9 (avg)', '- predictionstring: string\\n   - Typical length: 161 (avg)', '- discourse_len: integer', '- pred_len: integer', '- discourse_nr: integer', '- essay_len: integer', '- essay_words: integer', '- gap_length: float', '- gap_end_length: float'], 'row_index': ['Integer']}\n",
      "['Integer']\n",
      "['- id: string\\n   - Typical length: 12 (avg)', '- discourse_id: integer', '- discourse_start: integer', '- discourse_end: integer', '- discourse_text: string\\n   - Typical length: 240 (avg)', '- discourse_type: string\\n   - Typical length: 7 (avg)', '- discourse_type_num: string\\n   - Typical length: 9 (avg)', '- predictionstring: string\\n   - Typical length: 161 (avg)', '- discourse_len: integer', '- pred_len: integer', '- discourse_nr: integer', '- essay_len: integer', '- essay_words: integer', '- gap_length: float', '- gap_end_length: float']\n",
      "DS {'shape': (15594, 2), 'column_index': ['- id: string\\n   - Typical length: 12 (avg)', '- text: string\\n   - Typical length: 2364 (avg)'], 'row_index': ['Integer']}\n",
      "['Integer']\n",
      "['- id: string\\n   - Typical length: 12 (avg)', '- text: string\\n   - Typical length: 2364 (avg)']\n",
      "DS {'shape': (15594, 3), 'column_index': ['- id: string\\n   - Typical length: 12 (avg)', '- text: string\\n   - Typical length: 2364 (avg)', '- entities: list of str'], 'row_index': ['Integer']}\n",
      "['Integer']\n",
      "['- id: string\\n   - Typical length: 12 (avg)', '- text: string\\n   - Typical length: 2364 (avg)', '- entities: list of str']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# %%snappy\\ndef extracted_cell(train: DataFrame, train_text_df: DataFrame) -> DataFrame:\\n    \"\"\"\\nParams:\\ntrain: pandas.DataFrame:\\n          Rows:   Integer\\n          Columns:   - id: string\\n                         - Typical length: 12 (avg)\\n                      - discourse_id: integer\\n                      - discourse_start: integer\\n                      - discourse_end: integer\\n                      - discourse_text: string\\n                         - Typical length: 240 (avg)\\n                      - discourse_type: string\\n                         - Typical length: 7 (avg)\\n                      - discourse_type_num: string\\n                         - Typical length: 9 (avg)\\n                      - predictionstring: string\\n                         - Typical length: 161 (avg)\\n                      - discourse_len: integer\\n                      - pred_len: integer\\n                      - discourse_nr: integer\\n                      - essay_len: integer\\n                      - essay_words: integer\\n                      - gap_length: float\\n                      - gap_end_length: float\\ntrain_text_df: pandas.DataFrame:\\n                  Rows:   Integer\\n                  Columns:   - id: string\\n                                 - Typical length: 12 (avg)\\n                              - text: string\\n                                 - Typical length: 2364 (avg)\\n\\nReturns:\\npandas.DataFrame:\\n   Rows:   Integer\\n   Columns:   - id: string\\n                  - Typical length: 12 (avg)\\n               - text: string\\n                  - Typical length: 2364 (avg)\\n               - entities: list of str\\n\"\"\"\\n    all_entities = []\\n    for i in range(len(train_text_df)):\\n        total = len(train_text_df.loc[i, \\'text\\'].split())\\n        entities = [\\'O\\'] * total\\n        discourse_id = train_text_df.loc[i, \\'id\\']\\n        train_df_id = train.query(\\'id == @discourse_id\\').reset_index(drop=True)\\n        for j in range(len(train_df_id)):\\n            discourse = train_df_id.loc[j, \\'discourse_type\\']\\n            list_ix = [int(x) for x in train_df_id.loc[j, \\'predictionstring\\'].split(\\' \\')]\\n            entities[list_ix[0]] = f\\'B-{discourse}\\'\\n            for k in list_ix[1:]:\\n                entities[k] = f\\'I-{discourse}\\'\\n        all_entities.append(entities)\\n    train_text_df[\\'entities\\'] = all_entities\\n    return train_text_df\\ntrain_text_df = extracted_cell(train, train_text_df)'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.6 s (started: 2024-05-27 21:16:32 -04:00)\n"
     ]
    }
   ],
   "source": [
    "%%snappy\n",
    "all_entities = []\n",
    "#loop over dataframe with all full texts\n",
    "for i in (range(len(train_text_df))):\n",
    "    total = len(train_text_df.loc[i, 'text'].split())\n",
    "    #now a list with length the total number of words in an essay is initialised with all values being \"O\"\n",
    "    entities = [\"O\"]*total\n",
    "    #now loop over dataframe with all discourses of this particular essay\n",
    "    discourse_id = train_text_df.loc[i, 'id']\n",
    "    train_df_id = train.query('id == @discourse_id').reset_index(drop=True)\n",
    "    for j in range(len(train_df_id)):\n",
    "        discourse = train_df_id.loc[j, 'discourse_type']\n",
    "        #make a list with the position numbers in predictionstring converted into integer\n",
    "        list_ix = [int(x) for x in train_df_id.loc[j, 'predictionstring'].split(' ')]\n",
    "        #now the entities lists gets overwritten where there are discourse identified by the experts\n",
    "        #the first word of each discourse gets prefix \"Beginning\"\n",
    "        entities[list_ix[0]] = f\"B-{discourse}\"\n",
    "        #the other ones get prefix I\n",
    "        for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n",
    "    all_entities.append(entities)\n",
    "    \n",
    "    \n",
    "train_text_df['entities'] = all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bff946a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'G\\xc5,B\\xa3\\xc8/\\x9b'\n",
      "time: 5.51 ms (started: 2024-05-27 21:17:13 -04:00)\n"
     ]
    }
   ],
   "source": [
    "print(hash_dataframe(train_text_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "568ebbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T18:48:14.825846Z",
     "iopub.status.busy": "2024-04-14T18:48:14.825639Z",
     "iopub.status.idle": "2024-04-14T18:48:14.831696Z",
     "shell.execute_reply": "2024-04-14T18:48:14.831276Z",
     "shell.execute_reply.started": "2024-04-14T18:48:14.825823Z"
    },
    "papermill": {
     "duration": 0.101022,
     "end_time": "2022-02-06T13:51:36.905818",
     "exception": false,
     "start_time": "2022-02-06T13:51:36.804796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450531F9573</td>\n",
       "      <td>When asking for advice it is beneficial to ask...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8A9A8B0A3597</td>\n",
       "      <td>Extracurricular activities can give you many b...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9230E5F2AC7F</td>\n",
       "      <td>3-2-11\\n\\nDear TEACHER_NAME,\\n\\nI believe that...</td>\n",
       "      <td>[O, O, O, B-Position, I-Position, I-Position, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC71057F9A5</td>\n",
       "      <td>Should students be required to participate in ...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A156FB0E388E</td>\n",
       "      <td>The author suggest the reader to study Venus i...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  7450531F9573  When asking for advice it is beneficial to ask...   \n",
       "1  8A9A8B0A3597  Extracurricular activities can give you many b...   \n",
       "2  9230E5F2AC7F  3-2-11\\n\\nDear TEACHER_NAME,\\n\\nI believe that...   \n",
       "3  BBC71057F9A5  Should students be required to participate in ...   \n",
       "4  A156FB0E388E  The author suggest the reader to study Venus i...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "2  [O, O, O, B-Position, I-Position, I-Position, ...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Position, I-Position, I-Position, I-Positio...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.68 ms (started: 2024-05-27 21:17:13 -04:00)\n"
     ]
    }
   ],
   "source": [
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1753deda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 87.365791226\n",
      "time: 397 µs (started: 2024-05-27 21:17:13 -04:00)\n"
     ]
    }
   ],
   "source": [
    "SNAPPY_end_time = time.perf_counter_ns()\n",
    "print(\"Total elapsed time:\", (SNAPPY_end_time - SNAPPY_start_time) / (10 ** 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290ef94",
   "metadata": {
    "papermill": {
     "duration": 0.078177,
     "end_time": "2022-02-06T13:51:37.063558",
     "exception": false,
     "start_time": "2022-02-06T13:51:36.985381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thanks for your attention! If you like this notebook, an upvote is always appreciated.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
