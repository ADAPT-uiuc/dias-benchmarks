{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043611,
     "end_time": "2022-02-06T13:43:52.364884",
     "exception": false,
     "start_time": "2022-02-06T13:43:52.321273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feedback Prize - Evaluating Student Writing\n",
    "\n",
    "Georgia State University (GSU) is an undergraduate and graduate urban public research institution in Atlanta. U.S. News & World Report ranked GSU as one of the most innovative universities in the nation. GSU awards more bachelor’s degrees to African-Americans than any other non-profit college or university in the country. GSU and The Learning Agency Lab, an independent nonprofit based in Arizona, are focused on developing science of learning-based tools and programs for social good.\n",
    "\n",
    "In this competition, you’ll identify elements in student writing. More specifically, you will automatically segment texts and classify argumentative and rhetorical elements in essays written by 6th-12th grade students. You'll have access to the largest dataset of student writing ever released in order to test your skills in natural language processing, a fast-growing area of data science.\n",
    "\n",
    "If successful, you'll make it easier for students to receive feedback on their writing and increase opportunities to improve writing outcomes. Virtual writing tutors and automated writing systems can leverage these algorithms while teachers may use them to reduce grading time. The open-sourced algorithms you come up with will allow any educational organization to better help young writers develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-06T13:43:52.452622Z",
     "iopub.status.busy": "2022-02-06T13:43:52.451369Z",
     "iopub.status.idle": "2022-02-06T13:44:05.03955Z",
     "shell.execute_reply": "2022-02-06T13:44:05.038791Z",
     "shell.execute_reply.started": "2022-02-06T13:05:02.819938Z"
    },
    "papermill": {
     "duration": 12.632175,
     "end_time": "2022-02-06T13:44:05.039722",
     "exception": false,
     "start_time": "2022-02-06T13:43:52.407547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# STEFANOS: Disable, can't be parsed. Doesn't change the behavior especially since we've disabled plotting.\n",
    "# %matplotlib inline\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# STEFANOS: Remove unneeded imports.\n",
    "# import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:05.129137Z",
     "iopub.status.busy": "2022-02-06T13:44:05.128201Z",
     "iopub.status.idle": "2022-02-06T13:44:07.867254Z",
     "shell.execute_reply": "2022-02-06T13:44:07.866691Z",
     "shell.execute_reply.started": "2022-02-06T13:05:13.761069Z"
    },
    "papermill": {
     "duration": 2.786403,
     "end_time": "2022-02-06T13:44:07.86746",
     "exception": false,
     "start_time": "2022-02-06T13:44:05.081057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/feedback-prize-2021/train.csv')\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    train = train[:5000]\n",
    "\n",
    "train[['discourse_id', 'discourse_start', 'discourse_end']] = train[['discourse_id', 'discourse_start', 'discourse_end']].astype(int)\n",
    "\n",
    "sample_submission = pd.read_csv('../input/feedback-prize-2021/sample_submission.csv')\n",
    "\n",
    "#The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell\n",
    "train_txt = glob('../input/feedback-prize-2021/train/*.txt')\n",
    "test_txt = glob('../input/feedback-prize-2021/test/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144293 entries, 0 to 144292\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   id                  144293 non-null  object\n",
      " 1   discourse_id        144293 non-null  int64 \n",
      " 2   discourse_start     144293 non-null  int64 \n",
      " 3   discourse_end       144293 non-null  int64 \n",
      " 4   discourse_text      144293 non-null  object\n",
      " 5   discourse_type      144293 non-null  object\n",
      " 6   discourse_type_num  144293 non-null  object\n",
      " 7   predictionstring    144293 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 8.8+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                5 non-null      object \n",
      " 1   class             0 non-null      float64\n",
      " 2   predictionstring  0 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 248.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4184497 entries, 0 to 4184496\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Dtype \n",
      "---  ------              ----- \n",
      " 0   id                  object\n",
      " 1   discourse_id        int64 \n",
      " 2   discourse_start     int64 \n",
      " 3   discourse_end       int64 \n",
      " 4   discourse_text      object\n",
      " 5   discourse_type      object\n",
      " 6   discourse_type_num  object\n",
      " 7   predictionstring    object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 255.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                5 non-null      object \n",
      " 1   class             0 non-null      float64\n",
      " 2   predictionstring  0 non-null      float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df = train\n",
    "intended_df_size_in_MB = 256\n",
    "factor = intended_df_size_in_MB*(2**20)/df.memory_usage(index=True).sum()\n",
    "if int(factor) > 0:\n",
    "    df = pd.concat([df]*int(factor), ignore_index=True)\n",
    "else:\n",
    "    rowCount = int(df.shape[0]*factor)\n",
    "    df = df[0:rowCount]\n",
    "train = df\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04211,
     "end_time": "2022-02-06T13:44:07.953245",
     "exception": false,
     "start_time": "2022-02-06T13:44:07.911135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction to the competition\n",
    "\n",
    "Basically, we have a bunch of essays written by kids in the age range of about 12-18 years old in which we have to find word sequences that can be classified as one of 7 \"discourse types\". These are:\n",
    "\n",
    "- Lead - an introduction that begins with a statistic, a quotation, a description, or some other device to grab the reader’s attention and point toward the thesis\n",
    "- Position - an opinion or conclusion on the main question\n",
    "- Claim - a claim that supports the position\n",
    "- Counterclaim - a claim that refutes another claim or gives an opposing reason to the position\n",
    "- Rebuttal - a claim that refutes a counterclaim\n",
    "- Evidence - ideas or examples that support claims, counterclaims, or rebuttals.\n",
    "- Concluding Statement - a concluding statement that restates the claims\n",
    "\n",
    "Let's look at the full text of one essay first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:08.040361Z",
     "iopub.status.busy": "2022-02-06T13:44:08.038928Z",
     "iopub.status.idle": "2022-02-06T13:44:08.83206Z",
     "shell.execute_reply": "2022-02-06T13:44:08.832606Z",
     "shell.execute_reply.started": "2022-02-06T13:05:15.925429Z"
    },
    "papermill": {
     "duration": 0.837797,
     "end_time": "2022-02-06T13:44:08.832796",
     "exception": false,
     "start_time": "2022-02-06T13:44:07.994999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Disable shell code.\n",
    "# !cat ../input/feedback-prize-2021/train/423A1CA112E2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.041503,
     "end_time": "2022-02-06T13:44:08.916502",
     "exception": false,
     "start_time": "2022-02-06T13:44:08.874999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The train dataset gives us the following human annotations that are extracted from this essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:09.007738Z",
     "iopub.status.busy": "2022-02-06T13:44:09.006655Z",
     "iopub.status.idle": "2022-02-06T13:44:09.051922Z",
     "shell.execute_reply": "2022-02-06T13:44:09.052467Z",
     "shell.execute_reply.started": "2022-02-06T13:05:16.705196Z"
    },
    "papermill": {
     "duration": 0.092419,
     "end_time": "2022-02-06T13:44:09.052641",
     "exception": false,
     "start_time": "2022-02-06T13:44:08.960222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627660524</td>\n",
       "      <td>8</td>\n",
       "      <td>229</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627653021</td>\n",
       "      <td>230</td>\n",
       "      <td>312</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627671020</td>\n",
       "      <td>313</td>\n",
       "      <td>401</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627696365</td>\n",
       "      <td>402</td>\n",
       "      <td>758</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627759780</td>\n",
       "      <td>759</td>\n",
       "      <td>886</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040209</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627780655</td>\n",
       "      <td>887</td>\n",
       "      <td>1150</td>\n",
       "      <td>That's why there's a thing that's called no te...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>163 164 165 166 167 168 169 170 171 172 173 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040210</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627811787</td>\n",
       "      <td>1151</td>\n",
       "      <td>1533</td>\n",
       "      <td>Sometimes on the news there is either an accid...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 4</td>\n",
       "      <td>211 212 213 214 215 216 217 218 219 220 221 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040211</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627585180</td>\n",
       "      <td>1534</td>\n",
       "      <td>1602</td>\n",
       "      <td>Phones are fine to use and it's also the best ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>282 283 284 285 286 287 288 289 290 291 292 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040212</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627895668</td>\n",
       "      <td>1603</td>\n",
       "      <td>1890</td>\n",
       "      <td>If you go through a problem and you can't find...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 5</td>\n",
       "      <td>297 298 299 300 301 302 303 304 305 306 307 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040213</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1622627628524</td>\n",
       "      <td>1891</td>\n",
       "      <td>2027</td>\n",
       "      <td>The news always updated when people do somethi...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>355 356 357 358 359 360 361 362 363 364 365 36...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   discourse_id  discourse_start  discourse_end  \\\n",
       "0        423A1CA112E2  1622627660524                8            229   \n",
       "1        423A1CA112E2  1622627653021              230            312   \n",
       "2        423A1CA112E2  1622627671020              313            401   \n",
       "3        423A1CA112E2  1622627696365              402            758   \n",
       "4        423A1CA112E2  1622627759780              759            886   \n",
       "...               ...            ...              ...            ...   \n",
       "4040209  423A1CA112E2  1622627780655              887           1150   \n",
       "4040210  423A1CA112E2  1622627811787             1151           1533   \n",
       "4040211  423A1CA112E2  1622627585180             1534           1602   \n",
       "4040212  423A1CA112E2  1622627895668             1603           1890   \n",
       "4040213  423A1CA112E2  1622627628524             1891           2027   \n",
       "\n",
       "                                            discourse_text  \\\n",
       "0        Modern humans today are always on their phone....   \n",
       "1        They are some really bad consequences when stu...   \n",
       "2        Some certain areas in the United States ban ph...   \n",
       "3        When people have phones, they know about certa...   \n",
       "4        Driving is one of the way how to get around. P...   \n",
       "...                                                    ...   \n",
       "4040209  That's why there's a thing that's called no te...   \n",
       "4040210  Sometimes on the news there is either an accid...   \n",
       "4040211  Phones are fine to use and it's also the best ...   \n",
       "4040212  If you go through a problem and you can't find...   \n",
       "4040213  The news always updated when people do somethi...   \n",
       "\n",
       "               discourse_type      discourse_type_num  \\\n",
       "0                        Lead                  Lead 1   \n",
       "1                    Position              Position 1   \n",
       "2                    Evidence              Evidence 1   \n",
       "3                    Evidence              Evidence 2   \n",
       "4                       Claim                 Claim 1   \n",
       "...                       ...                     ...   \n",
       "4040209              Evidence              Evidence 3   \n",
       "4040210              Evidence              Evidence 4   \n",
       "4040211                 Claim                 Claim 2   \n",
       "4040212              Evidence              Evidence 5   \n",
       "4040213  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                          predictionstring  \n",
       "0        1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1             45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2          60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
       "3        76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
       "4        139 140 141 142 143 144 145 146 147 148 149 15...  \n",
       "...                                                    ...  \n",
       "4040209  163 164 165 166 167 168 169 170 171 172 173 17...  \n",
       "4040210  211 212 213 214 215 216 217 218 219 220 221 22...  \n",
       "4040211  282 283 284 285 286 287 288 289 290 291 292 29...  \n",
       "4040212  297 298 299 300 301 302 303 304 305 306 307 30...  \n",
       "4040213  355 356 357 358 359 360 361 362 363 364 365 36...  \n",
       "\n",
       "[290 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query('id == \"423A1CA112E2\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.042381,
     "end_time": "2022-02-06T13:44:09.137617",
     "exception": false,
     "start_time": "2022-02-06T13:44:09.095236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Kaggle gives us the following field descriptions:\n",
    "- id - ID code for essay response\n",
    "- discourse_id - ID code for discourse element\n",
    "- discourse_start - character position where discourse element begins in the essay response\n",
    "- discourse_end - character position where discourse element ends in the essay response\n",
    "- discourse_text - text of discourse element\n",
    "- discourse_type - classification of discourse element\n",
    "- discourse_type_num - enumerated class label of discourse element\n",
    "- predictionstring - the word indices of the training sample, as required for predictions\n",
    "\n",
    "The Ground Truth here is a combination of the discourse type and the prediction string. The predictionstring corresponds to the index of the words in the essay and the predicted discourse type for this sequence of words should be correct. There can be partial matches, if the correct discourse type is predicted but on a longer or shorter sequence of words than specified in the Ground Truth.\n",
    "\n",
    "As we can see, not necessarily all text of an essay is part of a discourse. In this case, the title is not part of any discourse.\n",
    "\n",
    "\n",
    "# Lenght of the discourse_text and predictionstring\n",
    "First, I would like to check if the discourse_text and the predictionstring always have the same number of words (as they should)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:09.228972Z",
     "iopub.status.busy": "2022-02-06T13:44:09.228249Z",
     "iopub.status.idle": "2022-02-06T13:44:10.19673Z",
     "shell.execute_reply": "2022-02-06T13:44:10.197224Z",
     "shell.execute_reply.started": "2022-02-06T13:05:16.753674Z"
    },
    "papermill": {
     "duration": 1.017913,
     "end_time": "2022-02-06T13:44:10.197435",
     "exception": false,
     "start_time": "2022-02-06T13:44:09.179522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_len</th>\n",
       "      <th>pred_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1622627660524</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1622627653021</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1622627671020</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1622627696365</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1622627759780</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    discourse_id                                     discourse_text  \\\n",
       "0  1622627660524  Modern humans today are always on their phone....   \n",
       "1  1622627653021  They are some really bad consequences when stu...   \n",
       "2  1622627671020  Some certain areas in the United States ban ph...   \n",
       "3  1622627696365  When people have phones, they know about certa...   \n",
       "4  1622627759780  Driving is one of the way how to get around. P...   \n",
       "\n",
       "  discourse_type                                   predictionstring  \\\n",
       "0           Lead  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...   \n",
       "1       Position       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59   \n",
       "2       Evidence    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75   \n",
       "3       Evidence  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...   \n",
       "4          Claim  139 140 141 142 143 144 145 146 147 148 149 15...   \n",
       "\n",
       "   discourse_len  pred_len  \n",
       "0             44        44  \n",
       "1             15        15  \n",
       "2             16        16  \n",
       "3             63        63  \n",
       "4             24        24  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add columns\n",
    "train[\"discourse_len\"] = train[\"discourse_text\"].apply(lambda x: len(x.split()))\n",
    "train[\"pred_len\"] = train[\"predictionstring\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "cols_to_display = ['discourse_id', 'discourse_text', 'discourse_type','predictionstring', 'discourse_len', 'pred_len']\n",
    "train[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04285,
     "end_time": "2022-02-06T13:44:10.283414",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.240564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Is this always correct? No, I find 468 discourses where this goes wrong (by one word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:10.372053Z",
     "iopub.status.busy": "2022-02-06T13:44:10.371379Z",
     "iopub.status.idle": "2022-02-06T13:44:10.39373Z",
     "shell.execute_reply": "2022-02-06T13:44:10.394269Z",
     "shell.execute_reply.started": "2022-02-06T13:05:17.732898Z"
    },
    "papermill": {
     "duration": 0.068268,
     "end_time": "2022-02-06T13:44:10.394488",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.32622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of discourses is 4184497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>discourse_len</th>\n",
       "      <th>pred_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1622473475289</td>\n",
       "      <td>if we would just make stricker laws for phone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>303 304 305 306 307 308 309 310 311 312 313 31...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>1622564912260</td>\n",
       "      <td>for navigation to wherever they are going</td>\n",
       "      <td>Claim</td>\n",
       "      <td>105 106 107 108 109 110 111 112</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1622992466917</td>\n",
       "      <td>People should not be able to use cell phones w...</td>\n",
       "      <td>Position</td>\n",
       "      <td>22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>1622992280991</td>\n",
       "      <td>First, cell phones are a benefit and allows ev...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1622992426147</td>\n",
       "      <td>Kids, teenagers, adults, even grandparents hav...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>90 91 92 93 94 95 96 97 98 99 100 101 102 103 ...</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182811</th>\n",
       "      <td>1617826841342</td>\n",
       "      <td>seeking people's opinions on making a choice i...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>563 564 565 566 567 568 569 570 571 572 573 57...</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183395</th>\n",
       "      <td>1617887956153</td>\n",
       "      <td>i feel like for the bst advice ask more then o...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>185 186 187 188 189 190 191 192 193 194 195 19...</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183431</th>\n",
       "      <td>1617652582742</td>\n",
       "      <td>, asking for advice from multiple people will ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>467 468 469 470 471 472 473 474 475 476 477 47...</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183515</th>\n",
       "      <td>1618286838241</td>\n",
       "      <td>Seeking multiple opinions can help make a bett...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>159 160 161 162 163 164 165 166 167 168 169 17...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184047</th>\n",
       "      <td>1617811065126</td>\n",
       "      <td>Asking for advice is a way of getting through ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          discourse_id                                     discourse_text  \\\n",
       "107      1622473475289  if we would just make stricker laws for phone ...   \n",
       "1025     1622564912260        for navigation to wherever they are going     \n",
       "1525     1622992466917  People should not be able to use cell phones w...   \n",
       "1526     1622992280991  First, cell phones are a benefit and allows ev...   \n",
       "1527     1622992426147  Kids, teenagers, adults, even grandparents hav...   \n",
       "...                ...                                                ...   \n",
       "4182811  1617826841342  seeking people's opinions on making a choice i...   \n",
       "4183395  1617887956153  i feel like for the bst advice ask more then o...   \n",
       "4183431  1617652582742  , asking for advice from multiple people will ...   \n",
       "4183515  1618286838241  Seeking multiple opinions can help make a bett...   \n",
       "4184047  1617811065126  Asking for advice is a way of getting through ...   \n",
       "\n",
       "               discourse_type  \\\n",
       "107      Concluding Statement   \n",
       "1025                    Claim   \n",
       "1525                 Position   \n",
       "1526                    Claim   \n",
       "1527                 Evidence   \n",
       "...                       ...   \n",
       "4182811  Concluding Statement   \n",
       "4183395              Evidence   \n",
       "4183431  Concluding Statement   \n",
       "4183515                 Claim   \n",
       "4184047                 Claim   \n",
       "\n",
       "                                          predictionstring  discourse_len  \\\n",
       "107      303 304 305 306 307 308 309 310 311 312 313 31...             19   \n",
       "1025                       105 106 107 108 109 110 111 112              7   \n",
       "1525     22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 3...             47   \n",
       "1526     69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 8...             21   \n",
       "1527     90 91 92 93 94 95 96 97 98 99 100 101 102 103 ...             78   \n",
       "...                                                    ...            ...   \n",
       "4182811  563 564 565 566 567 568 569 570 571 572 573 57...             51   \n",
       "4183395  185 186 187 188 189 190 191 192 193 194 195 19...             83   \n",
       "4183431  467 468 469 470 471 472 473 474 475 476 477 47...             84   \n",
       "4183515  159 160 161 162 163 164 165 166 167 168 169 17...             15   \n",
       "4184047  3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20...             21   \n",
       "\n",
       "         pred_len  \n",
       "107            18  \n",
       "1025            8  \n",
       "1525           48  \n",
       "1526           22  \n",
       "1527           79  \n",
       "...           ...  \n",
       "4182811        50  \n",
       "4183395        82  \n",
       "4183431        83  \n",
       "4183515        16  \n",
       "4184047        22  \n",
       "\n",
       "[13572 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The total number of discourses is {len(train)}\")\n",
    "train.query('discourse_len != pred_len')[cols_to_display]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043749,
     "end_time": "2022-02-06T13:44:10.482174",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.438425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:10.579865Z",
     "iopub.status.busy": "2022-02-06T13:44:10.578825Z",
     "iopub.status.idle": "2022-02-06T13:44:10.59474Z",
     "shell.execute_reply": "2022-02-06T13:44:10.594007Z",
     "shell.execute_reply.started": "2022-02-06T13:05:17.761778Z"
    },
    "papermill": {
     "duration": 0.067548,
     "end_time": "2022-02-06T13:44:10.594895",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.527347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if we would just make stricker laws for phone an driving the people would stop because of the consequences.      \n",
      "['if', 'we', 'would', 'just', 'make', 'stricker', 'laws', 'for', 'phone', 'an', 'driving', 'the', 'people', 'would', 'stop', 'because', 'of', 'the', 'consequences.']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(train.query('discourse_id == 1622473475289')['discourse_text'].values[0])\n",
    "print(train.query('discourse_id == 1622473475289')['discourse_text'].values[0].split())\n",
    "print(len(train.query('discourse_id == 1622473475289')['discourse_text'].values[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043589,
     "end_time": "2022-02-06T13:44:10.683438",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.639849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The length of 19 words seems correct to me, and the length of the predictionstring also really seems to be 18. Something to keep in mind.\n",
    "\n",
    "**Update:** the answers to this can be found in discussion topic: [Mystery Solved - Discrepancy Between PredictionString and DiscourseText](https://www.kaggle.com/c/feedback-prize-2021/discussion/297591)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:10.783115Z",
     "iopub.status.busy": "2022-02-06T13:44:10.78042Z",
     "iopub.status.idle": "2022-02-06T13:44:10.797854Z",
     "shell.execute_reply": "2022-02-06T13:44:10.798403Z",
     "shell.execute_reply.started": "2022-02-06T13:05:17.785767Z"
    },
    "papermill": {
     "duration": 0.071035,
     "end_time": "2022-02-06T13:44:10.798583",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.727548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320\n",
      "['303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(train.query('discourse_id == 1622473475289')['predictionstring'].values[0])\n",
    "print(train.query('discourse_id == 1622473475289')['predictionstring'].values[0].split())\n",
    "print(len(train.query('discourse_id == 1622473475289')['predictionstring'].values[0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044746,
     "end_time": "2022-02-06T13:44:10.888764",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.844018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Length and frequency and relative position per discourse_type\n",
    "\n",
    "Is there a correlation between the length of a discourse and the class (discourse_type)? Yes, there is. Evidence is the longest discount type on average. When looking at the frequencies of occurence, we see that Counterclaim and Rebuttal are relatively rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:10.997198Z",
     "iopub.status.busy": "2022-02-06T13:44:10.989647Z",
     "iopub.status.idle": "2022-02-06T13:44:11.571834Z",
     "shell.execute_reply": "2022-02-06T13:44:11.572395Z",
     "shell.execute_reply.started": "2022-02-06T13:05:17.807334Z"
    },
    "papermill": {
     "duration": 0.637721,
     "end_time": "2022-02-06T13:44:11.572582",
     "exception": false,
     "start_time": "2022-02-06T13:44:10.934861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEFANOS: Disable plotting\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# ax1 = fig.add_subplot(211)\n",
    "# ax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values().plot(kind=\"barh\")\n",
    "ax1 = train.groupby('discourse_type')['discourse_len'].mean().sort_values()\n",
    "# ax1.set_title(\"Average number of words versus Discourse Type\", fontsize=14, fontweight = 'bold')\n",
    "# ax1.set_xlabel(\"Average number of words\", fontsize = 10)\n",
    "# ax1.set_ylabel(\"\")\n",
    "\n",
    "# ax2 = fig.add_subplot(212)\n",
    "# ax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values().plot(kind=\"barh\")\n",
    "ax2 = train.groupby('discourse_type')['discourse_type'].count().sort_values()\n",
    "# ax2.get_xaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\n",
    "# ax2.set_title(\"Frequency of Discourse Type in all essays\", fontsize=14, fontweight = 'bold')\n",
    "# ax2.set_xlabel(\"Frequency\", fontsize = 10)\n",
    "# ax2.set_ylabel(\"\")\n",
    "\n",
    "# plt.tight_layout(pad=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04586,
     "end_time": "2022-02-06T13:44:11.665568",
     "exception": false,
     "start_time": "2022-02-06T13:44:11.619708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We do have the field discourse_type_num. We see that Evidence1, Position1 and Claim1 are almost always there in an essay. Most students also had at least one Concluding Statement. What's surprising to me is that a Lead is missing in about 40% of the essays (Lead 1 is found in almost 60% of the essays).\n",
    "\n",
    "The graph only plots discourse_type_nums which are found in at least 3% of the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:11.763683Z",
     "iopub.status.busy": "2022-02-06T13:44:11.762899Z",
     "iopub.status.idle": "2022-02-06T13:44:12.196337Z",
     "shell.execute_reply": "2022-02-06T13:44:12.196849Z",
     "shell.execute_reply.started": "2022-02-06T13:05:18.371438Z"
    },
    "papermill": {
     "duration": 0.485511,
     "end_time": "2022-02-06T13:44:12.197026",
     "exception": false,
     "start_time": "2022-02-06T13:44:11.711515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEFANOS: Disable plotting\n",
    "# fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "# av_per_essay = train['discourse_type_num'].value_counts(ascending = True).rename_axis('discourse_type_num').reset_index(name='count')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "av_per_essay = train['discourse_type_num'].value_counts(ascending = True)\n",
    "av_per_essay.index.name = \"discourse_type_num\"\n",
    "av_per_essay = av_per_essay.reset_index(name='count')\n",
    "\n",
    "av_per_essay['perc'] = round((av_per_essay['count'] / train.id.nunique()),3)\n",
    "av_per_essay = av_per_essay.set_index('discourse_type_num')\n",
    "# ax = av_per_essay.query('perc > 0.03')['perc'].plot(kind=\"barh\")\n",
    "ax = av_per_essay.query('perc > 0.03')['perc']\n",
    "# ax.set_title(\"discourse_type_num: Percent present in essays\", fontsize=20, fontweight = 'bold')\n",
    "# ax.bar_label(ax.containers[0], label_type=\"edge\")\n",
    "# ax.set_xlabel(\"Percent\")\n",
    "# ax.set_ylabel(\"\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049391,
     "end_time": "2022-02-06T13:44:12.295102",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.245711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below you can see a plot with the average positions of the discourse start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:12.414272Z",
     "iopub.status.busy": "2022-02-06T13:44:12.407154Z",
     "iopub.status.idle": "2022-02-06T13:44:12.632931Z",
     "shell.execute_reply": "2022-02-06T13:44:12.632405Z",
     "shell.execute_reply.started": "2022-02-06T13:05:18.81135Z"
    },
    "papermill": {
     "duration": 0.28928,
     "end_time": "2022-02-06T13:44:12.633078",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.343798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = train.groupby(\"discourse_type\")[['discourse_end', 'discourse_start']].mean().reset_index().sort_values(by = 'discourse_start', ascending = False)\n",
    "# data.plot(x='discourse_type',\n",
    "#         kind='barh',\n",
    "#         stacked=False,\n",
    "#         title='Average start and end position absolute',\n",
    "#         figsize=(12,4))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051099,
     "end_time": "2022-02-06T13:44:12.734248",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.683149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am also interested in the relative positions of discourse types with the essays. Below you can see the distributions of the discourse types of the first and last discourses identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:12.848173Z",
     "iopub.status.busy": "2022-02-06T13:44:12.847474Z",
     "iopub.status.idle": "2022-02-06T13:44:12.945592Z",
     "shell.execute_reply": "2022-02-06T13:44:12.945025Z",
     "shell.execute_reply.started": "2022-02-06T13:05:19.092044Z"
    },
    "papermill": {
     "duration": 0.161208,
     "end_time": "2022-02-06T13:44:12.945746",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.784538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>counts_first</th>\n",
       "      <th>percent_first</th>\n",
       "      <th>counts_last</th>\n",
       "      <th>percent_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead</td>\n",
       "      <td>9298</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Position</td>\n",
       "      <td>5760</td>\n",
       "      <td>0.37</td>\n",
       "      <td>521</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evidence</td>\n",
       "      <td>261</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1609</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claim</td>\n",
       "      <td>255</td>\n",
       "      <td>0.02</td>\n",
       "      <td>285</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12993</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         discourse_type  counts_first  percent_first  counts_last  \\\n",
       "0                  Lead          9298           0.60            3   \n",
       "1              Position          5760           0.37          521   \n",
       "2              Evidence           261           0.02         1609   \n",
       "3                 Claim           255           0.02          285   \n",
       "4          Counterclaim            19           0.00           30   \n",
       "5  Concluding Statement             1           0.00        12993   \n",
       "\n",
       "   percent_last  \n",
       "0          0.00  \n",
       "1          0.03  \n",
       "2          0.10  \n",
       "3          0.02  \n",
       "4          0.00  \n",
       "5          0.83  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "#train_first = train.drop_duplicates(subset = \"id\", keep = \"first\").discourse_type.value_counts().rename_axis('discourse_type').reset_index(name='counts_first')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "train_first = train.drop_duplicates(subset = \"id\", keep = \"first\").discourse_type.value_counts()\n",
    "train_first.index.name = 'discourse_type'\n",
    "train_first = train_first.reset_index(name='counts_first')\n",
    "\n",
    "train_first['percent_first'] = round((train_first['counts_first']/train.id.nunique()),2)\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "#### ORIGINAL ####\n",
    "# train_last = train.drop_duplicates(subset = \"id\", keep = \"last\").discourse_type.value_counts().rename_axis('discourse_type').reset_index(name='counts_last')\n",
    "#### CAN RUN WITH MODIN ####\n",
    "train_last = train.drop_duplicates(subset = \"id\", keep = \"last\").discourse_type.value_counts()\n",
    "train_last.index.name = 'discourse_type'\n",
    "train_last = train_last.reset_index(name='counts_last')\n",
    "\n",
    "\n",
    "train_last['percent_last'] = round((train_last['counts_last']/train.id.nunique()),2)\n",
    "train_first_last = train_first.merge(train_last, on = \"discourse_type\", how = \"left\")\n",
    "train_first_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052158,
     "end_time": "2022-02-06T13:44:13.049027",
     "exception": false,
     "start_time": "2022-02-06T13:44:12.996869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We also know that a Lead is missing in around 40% of the essays. Below you can see that if there is a Lead, it's almost always the first discourse identified in an essay (Lead 2 is very rare anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:44:13.155223Z",
     "iopub.status.busy": "2022-02-06T13:44:13.154535Z",
     "iopub.status.idle": "2022-02-06T13:45:55.77051Z",
     "shell.execute_reply": "2022-02-06T13:45:55.769936Z",
     "shell.execute_reply.started": "2022-02-06T13:05:19.200023Z"
    },
    "papermill": {
     "duration": 102.669421,
     "end_time": "2022-02-06T13:45:55.770684",
     "exception": false,
     "start_time": "2022-02-06T13:44:13.101263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e50be351234378a631defc28fb6682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4184496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7fb11ff0e4d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['discourse_nr'] = 1\n",
    "counter = 1\n",
    "\n",
    "for i in tqdm(range(1, len(train))):\n",
    "    if train.loc[i, 'id'] == train.loc[i-1, 'id']:\n",
    "        counter += 1\n",
    "        train.loc[i, 'discourse_nr'] = counter\n",
    "    else:\n",
    "        counter = 1\n",
    "        train.loc[i, 'discourse_nr'] = counter\n",
    "\n",
    "#if you are interested in other discourse_types you can add them to the list in df.query\n",
    "# STEFANOS-DISABLE-FOR-MODIN:\n",
    "# It seems you cannot call things on top of a groupby.\n",
    "### ORIGINAL\n",
    "# train.query('discourse_type in [\"Lead\"]').groupby('discourse_type_num')['discourse_nr'].value_counts().to_frame('occurences')\n",
    "### COMPATIBLE WITH MODIN:\n",
    "train.query('discourse_type in [\"Lead\"]').groupby('discourse_type_num')['discourse_nr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052857,
     "end_time": "2022-02-06T13:45:55.87624",
     "exception": false,
     "start_time": "2022-02-06T13:45:55.823383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Investigation the gaps between Annotations (text not used as discourse_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052078,
     "end_time": "2022-02-06T13:45:55.98035",
     "exception": false,
     "start_time": "2022-02-06T13:45:55.928272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Just taking the last discourse_end in train is not entirely correct as a last piece of text may not have been used as a discourse. Therefore, I will go through the essays to find the real ends. Eh....until I remembered that Rob Mulla already did that in the excellent EDA [Student Writing Competition [Twitch Stream]](https://www.kaggle.com/robikscube/student-writing-competition-twitch) ;-). Please upvote his notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:45:56.119724Z",
     "iopub.status.busy": "2022-02-06T13:45:56.11886Z",
     "iopub.status.idle": "2022-02-06T13:47:08.609974Z",
     "shell.execute_reply": "2022-02-06T13:47:08.609204Z",
     "shell.execute_reply.started": "2022-02-06T13:06:53.860062Z"
    },
    "papermill": {
     "duration": 72.576941,
     "end_time": "2022-02-06T13:47:08.610152",
     "exception": false,
     "start_time": "2022-02-06T13:45:56.033211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f7158e1b1f4e4cb42260f49d25cc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this code chunk is copied from Rob Mulla\n",
    "len_dict = {}\n",
    "word_dict = {}\n",
    "for t in tqdm(train_txt):\n",
    "    with open(t, \"r\") as txt_file:\n",
    "        myid = t.split(\"/\")[-1].replace(\".txt\", \"\")\n",
    "        data = txt_file.read()\n",
    "        mylen = len(data.strip())\n",
    "        myword = len(data.split())\n",
    "        len_dict[myid] = mylen\n",
    "        word_dict[myid] = myword\n",
    "train[\"essay_len\"] = train[\"id\"].map(len_dict)\n",
    "train[\"essay_words\"] = train[\"id\"].map(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.054548,
     "end_time": "2022-02-06T13:47:08.720231",
     "exception": false,
     "start_time": "2022-02-06T13:47:08.665683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When comparing the discourse_end of the last discourse in each essay, we see that the discourse_end is sometimes larger than the essay_len. This cannot be right, but I will assume that those are last pieces of text in the essay indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:08.834233Z",
     "iopub.status.busy": "2022-02-06T13:47:08.833512Z",
     "iopub.status.idle": "2022-02-06T13:47:44.055736Z",
     "shell.execute_reply": "2022-02-06T13:47:44.056207Z",
     "shell.execute_reply.started": "2022-02-06T13:07:43.684306Z"
    },
    "papermill": {
     "duration": 35.284433,
     "end_time": "2022-02-06T13:47:44.056432",
     "exception": false,
     "start_time": "2022-02-06T13:47:08.771999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf6859a71a94bf6b7d1792a8911091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4184496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#initialize column\n",
    "train['gap_length'] = np.nan\n",
    "\n",
    "#set the first one\n",
    "train.loc[0, 'gap_length'] = 7 #discourse start - 1 (previous end is always -1)\n",
    "\n",
    "#loop over rest\n",
    "for i in tqdm(range(1, len(train))):\n",
    "    #gap if difference is not 1 within an essay\n",
    "    if ((train.loc[i, \"id\"] == train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] > 1)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] - train.loc[i-1, \"discourse_end\"] - 2\n",
    "        #minus 2 as the previous end is always -1 and the previous start always +1\n",
    "    #gap if the first discourse of an new essay does not start at 0\n",
    "    elif ((train.loc[i, \"id\"] != train.loc[i-1, \"id\"])\\\n",
    "        and (train.loc[i, \"discourse_start\"] != 0)):\n",
    "        train.loc[i, 'gap_length'] = train.loc[i, \"discourse_start\"] -1\n",
    "\n",
    "\n",
    " #is there any text after the last discourse of an essay?\n",
    "last_ones = train.drop_duplicates(subset=\"id\", keep='last')\n",
    "last_ones['gap_end_length'] = np.where((last_ones.discourse_end < last_ones.essay_len),\\\n",
    "                                       (last_ones.essay_len - last_ones.discourse_end),\\\n",
    "                                       np.nan)\n",
    "\n",
    "cols_to_merge = ['id', 'discourse_id', 'gap_end_length']\n",
    "train = train.merge(last_ones[cols_to_merge], on = [\"id\", \"discourse_id\"], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:44.168385Z",
     "iopub.status.busy": "2022-02-06T13:47:44.167673Z",
     "iopub.status.idle": "2022-02-06T13:47:44.228946Z",
     "shell.execute_reply": "2022-02-06T13:47:44.229452Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.021319Z"
    },
    "papermill": {
     "duration": 0.119834,
     "end_time": "2022-02-06T13:47:44.229623",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.109789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>essay_len</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>gap_end_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>Lead</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>318</td>\n",
       "      <td>515</td>\n",
       "      <td>Position</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>684</td>\n",
       "      <td>692</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>167.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>693</td>\n",
       "      <td>710</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>714</td>\n",
       "      <td>724</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184483</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2029</td>\n",
       "      <td>2123</td>\n",
       "      <td>Claim</td>\n",
       "      <td>3140</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184484</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2123</td>\n",
       "      <td>2702</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184485</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2703</td>\n",
       "      <td>2799</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184486</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2817</td>\n",
       "      <td>2907</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>3140</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4184487</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>2907</td>\n",
       "      <td>3140</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>3140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  discourse_start  discourse_end        discourse_type  \\\n",
       "144270   AFEC37C2D43F                0            317                  Lead   \n",
       "144271   AFEC37C2D43F              318            515              Position   \n",
       "144272   AFEC37C2D43F              684            692                 Claim   \n",
       "144273   AFEC37C2D43F              693            710                 Claim   \n",
       "144274   AFEC37C2D43F              714            724                 Claim   \n",
       "...               ...              ...            ...                   ...   \n",
       "4184483  AFEC37C2D43F             2029           2123                 Claim   \n",
       "4184484  AFEC37C2D43F             2123           2702              Evidence   \n",
       "4184485  AFEC37C2D43F             2703           2799          Counterclaim   \n",
       "4184486  AFEC37C2D43F             2817           2907              Rebuttal   \n",
       "4184487  AFEC37C2D43F             2907           3140  Concluding Statement   \n",
       "\n",
       "         essay_len  gap_length  gap_end_length  \n",
       "144270        3140         NaN             NaN  \n",
       "144271        3140         NaN             NaN  \n",
       "144272        3140       167.0             NaN  \n",
       "144273        3140         NaN             NaN  \n",
       "144274        3140         2.0             NaN  \n",
       "...            ...         ...             ...  \n",
       "4184483       3140         8.0             NaN  \n",
       "4184484       3140         NaN             NaN  \n",
       "4184485       3140         NaN             NaN  \n",
       "4184486       3140        16.0             NaN  \n",
       "4184487       3140         NaN             NaN  \n",
       "\n",
       "[406 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display an example\n",
    "cols_to_display = ['id', 'discourse_start', 'discourse_end', 'discourse_type', 'essay_len', 'gap_length', 'gap_end_length']\n",
    "train[cols_to_display].query('id == \"AFEC37C2D43F\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:44.341822Z",
     "iopub.status.busy": "2022-02-06T13:47:44.339642Z",
     "iopub.status.idle": "2022-02-06T13:47:44.361949Z",
     "shell.execute_reply": "2022-02-06T13:47:44.362993Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.087847Z"
    },
    "papermill": {
     "duration": 0.080122,
     "end_time": "2022-02-06T13:47:44.363283",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.283161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Besides the 4184497 discourse texts, there are 932698 pieces of text not classified.\n"
     ]
    }
   ],
   "source": [
    "#how many pieces of tekst are not used as discourses?\n",
    "print(f\"Besides the {len(train)} discourse texts, there are {len(train.query('gap_length.notna()', engine='python'))+ len(train.query('gap_end_length.notna()', engine='python'))} pieces of text not classified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052699,
     "end_time": "2022-02-06T13:47:44.470668",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.417969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Although the gaps in the example above are small, we do have huge gaps in a number of essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:44.581753Z",
     "iopub.status.busy": "2022-02-06T13:47:44.58105Z",
     "iopub.status.idle": "2022-02-06T13:47:44.628395Z",
     "shell.execute_reply": "2022-02-06T13:47:44.62775Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.109435Z"
    },
    "papermill": {
     "duration": 0.103633,
     "end_time": "2022-02-06T13:47:44.628562",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.524929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEFANOS: We have to change code slightly because we use less data. The original code plugs constant values\n",
    "# which depend on some data existing.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    _IREWR_tmp = train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()\n",
    "    _IREWR_plug_2 = _IREWR_tmp.iloc[0][\"id\"]\n",
    "    _IREWR_tmp\n",
    "else:\n",
    "    # Original\n",
    "    train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:44.743136Z",
     "iopub.status.busy": "2022-02-06T13:47:44.742475Z",
     "iopub.status.idle": "2022-02-06T13:47:44.785114Z",
     "shell.execute_reply": "2022-02-06T13:47:44.784513Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.159489Z"
    },
    "papermill": {
     "duration": 0.101666,
     "end_time": "2022-02-06T13:47:44.785265",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.683599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEFANOS: We have to change code slightly because we use less data. The original code plugs constant values\n",
    "# which depend on some data existing.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    _IREWR_tmp2 = train.sort_values(by = \"gap_end_length\", ascending = False)[cols_to_display].head()\n",
    "    _IREWR_plug_1 = _IREWR_tmp2.iloc[1][\"id\"]\n",
    "    _IREWR_tmp2\n",
    "else:\n",
    "    train.sort_values(by = \"gap_length\", ascending = False)[cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056313,
     "end_time": "2022-02-06T13:47:44.897591",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.841278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, you can see a histogram of the length of all gaps with the outliers taken out (all gaps longer than 300 characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:45.016599Z",
     "iopub.status.busy": "2022-02-06T13:47:45.015819Z",
     "iopub.status.idle": "2022-02-06T13:47:45.392704Z",
     "shell.execute_reply": "2022-02-06T13:47:45.392129Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.200828Z"
    },
    "papermill": {
     "duration": 0.440058,
     "end_time": "2022-02-06T13:47:45.392861",
     "exception": false,
     "start_time": "2022-02-06T13:47:44.952803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_gaps = (train.gap_length[~train.gap_length.isna()]).append((train.gap_end_length[~train.gap_end_length.isna()]), ignore_index= True)\n",
    "#filter outliers\n",
    "all_gaps = all_gaps[all_gaps<300]\n",
    "# fig = plt.figure(figsize=(12,6))\n",
    "# all_gaps.plot.hist(bins=100)\n",
    "# plt.title(\"Histogram of gap length (gaps up to 300 characters only)\")\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.xlabel(\"Length of gaps in characters\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056164,
     "end_time": "2022-02-06T13:47:45.505315",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.449151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Are there many really bad essays (large percentage of text not classified)?\n",
    "Yes, we do have those. Some have around 90% of text not classified as one of the discourse types.\n",
    "\n",
    "Regarding the one with gap_end_length 7348: I found out that this student just copied and pasted the same texts multiple times in his/her essay. See discussion topic: [Finding: essay with all text repeated many times](https://www.kaggle.com/c/feedback-prize-2021/discussion/298193)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:45.621717Z",
     "iopub.status.busy": "2022-02-06T13:47:45.620451Z",
     "iopub.status.idle": "2022-02-06T13:47:45.686258Z",
     "shell.execute_reply": "2022-02-06T13:47:45.685711Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.607463Z"
    },
    "papermill": {
     "duration": 0.125624,
     "end_time": "2022-02-06T13:47:45.686445",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.560821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_len</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>gap_end_length</th>\n",
       "      <th>perc_not_classified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C278EDC82048</th>\n",
       "      <td>8015</td>\n",
       "      <td>377.0</td>\n",
       "      <td>213092.0</td>\n",
       "      <td>26.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129497C3E0FC</th>\n",
       "      <td>3616</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>92017.0</td>\n",
       "      <td>26.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F5EE08CB44B9</th>\n",
       "      <td>3022</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>77401.0</td>\n",
       "      <td>26.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F45B396E0A01</th>\n",
       "      <td>1865</td>\n",
       "      <td>48053.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B7C17E1993BA</th>\n",
       "      <td>3569</td>\n",
       "      <td>32190.0</td>\n",
       "      <td>59740.0</td>\n",
       "      <td>25.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              essay_len  gap_length  gap_end_length  perc_not_classified\n",
       "id                                                                      \n",
       "C278EDC82048       8015       377.0        213092.0                26.63\n",
       "129497C3E0FC       3616      3770.0         92017.0                26.49\n",
       "F5EE08CB44B9       3022      1798.0         77401.0                26.21\n",
       "F45B396E0A01       1865     48053.0             0.0                25.77\n",
       "B7C17E1993BA       3569     32190.0         59740.0                25.76"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_gaps = train.groupby('id').agg({'essay_len': 'first',\\\n",
    "                                               'gap_length': 'sum',\\\n",
    "                                               'gap_end_length': 'sum'})\n",
    "total_gaps['perc_not_classified'] = round(((total_gaps.gap_length + total_gaps.gap_end_length)/total_gaps.essay_len),2)\n",
    "\n",
    "total_gaps.sort_values(by = 'perc_not_classified', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057853,
     "end_time": "2022-02-06T13:47:45.801995",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.744142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Color printing essays including the gaps\n",
    "\n",
    "I saw  a very pretty way to do this in the Notebook made by Sanskar Hasija (https://www.kaggle.com/odins0n/feedback-prize-eda). The code is nice but did not print the gaps yet. Below, I make a function that adds all gaps in an essay as rows with discourse type \"Nothing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:45.926835Z",
     "iopub.status.busy": "2022-02-06T13:47:45.926051Z",
     "iopub.status.idle": "2022-02-06T13:47:45.933372Z",
     "shell.execute_reply": "2022-02-06T13:47:45.933916Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.679074Z"
    },
    "papermill": {
     "duration": 0.0748,
     "end_time": "2022-02-06T13:47:45.934099",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.859299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_gap_rows(essay):\n",
    "    cols_to_keep = ['discourse_start', 'discourse_end', 'discourse_type', 'gap_length', 'gap_end_length']\n",
    "    df_essay = train.query('id == @essay')[cols_to_keep].reset_index(drop = True)\n",
    "    \n",
    "    print(df_essay)\n",
    "\n",
    "    #index new row\n",
    "    insert_row = len(df_essay)\n",
    "   \n",
    "    for i in range(1, len(df_essay)):          \n",
    "        if df_essay.loc[i,\"gap_length\"] >0:\n",
    "            if i == 0:\n",
    "                start = 0 #as there is no i-1 for first row\n",
    "                end = df_essay.loc[0, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "            else:\n",
    "                start = df_essay.loc[i-1, \"discourse_end\"] + 1\n",
    "                end = df_essay.loc[i, 'discourse_start'] -1\n",
    "                disc_type = \"Nothing\"\n",
    "                gap_end = np.nan\n",
    "                gap = np.nan\n",
    "                df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "                insert_row += 1\n",
    "\n",
    "    df_essay = df_essay.sort_values(by = \"discourse_start\").reset_index(drop=True)\n",
    "\n",
    "    #add gap at end\n",
    "    if df_essay.loc[(len(df_essay)-1),'gap_end_length'] > 0:\n",
    "        start = df_essay.loc[(len(df_essay)-1), \"discourse_end\"] + 1\n",
    "        end = start + df_essay.loc[(len(df_essay)-1), 'gap_end_length']\n",
    "        disc_type = \"Nothing\"\n",
    "        gap_end = np.nan\n",
    "        gap = np.nan\n",
    "        df_essay.loc[insert_row] = [start, end, disc_type, gap, gap_end]\n",
    "        \n",
    "    return(df_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:46.052378Z",
     "iopub.status.busy": "2022-02-06T13:47:46.051649Z",
     "iopub.status.idle": "2022-02-06T13:47:46.087398Z",
     "shell.execute_reply": "2022-02-06T13:47:46.087942Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.698052Z"
    },
    "papermill": {
     "duration": 0.096602,
     "end_time": "2022-02-06T13:47:46.088119",
     "exception": false,
     "start_time": "2022-02-06T13:47:45.991517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     discourse_start  discourse_end discourse_type  gap_length  gap_end_length\n",
      "0                  0             57           Lead         NaN             NaN\n",
      "1                 58            111          Claim         NaN             NaN\n",
      "2                121            137          Claim         8.0             NaN\n",
      "3                158            281   Counterclaim        19.0             NaN\n",
      "4                386            443       Position       103.0          3173.0\n",
      "..               ...            ...            ...         ...             ...\n",
      "140                0             57           Lead         NaN             NaN\n",
      "141               58            111          Claim         NaN             NaN\n",
      "142              121            137          Claim         8.0             NaN\n",
      "143              158            281   Counterclaim        19.0             NaN\n",
      "144              386            443       Position       103.0          3173.0\n",
      "\n",
      "[145 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: See above.\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    add_gap_rows(_IREWR_plug_1)\n",
    "else:\n",
    "    add_gap_rows(\"129497C3E0FC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058607,
     "end_time": "2022-02-06T13:47:46.204803",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.146196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This enables me to make a function that uses the code made by Sanskar Hasija to color print an essay including the gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:46.336185Z",
     "iopub.status.busy": "2022-02-06T13:47:46.334964Z",
     "iopub.status.idle": "2022-02-06T13:47:46.33727Z",
     "shell.execute_reply": "2022-02-06T13:47:46.337916Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.753218Z"
    },
    "papermill": {
     "duration": 0.073031,
     "end_time": "2022-02-06T13:47:46.338095",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.265064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_colored_essay(essay):\n",
    "    df_essay = add_gap_rows(essay)\n",
    "    #code from https://www.kaggle.com/odins0n/feedback-prize-eda, but adjusted to df_essay\n",
    "    essay_file = \"../input/feedback-prize-2021/train/\" + essay + \".txt\"\n",
    "\n",
    "    ents = []\n",
    "    for i, row in df_essay.iterrows():\n",
    "        ents.append({\n",
    "                        'start': int(row['discourse_start']), \n",
    "                         'end': int(row['discourse_end']), \n",
    "                         'label': row['discourse_type']\n",
    "                    })\n",
    "\n",
    "    with open(essay_file, 'r') as file: data = file.read()\n",
    "\n",
    "    doc2 = {\n",
    "        \"text\": data,\n",
    "        \"ents\": ents,\n",
    "    }\n",
    "\n",
    "    colors = {'Lead': '#EE11D0','Position': '#AB4DE1','Claim': '#1EDE71','Evidence': '#33FAFA','Counterclaim': '#4253C1','Concluding Statement': 'yellow','Rebuttal': 'red'}\n",
    "    options = {\"ents\": df_essay.discourse_type.unique().tolist(), \"colors\": colors}\n",
    "    # STEFANOS: Disable plotting-like code.\n",
    "#     spacy.displacy.render(doc2, style=\"ent\", options=options, manual=True, jupyter=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:46.459621Z",
     "iopub.status.busy": "2022-02-06T13:47:46.458931Z",
     "iopub.status.idle": "2022-02-06T13:47:46.48262Z",
     "shell.execute_reply": "2022-02-06T13:47:46.483249Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.765083Z"
    },
    "papermill": {
     "duration": 0.086354,
     "end_time": "2022-02-06T13:47:46.483456",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.397102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     discourse_start  discourse_end        discourse_type  gap_length  \\\n",
      "0                  0             77              Position         NaN   \n",
      "1                 77            455              Evidence         NaN   \n",
      "2                456           1014              Evidence         NaN   \n",
      "3               1015           1130                 Claim         NaN   \n",
      "4               3377           3846  Concluding Statement      2245.0   \n",
      "..               ...            ...                   ...         ...   \n",
      "140                0             77              Position         NaN   \n",
      "141               77            455              Evidence         NaN   \n",
      "142              456           1014              Evidence         NaN   \n",
      "143             1015           1130                 Claim         NaN   \n",
      "144             3377           3846  Concluding Statement      2245.0   \n",
      "\n",
      "     gap_end_length  \n",
      "0               NaN  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "..              ...  \n",
      "140             NaN  \n",
      "141             NaN  \n",
      "142             NaN  \n",
      "143             NaN  \n",
      "144             NaN  \n",
      "\n",
      "[145 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# STEFANOS: See above.\n",
    "# print_colored_essay(\"7330313ED3F0\")\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    print_colored_essay(_IREWR_plug_2)\n",
    "else:\n",
    "    print_colored_essay(\"7330313ED3F0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05854,
     "end_time": "2022-02-06T13:47:46.600585",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.542045",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Most used words per Discourse Type\n",
    "\n",
    "Initially, I did a manual effort to find out which single words were used most often.I took out stopwords, converted all text to lowercase, but left in the punctuation. I also took out some extra words that were all over the place in the figures for each discourse_type. After this effort, I was not sure how useful this is. One thing to notice is that \"however,\" is used a lot in Rebuttal.\n",
    "\n",
    "Later on, I decided that making one function for all n_grams was the way to go. If you are still interested in my manual effort for the single words, you can unhide the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:46.754795Z",
     "iopub.status.busy": "2022-02-06T13:47:46.72494Z",
     "iopub.status.idle": "2022-02-06T13:47:52.409877Z",
     "shell.execute_reply": "2022-02-06T13:47:52.410426Z",
     "shell.execute_reply.started": "2022-02-06T13:08:17.805743Z"
    },
    "papermill": {
     "duration": 5.749522,
     "end_time": "2022-02-06T13:47:52.41061",
     "exception": false,
     "start_time": "2022-02-06T13:47:46.661088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['discourse_text'] = train['discourse_text'].str.lower()\n",
    "\n",
    "#get stopwords from nltk library\n",
    "stop_english = stopwords.words(\"english\")\n",
    "other_words_to_take_out = ['school', 'students', 'people', 'would', 'could', 'many']\n",
    "stop_english.extend(other_words_to_take_out)\n",
    "\n",
    "#put dataframe of Top-10 words in dict for all discourse types\n",
    "counts_dict = {}\n",
    "for dt in train['discourse_type'].unique():\n",
    "    df = train.query('discourse_type == @dt')\n",
    "    text = df.discourse_text.apply(lambda x: x.split()).tolist()\n",
    "    text = [item for elem in text for item in elem]\n",
    "    df1 = pd.Series(text).value_counts().to_frame().reset_index()\n",
    "    df1.columns = ['Word', 'Frequency']\n",
    "    df1 = df1[~df1.Word.isin(stop_english)].head(10)\n",
    "    df1 = df1.set_index(\"Word\").sort_values(by = \"Frequency\", ascending = True)\n",
    "    counts_dict[dt] = df1\n",
    "\n",
    "# STEFANOS: Disable plotting\n",
    "# plt.figure(figsize=(15, 12))\n",
    "# plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "keys = list(counts_dict.keys())\n",
    "\n",
    "# STEFANOS: Disable plotting\n",
    "# for n, key in enumerate(keys):\n",
    "#     ax = plt.subplot(4, 2, n + 1)\n",
    "#     ax.set_title(f\"Most used words in {key}\")\n",
    "#     counts_dict[keys[n]].plot(ax=ax, kind = 'barh')\n",
    "#     plt.ylabel(\"\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.06137,
     "end_time": "2022-02-06T13:47:52.534893",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.473523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making n_grams for each discourse type\n",
    "\n",
    "After the manual effort above, I was not fully pleased with the result and decided that I wanted to make a function to compose Top-10 n_grams per discount type by using CountVectorizer(). This function should also work for the single words (just run it with n_grams =1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:52.665103Z",
     "iopub.status.busy": "2022-02-06T13:47:52.664408Z",
     "iopub.status.idle": "2022-02-06T13:47:52.67466Z",
     "shell.execute_reply": "2022-02-06T13:47:52.674036Z",
     "shell.execute_reply.started": "2022-02-06T13:08:23.425982Z"
    },
    "papermill": {
     "duration": 0.076141,
     "end_time": "2022-02-06T13:47:52.674833",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.598692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_n_grams(n_grams, top_n = 10):\n",
    "    df_words = pd.DataFrame()\n",
    "    for dt in tqdm(train['discourse_type'].unique()):\n",
    "        df = train.query('discourse_type == @dt')\n",
    "        texts = df['discourse_text'].tolist()\n",
    "        vec = CountVectorizer(lowercase = True, stop_words = 'english',\\\n",
    "                              ngram_range=(n_grams, n_grams)).fit(texts)\n",
    "        bag_of_words = vec.transform(texts)\n",
    "        sum_words = bag_of_words.sum(axis=0)\n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "        cvec_df = pd.DataFrame.from_records(words_freq,\\\n",
    "                                            columns= ['words', 'counts']).sort_values(by=\"counts\", ascending=False)\n",
    "        cvec_df.insert(0, \"Discourse_type\", dt)\n",
    "        cvec_df = cvec_df.iloc[:top_n,:]\n",
    "        df_words = df_words.append(cvec_df)\n",
    "    return df_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062281,
     "end_time": "2022-02-06T13:47:52.799073",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.736792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function return one dataframe with 70 rows (the top 10 most used n-grams for each discourse type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:47:52.936697Z",
     "iopub.status.busy": "2022-02-06T13:47:52.935929Z",
     "iopub.status.idle": "2022-02-06T13:48:18.423575Z",
     "shell.execute_reply": "2022-02-06T13:48:18.42289Z",
     "shell.execute_reply.started": "2022-02-06T13:08:23.441806Z"
    },
    "papermill": {
     "duration": 25.563253,
     "end_time": "2022-02-06T13:48:18.423732",
     "exception": false,
     "start_time": "2022-02-06T13:47:52.860479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a0c7bce2dc4b23bc3b829f5e87c9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discourse_type</th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73564</th>\n",
       "      <td>Lead</td>\n",
       "      <td>electoral college</td>\n",
       "      <td>34191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63518</th>\n",
       "      <td>Lead</td>\n",
       "      <td>driverless cars</td>\n",
       "      <td>23432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Lead</td>\n",
       "      <td>cell phones</td>\n",
       "      <td>17168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19359</th>\n",
       "      <td>Lead</td>\n",
       "      <td>summer projects</td>\n",
       "      <td>14877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85397</th>\n",
       "      <td>Lead</td>\n",
       "      <td>distance learning</td>\n",
       "      <td>13572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Discourse_type              words  counts\n",
       "73564           Lead  electoral college   34191\n",
       "63518           Lead    driverless cars   23432\n",
       "55              Lead        cell phones   17168\n",
       "19359           Lead    summer projects   14877\n",
       "85397           Lead  distance learning   13572"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = get_n_grams(n_grams = 2, top_n=10)\n",
    "bigrams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063593,
     "end_time": "2022-02-06T13:48:18.552695",
     "exception": false,
     "start_time": "2022-02-06T13:48:18.489102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I have also made a function that prints the results in this dataframe as subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:48:18.711235Z",
     "iopub.status.busy": "2022-02-06T13:48:18.710511Z",
     "iopub.status.idle": "2022-02-06T13:48:20.300107Z",
     "shell.execute_reply": "2022-02-06T13:48:20.300636Z",
     "shell.execute_reply.started": "2022-02-06T13:08:47.612558Z"
    },
    "papermill": {
     "duration": 1.684094,
     "end_time": "2022-02-06T13:48:20.300811",
     "exception": false,
     "start_time": "2022-02-06T13:48:18.616717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_ngram(df, type = \"bigrams\"):\n",
    "# STEFANOS: Disable plotting\n",
    "#     plt.figure(figsize=(15, 12))\n",
    "#     plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#     for n, dt in enumerate(df.Discourse_type.unique()):\n",
    "#         ax = plt.subplot(4, 2, n + 1)\n",
    "#         ax.set_title(f\"Most used {type} in {dt}\")\n",
    "        data = df.query('Discourse_type == @dt')[['words', 'counts']].set_index(\"words\").sort_values(by = \"counts\", ascending = True)\n",
    "#         data.plot(ax=ax, kind = 'barh')\n",
    "#         plt.ylabel(\"\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "plot_ngram(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-28T14:49:19.545062Z",
     "iopub.status.busy": "2021-12-28T14:49:19.543924Z",
     "iopub.status.idle": "2021-12-28T14:49:21.441599Z",
     "shell.execute_reply": "2021-12-28T14:49:21.4376Z",
     "shell.execute_reply.started": "2021-12-28T14:49:19.545018Z"
    },
    "papermill": {
     "duration": 0.069866,
     "end_time": "2022-02-06T13:48:20.440993",
     "exception": false,
     "start_time": "2022-02-06T13:48:20.371127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, I am also plotting the trigrams using both functions in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:48:20.596556Z",
     "iopub.status.busy": "2022-02-06T13:48:20.584981Z",
     "iopub.status.idle": "2022-02-06T13:48:53.132044Z",
     "shell.execute_reply": "2022-02-06T13:48:53.132716Z",
     "shell.execute_reply.started": "2022-02-06T13:08:49.240635Z"
    },
    "papermill": {
     "duration": 32.621724,
     "end_time": "2022-02-06T13:48:53.132923",
     "exception": false,
     "start_time": "2022-02-06T13:48:20.511199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f26b12cd64a4c72990df9ff9bb44852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trigrams = get_n_grams(n_grams = 3, top_n=10)\n",
    "plot_ngram(trigrams, type = \"trigrams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.075665,
     "end_time": "2022-02-06T13:48:53.286223",
     "exception": false,
     "start_time": "2022-02-06T13:48:53.210558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NER Introduction\n",
    "\n",
    "Named Entity Recognition (NER) is the technique that works best for this challenge. If you are looking for more info on this, the free course on Hugging Face is strongly recommended. In the section [Token Classification](https://huggingface.co/course/chapter7/2?fw=pt), we can find the following things that are relevant here:\n",
    "- Named entity recognition (NER): Find the entities (such as persons, locations, or organizations) in a sentence. This can be formulated as attributing a label to each token by having one class per entity and one class for “no entity.”\n",
    "- Chunking: Find the tokens that belong to the same entity. This task (which can be combined with POS or NER) can be formulated as attributing one label (usually B-) to any tokens that are at the beginning of a chunk, another label (usually I-) to tokens that are inside a chunk, and a third label (usually O) to tokens that don’t belong to any chunk.\n",
    "\n",
    "Basically, what is being used in this competition is NER Chunking. Darek Kłeczek wrote a great notebook that explains the ideas behind this (please upvote!): [Visual Tutorial NER Chunking Token Classification](https://www.kaggle.com/thedrcat/visual-tutorial-ner-chunking-token-classification).\n",
    "\n",
    "In this section, I am only going to show how these NER labels can be made for this competition. I am basically using the loop found in Chris Deotte's great notebook [PyTorch - BigBird - NER - [CV 0.615]](https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615) (Please upvote his notebook!), but tried to make it a little easier to understand. I am also using df.loc instead of df.iterrows.\n",
    "\n",
    "First, we have to make a dataframe with all full texts of the essays in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:48:53.446351Z",
     "iopub.status.busy": "2022-02-06T13:48:53.445281Z",
     "iopub.status.idle": "2022-02-06T13:49:03.334476Z",
     "shell.execute_reply": "2022-02-06T13:49:03.33498Z",
     "shell.execute_reply.started": "2022-02-06T13:09:20.85507Z"
    },
    "papermill": {
     "duration": 9.970722,
     "end_time": "2022-02-06T13:49:03.335172",
     "exception": false,
     "start_time": "2022-02-06T13:48:53.36445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a29229165ba4ea087632c1a11a2e72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321A3E87AD3</td>\n",
       "      <td>I do agree that some students would benefit fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DFEAEC512BAB</td>\n",
       "      <td>Should students design a summer project for sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2E4AFCD3987F</td>\n",
       "      <td>Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EB6C2AF20BFE</td>\n",
       "      <td>People sometimes have a different opinion than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91A08E523D5</td>\n",
       "      <td>Dear senator,\\n\\nAs you know the Electoral Col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text\n",
       "0  3321A3E87AD3  I do agree that some students would benefit fr...\n",
       "1  DFEAEC512BAB  Should students design a summer project for sc...\n",
       "2  2E4AFCD3987F  Dear State Senator\\n\\n,\\n\\nIn the ruels of vot...\n",
       "3  EB6C2AF20BFE  People sometimes have a different opinion than...\n",
       "4  A91A08E523D5  Dear senator,\\n\\nAs you know the Electoral Col..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/raghavendrakotala/fine-tunned-on-roberta-base-as-ner-problem-0-533\n",
    "test_names, train_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.085572,
     "end_time": "2022-02-06T13:49:03.515979",
     "exception": false,
     "start_time": "2022-02-06T13:49:03.430407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are ready to add a column with NER entities to this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:49:03.697014Z",
     "iopub.status.busy": "2022-02-06T13:49:03.688508Z",
     "iopub.status.idle": "2022-02-06T13:51:36.725708Z",
     "shell.execute_reply": "2022-02-06T13:51:36.726314Z",
     "shell.execute_reply.started": "2022-02-06T13:09:28.324801Z"
    },
    "papermill": {
     "duration": 153.131048,
     "end_time": "2022-02-06T13:51:36.72673",
     "exception": false,
     "start_time": "2022-02-06T13:49:03.595682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51e9f12119e4d969c2f1a56ab71ae4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#now loop over dataframe with all discourses of this particular essay\u001b[39;00m\n\u001b[1;32m      8\u001b[0m discourse_id \u001b[38;5;241m=\u001b[39m train_text_df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m train_df_id \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid == @discourse_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_df_id)):\n\u001b[1;32m     11\u001b[0m     discourse \u001b[38;5;241m=\u001b[39m train_df_id\u001b[38;5;241m.\u001b[39mloc[j, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscourse_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/frame.py:4474\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4472\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   4473\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 4474\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   4477\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[res]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/frame.py:4612\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   4609\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   4610\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolvers\u001b[39m\u001b[38;5;124m\"\u001b[39m, ())) \u001b[38;5;241m+\u001b[39m resolvers\n\u001b[0;32m-> 4612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/eval.py:353\u001b[0m, in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[1;32m    345\u001b[0m env \u001b[38;5;241m=\u001b[39m ensure_scope(\n\u001b[1;32m    346\u001b[0m     level \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    347\u001b[0m     global_dict\u001b[38;5;241m=\u001b[39mglobal_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[1;32m    351\u001b[0m )\n\u001b[0;32m--> 353\u001b[0m parsed_expr \u001b[38;5;241m=\u001b[39m \u001b[43mExpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# construct the engine and evaluate the parsed expression\u001b[39;00m\n\u001b[1;32m    356\u001b[0m eng \u001b[38;5;241m=\u001b[39m ENGINES[engine]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:813\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[0;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_visitor \u001b[38;5;241m=\u001b[39m PARSERS[parser](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparser)\n\u001b[0;32m--> 813\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:832\u001b[0m, in \u001b[0;36mExpr.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03m    Parse an expression.\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_visitor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:421\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly a single expression is allowed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    420\u001b[0m expr \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mbody[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:424\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:723\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslate_In(ops[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    722\u001b[0m     binop \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mBinOp(op\u001b[38;5;241m=\u001b[39mop, left\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mleft, right\u001b[38;5;241m=\u001b[39mcomps[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbinop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m left \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mleft\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mtype\u001b[39m(node)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    414\u001b[0m visitor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:538\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BinOp\u001b[0;34m(self, node, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m op, op_class, left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_transform_eq_ne(node)\n\u001b[1;32m    537\u001b[0m left, right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_downcast_constants(left, right)\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_evaluate_binop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:524\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_evaluate_binop\u001b[0;34m(self, op, op_class, lhs, rhs, eval_in_python, maybe_eval_in_python)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_eval(res, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary_ops)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mop \u001b[38;5;129;01min\u001b[39;00m eval_in_python:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# \"in\"/\"not in\" ops are always evaluated in python\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_in_python\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytables\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(lhs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(rhs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_type\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    529\u001b[0m     ):\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;66;03m# evaluate \"==\" and \"!=\" in python if either of our operands\u001b[39;00m\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;66;03m# has an object return type\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/expr.py:492\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_eval\u001b[0;34m(self, binop, eval_in_python)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_eval\u001b[39m(\u001b[38;5;28mself\u001b[39m, binop, eval_in_python):\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# eval `in` and `not in` (for now) in \"partial\" python space\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;66;03m# things that can be evaluated in \"eval\" space will be turned into\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# in that case a + 2 * b will be evaluated using numexpr, and the \"in\"\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;66;03m# call will be evaluated using isin (in python space)\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_in_python\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/ops.py:449\u001b[0m, in \u001b[0;36mBinOp.evaluate\u001b[0;34m(self, env, engine, parser, term_type, eval_in_python)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# base cases\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop \u001b[38;5;129;01min\u001b[39;00m eval_in_python:\n\u001b[0;32m--> 449\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28meval\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/computation/ops.py:265\u001b[0m, in \u001b[0;36m_in\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mCompute the vectorized membership of ``x in y`` if possible, otherwise\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03muse Python.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like(x):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/series.py:5563\u001b[0m, in \u001b[0;36mSeries.isin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   5490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misin\u001b[39m(\u001b[38;5;28mself\u001b[39m, values) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   5491\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5492\u001b[0m \u001b[38;5;124;03m    Whether elements in Series are contained in `values`.\u001b[39;00m\n\u001b[1;32m   5493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5561\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[1;32m   5562\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5563\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   5565\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5566\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py3.10/lib/python3.10/site-packages/pandas/core/algorithms.py:527\u001b[0m, in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    524\u001b[0m     comps_array \u001b[38;5;241m=\u001b[39m comps_array\u001b[38;5;241m.\u001b[39mastype(common, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    525\u001b[0m     f \u001b[38;5;241m=\u001b[39m htable\u001b[38;5;241m.\u001b[39mismember\n\u001b[0;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomps_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_entities = []\n",
    "#loop over dataframe with all full texts\n",
    "for i in tqdm(range(len(train_text_df))):\n",
    "    total = len(train_text_df.loc[i, 'text'].split())\n",
    "    #now a list with length the total number of words in an essay is initialised with all values being \"O\"\n",
    "    entities = [\"O\"]*total\n",
    "    #now loop over dataframe with all discourses of this particular essay\n",
    "    discourse_id = train_text_df.loc[i, 'id']\n",
    "    train_df_id = train.query('id == @discourse_id').reset_index(drop=True)\n",
    "    for j in range(len(train_df_id)):\n",
    "        discourse = train_df_id.loc[j, 'discourse_type']\n",
    "        #make a list with the position numbers in predictionstring converted into integer\n",
    "        list_ix = [int(x) for x in train_df_id.loc[j, 'predictionstring'].split(' ')]\n",
    "        #now the entities lists gets overwritten where there are discourse identified by the experts\n",
    "        #the first word of each discourse gets prefix \"Beginning\"\n",
    "        entities[list_ix[0]] = f\"B-{discourse}\"\n",
    "        #the other ones get prefix I\n",
    "        for k in list_ix[1:]: entities[k] = f\"I-{discourse}\"\n",
    "    all_entities.append(entities)\n",
    "    \n",
    "    \n",
    "train_text_df['entities'] = all_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T13:51:36.88841Z",
     "iopub.status.busy": "2022-02-06T13:51:36.887386Z",
     "iopub.status.idle": "2022-02-06T13:51:36.905134Z",
     "shell.execute_reply": "2022-02-06T13:51:36.905633Z",
     "shell.execute_reply.started": "2022-02-06T13:12:05.470089Z"
    },
    "papermill": {
     "duration": 0.101022,
     "end_time": "2022-02-06T13:51:36.905818",
     "exception": false,
     "start_time": "2022-02-06T13:51:36.804796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078177,
     "end_time": "2022-02-06T13:51:37.063558",
     "exception": false,
     "start_time": "2022-02-06T13:51:36.985381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thanks for your attention! If you like this notebook, an upvote is always appreciated.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
