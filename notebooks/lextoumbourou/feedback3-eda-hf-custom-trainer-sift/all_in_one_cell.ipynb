{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was obtained by running `jupyter nbconvert --to script bench.ipynb` and putting all the code from the resuling `.py` into one cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Imports\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# # Load Data\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(os.path.abspath('') + '/input/feedback-prize-english-language-learning/train.csv')\n",
    "test_df = pd.read_csv(os.path.abspath('') + '/input/feedback-prize-english-language-learning/test.csv')\n",
    "\n",
    "\n",
    "# # -- STEFANOS -- Replicate Data\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "factor = 500\n",
    "if \"IREWR_LESS_REPLICATION\" in os.environ and os.environ[\"IREWR_LESS_REPLICATION\"] == \"True\":\n",
    "    factor = factor//5\n",
    "train_df = pd.concat([train_df]*factor)\n",
    "test_df = pd.concat([test_df]*factor)\n",
    "# train_df.info()\n",
    "\n",
    "\n",
    "# Let's see a row from each dataset.\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "test_df.head()\n",
    "\n",
    "\n",
    "# Then the size of each dataset.\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "len(train_df), len(test_df)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "LABEL_COLUMNS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "\n",
    "# # Text Examples\n",
    "\n",
    "# ## Random Examples\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "texts = train_df.sample(frac=1, random_state=420).head(4)\n",
    "\n",
    "\n",
    "# ## Lowest Scoring Examples\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "train_df['total_score'] = train_df[LABEL_COLUMNS].sum(axis=1)\n",
    "lowest_df = train_df.sort_values('total_score').head(4)\n",
    "\n",
    "\n",
    "# ## Highest Scoring Examples\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "train_df['total_score'] = train_df[LABEL_COLUMNS].sum(axis=1)\n",
    "highest_df = train_df.sort_values('total_score', ascending=False).head(4)\n",
    "\n",
    "\n",
    "# # Text Overview\n",
    "\n",
    "# ## Word Count\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "train_df['word_count'] = train_df.full_text.apply(lambda x: len(x.split()))\n",
    "\n",
    "\n",
    "# Mean word count:\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "train_df['word_count'].mean()\n",
    "\n",
    "\n",
    "# Max word count:\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "train_df['word_count'].max()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
