{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Competition\n",
    "\n",
    "You are someone who is recently starting on NLP or has become a master ,irrespective of where you lie in the learning chain , I can bet you have worked on sentiment analysis and if not you will be going to, you just can't bypass it. Can You?. <b>Sentiment analysis</b> is for NLP <b>'what Happy Birthday to You'</b> is for Guitar players Right? You start here <br>\n",
    "<br>\n",
    "In case you are not aware about sentiment analysis here is a very good article : https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17\n",
    "<br><br>\n",
    "Recently Kaggle Lauched a new competition admist the COVID-19 Scare , named Twitter Sentiment Extraction ,I know right its a twitter sentiment analysis competition,But kaggle never disappoints you,it could not have been this straightforward, afterall it has go on for two months.So what this competition asks for is not the sentiment scores but the part of the tweet (word or phrase) that reflects the sentiment., Interesting it isn't it? This competition is special,so if you want to level up your NLP skills , this competition is for you\n",
    "\n",
    "# Acknowledgements\n",
    "* https://www.kaggle.com/aashita/word-clouds-of-various-shapes --> WORDCLOUDS FUNCTION\n",
    "* https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb --> For understanding how to train spacy NER on custom inputs\n",
    "\n",
    "\n",
    "# About this Notebook\n",
    "\n",
    "In this kernel, I will briefly explain the structure of dataset.I will generate and analyze metafeatures. Then, I will visualize the dataset using Matplotlib, seaborn and Plotly to gain as much insight as I can . Also I will approach this problem as an NER problem to build a model\n",
    "<br><br>\n",
    "In case you are just starting with NLP here is a guide to Approach almost any NLP Problem by Grandmaster @Abhishek Thakur\n",
    "https://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem\n",
    "\n",
    "\n",
    "<b> This kernel is a work in Progress,and I will keep on updating it as the competition progresses and I learn more and more things about the data</b>\n",
    "\n",
    "**<span style=\"color:Red\">If you find this kernel useful, Please Upvote it , it motivates me to write more Quality content**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necesseties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/test.csv\n",
      "../input/sample_submission.csv\n",
      "../input/train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/damitha/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np \n",
    "import random\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "%matplotlib inline\n",
    "# from plotly import graph_objs as go\n",
    "# import plotly.express as px\n",
    "# import plotly.figure_factory as ff\n",
    "from collections import Counter\n",
    "\n",
    "from PIL import Image\n",
    "# from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import nltk\n",
    "# import spacy\n",
    "import random\n",
    "# from spacy.util import compounding\n",
    "# from spacy.util import minibatch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is a helper Function which generates random colors which can be used to give different colors to your plots.Feel free to use it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def random_colours(number_of_colors):\n",
    "    '''\n",
    "    Simple function for random colours generation.\n",
    "    Input:\n",
    "        number_of_colors - integer value indicating the number of colours which are going to be generated.\n",
    "    Output:\n",
    "        Color in the following format: ['#E86DA4'] .\n",
    "    '''\n",
    "    colors = []\n",
    "    for i in range(number_of_colors):\n",
    "        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "ss = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 4)\n",
      "(3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So We have 27486 tweets in the train set and 3535 tweets in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   textID         27481 non-null  object\n",
      " 1   text           27480 non-null  object\n",
      " 2   selected_text  27480 non-null  object\n",
      " 3   sentiment      27481 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 858.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one null Value in the train , as the test field for value is NAN we will just remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3534 entries, 0 to 3533\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   textID     3534 non-null   object\n",
      " 1   text       3534 non-null   object\n",
      " 2   sentiment  3534 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 83.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null Values in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected_text is a subset of text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27480</td>\n",
       "      <td>27480</td>\n",
       "      <td>22463</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>good</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>11117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            textID                                  text selected_text  \\\n",
       "count        27480                                 27480         27480   \n",
       "unique       27480                                 27480         22463   \n",
       "top     cb774db0d1   I`d have responded, if I were going          good   \n",
       "freq             1                                     1           199   \n",
       "\n",
       "       sentiment  \n",
       "count      27480  \n",
       "unique         3  \n",
       "top      neutral  \n",
       "freq       11117  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the distribution of tweets in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7edaa_row0_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7edaa_row1_col1 {\n",
       "  background-color: #dcdcec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7edaa_row2_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7edaa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7edaa_level0_col0\" class=\"col_heading level0 col0\" >sentiment</th>\n",
       "      <th id=\"T_7edaa_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7edaa_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_7edaa_row0_col0\" class=\"data row0 col0\" >neutral</td>\n",
       "      <td id=\"T_7edaa_row0_col1\" class=\"data row0 col1\" >11117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7edaa_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_7edaa_row1_col0\" class=\"data row1 col0\" >positive</td>\n",
       "      <td id=\"T_7edaa_row1_col1\" class=\"data row1 col1\" >8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7edaa_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "      <td id=\"T_7edaa_row2_col0\" class=\"data row2 col0\" >negative</td>\n",
       "      <td id=\"T_7edaa_row2_col1\" class=\"data row2 col1\" >7781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5c155183a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# sns.countplot(x='sentiment',data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw a Funnel-Chart for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = go.Figure(go.Funnelarea(\n",
    "#     text =temp.sentiment,\n",
    "#     values = temp.text,\n",
    "#     title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n",
    "#     ))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we currently Know About our Data:\n",
    "\n",
    "Before starting let's look at some things that we already know about the data and will help us in gaining more new insights:\n",
    "* We Know that selected_text is a subset of text\n",
    "* We know that selected_text contains only one segment of text,i.e,It does not jump between two sentences.For Eg:- If text is 'Spent the entire morning in a meeting w/ a vendor, and my boss was not happy w/ them. Lots of fun.  I had other plans for my morning' The selected text can be 'my boss was not happy w/ them. Lots of fun' or 'Lots of fun' but cannot be 'Morning,vendor and my boss,\n",
    "* Thanks to this discussion:https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/138520 We know that neutral tweets have a jaccard similarity of 97 percent between text and selected_text\n",
    "* Also as discussed here https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/138272 ,there are rows where selected_text starts from between the words and thus selected_texts dont always make sense and since we do not know whether the output of test set contain these descrepancies or not ,we are not sure that preprocessing and removing punctuations would be a good idea or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Meta-Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the previous versions of this notebook,I used Number of words in selected text and main text ,Length of words in text and selected as main meta features,but in the context of this competition where we have to predict selected_text which is a subset of text, more useful features to generate would be** :-\n",
    "* Difference In Number Of words of Selected_text and Text\n",
    "* Jaccard Similarity Scores between text and Selected_text\n",
    "\n",
    "Thus it will not be useful for us to generate features we used before as they are of no importance here\n",
    "\n",
    "For what who don't know what Jaccard Similarity is : https://www.geeksforgeeks.org/find-the-jaccard-index-and-jaccard-distance-between-the-two-given-sets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "results_jaccard=[]\n",
    "\n",
    "for ind,row in train.iterrows():\n",
    "    sentence1 = row.text\n",
    "    sentence2 = row.selected_text\n",
    "\n",
    "    jaccard_score = jaccard(sentence1,sentence2)\n",
    "    results_jaccard.append([sentence1,sentence2,jaccard_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\n",
    "train = train.merge(jaccard,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>jaccard_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27475</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0                    I`d have responded, if I were going   \n",
       "1          Sooo SAD I will miss you here in San Diego!!!   \n",
       "2                              my boss is bullying me...   \n",
       "3                         what interview! leave me alone   \n",
       "4       Sons of ****, why couldn`t they put them on t...   \n",
       "...                                                  ...   \n",
       "27475   wish we could come see u on Denver  husband l...   \n",
       "27476   I`ve wondered about rake to.  The client has ...   \n",
       "27477   Yay good for both of you. Enjoy the break - y...   \n",
       "27478                         But it was worth it  ****.   \n",
       "27479     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text  jaccard_score  \n",
       "0                    I`d have responded, if I were going       1.000000  \n",
       "1                                               Sooo SAD       0.200000  \n",
       "2                                            bullying me       0.166667  \n",
       "3                                         leave me alone       0.600000  \n",
       "4                                          Sons of ****,       0.214286  \n",
       "...                                                  ...            ...  \n",
       "27475                                             d lost       0.058824  \n",
       "27476                                      , don`t force       0.083333  \n",
       "27477                          Yay good for both of you.       0.272727  \n",
       "27478                         But it was worth it  ****.       1.000000  \n",
       "27479  All this flirting going on - The ATG smiles. Y...       0.833333  \n",
       "\n",
       "[27480 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\n",
    "train['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\n",
    "train['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>Num_words_ST</th>\n",
       "      <th>Num_word_text</th>\n",
       "      <th>difference_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  jaccard_score  Num_words_ST  \\\n",
       "0  I`d have responded, if I were going   neutral       1.000000             7   \n",
       "1                             Sooo SAD  negative       0.200000             2   \n",
       "2                          bullying me  negative       0.166667             2   \n",
       "3                       leave me alone  negative       0.600000             3   \n",
       "4                        Sons of ****,  negative       0.214286             3   \n",
       "\n",
       "   Num_word_text  difference_in_words  \n",
       "0              7                    0  \n",
       "1             10                    8  \n",
       "2              5                    3  \n",
       "3              5                    2  \n",
       "4             14                   11  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of Meta-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "hist_data = [train['Num_words_ST'],train['Num_word_text']]\n",
    "\n",
    "group_labels = ['Selected_Text', 'Text']\n",
    "\n",
    "# Create distplot with custom bin_size\n",
    "# fig = ff.create_distplot(hist_data, group_labels,show_curve=False)\n",
    "# fig.update_layout(title_text='Distribution of Number Of words')\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=900,\n",
    "#     height=700,\n",
    "#     paper_bgcolor=\"LightSteelBlue\",\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The number of words plot is really interesting ,the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# p1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\n",
    "# p1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now It will be more interesting to see the differnce in number of words and jaccard_scores across different Sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# p1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\n",
    "# p2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# sns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was not able to plot kde plot for neutral tweets because most of the values for difference in number of words were zero. We can see it clearly now ,if we had used the feature in the starting we would have known that text and selected text are mostly the same for neutral tweets,thus its always important to keep the end goal in mind while performing EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# p1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\n",
    "# p2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\n",
    "# plt.legend(labels=['positive','negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was not able to plot kde of jaccard_scores of neutral tweets for the same reason,thus I will plot a distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# sns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some interesting trends here:\n",
    "* Positive and negative tweets have high kurtosis and thus values are concentrated in two regions narrow and high density \n",
    "* Neutral tweets have a low kurtosis value and their is bump in density near values of 1\n",
    "\n",
    "For those who don't know :\n",
    "* Kurtosis is the measure of how peaked a distribution is and how much spread it is around that peak\n",
    "* Skewness measures how much a curve deviates from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion Of EDA\n",
    "\n",
    "* We can see from the jaccard score plot that there is peak for negative and positive plot around score of 1 .That means there is a cluster of tweets where there is a high similarity between text and selected texts ,if we can find those clusters then we can predict text for selected texts for those tweets irrespective of segment\n",
    "\n",
    "Let's see if we can find those clusters,one interesting idea would be to check tweets which have number of words lesss than 3 in text, because there the text might be completely used as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = train[train['Num_word_text']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>Num_words_ST</th>\n",
       "      <th>Num_word_text</th>\n",
       "      <th>difference_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "      <td>728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.889423</td>\n",
       "      <td>1.564560</td>\n",
       "      <td>1.726648</td>\n",
       "      <td>0.162088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.244655</td>\n",
       "      <td>0.496155</td>\n",
       "      <td>0.445986</td>\n",
       "      <td>0.368785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       jaccard_score  Num_words_ST  Num_word_text  difference_in_words\n",
       "count     728.000000    728.000000     728.000000           728.000000\n",
       "mean        0.889423      1.564560       1.726648             0.162088\n",
       "std         0.244655      0.496155       0.445986             0.368785\n",
       "min         0.000000      1.000000       1.000000             0.000000\n",
       "25%         1.000000      1.000000       1.000000             0.000000\n",
       "50%         1.000000      2.000000       2.000000             0.000000\n",
       "75%         1.000000      2.000000       2.000000             0.000000\n",
       "max         1.000000      2.000000       2.000000             1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k.groupby('sentiment').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    0.788580\n",
       "neutral     0.977805\n",
       "positive    0.765700\n",
       "Name: jaccard_score, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.groupby('sentiment').mean(numeric_only=True)['jaccard_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is similarity between text and selected text .Let's have closer look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>Num_words_ST</th>\n",
       "      <th>Num_word_text</th>\n",
       "      <th>difference_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>fa2654e730</td>\n",
       "      <td>Chilliin</td>\n",
       "      <td>Chilliin</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>bbbc46889b</td>\n",
       "      <td>THANK YYYYYYYYYOOOOOOOOOOUUUUU!</td>\n",
       "      <td>THANK YYYYYYYYYOOOOOOOOOOUUUUU!</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>f3d95b57b1</td>\n",
       "      <td>good morning</td>\n",
       "      <td>good morning</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>89d5b3f0b5</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>a78ef3e0d0</td>\n",
       "      <td>Goodmorning</td>\n",
       "      <td>Goodmorning</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26689</th>\n",
       "      <td>e80c242d6a</td>\n",
       "      <td>Goodnight;</td>\n",
       "      <td>Goodnight;</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26725</th>\n",
       "      <td>aad244f37d</td>\n",
       "      <td>*hug*</td>\n",
       "      <td>*hug*</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26842</th>\n",
       "      <td>a46571fe12</td>\n",
       "      <td>congrats!</td>\n",
       "      <td>congrats!</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26959</th>\n",
       "      <td>49a942e9b1</td>\n",
       "      <td>Happy birthday.</td>\n",
       "      <td>Happy birthday.</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27292</th>\n",
       "      <td>47c474aaf1</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>Good</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                              text  \\\n",
       "68     fa2654e730                          Chilliin   \n",
       "80     bbbc46889b   THANK YYYYYYYYYOOOOOOOOOOUUUUU!   \n",
       "170    f3d95b57b1                      good morning   \n",
       "278    89d5b3f0b5                            Thanks   \n",
       "429    a78ef3e0d0                       Goodmorning   \n",
       "...           ...                               ...   \n",
       "26689  e80c242d6a                        Goodnight;   \n",
       "26725  aad244f37d                             *hug*   \n",
       "26842  a46571fe12                         congrats!   \n",
       "26959  49a942e9b1                   Happy birthday.   \n",
       "27292  47c474aaf1                       Good choice   \n",
       "\n",
       "                         selected_text sentiment  jaccard_score  Num_words_ST  \\\n",
       "68                            Chilliin  positive            1.0             1   \n",
       "80     THANK YYYYYYYYYOOOOOOOOOOUUUUU!  positive            1.0             2   \n",
       "170                       good morning  positive            1.0             2   \n",
       "278                             Thanks  positive            1.0             1   \n",
       "429                        Goodmorning  positive            1.0             1   \n",
       "...                                ...       ...            ...           ...   \n",
       "26689                       Goodnight;  positive            1.0             1   \n",
       "26725                            *hug*  positive            1.0             1   \n",
       "26842                        congrats!  positive            1.0             1   \n",
       "26959                  Happy birthday.  positive            1.0             2   \n",
       "27292                             Good  positive            0.5             1   \n",
       "\n",
       "       Num_word_text  difference_in_words  \n",
       "68                 1                    0  \n",
       "80                 2                    0  \n",
       "170                2                    0  \n",
       "278                1                    0  \n",
       "429                1                    0  \n",
       "...              ...                  ...  \n",
       "26689              1                    0  \n",
       "26725              1                    0  \n",
       "26842              1                    0  \n",
       "26959              2                    0  \n",
       "27292              2                    1  \n",
       "\n",
       "[207 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[k['sentiment']=='positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus its clear that most of the times , text is used as selected text.We can improve this by preprocessing the text which have word length less than 3.We will remember this information and use it in model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Corpus\n",
    "Now Before We Dive into extracting information out of words in text and selected text,let's first clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x:clean_text(x))\n",
    "train['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard_score</th>\n",
       "      <th>Num_words_ST</th>\n",
       "      <th>Num_word_text</th>\n",
       "      <th>difference_in_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of  why couldnt they put them on the rel...</td>\n",
       "      <td>sons of</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                  id have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861   sons of  why couldnt they put them on the rel...   \n",
       "\n",
       "                       selected_text sentiment  jaccard_score  Num_words_ST  \\\n",
       "0  id have responded if i were going   neutral       1.000000             7   \n",
       "1                           sooo sad  negative       0.200000             2   \n",
       "2                        bullying me  negative       0.166667             2   \n",
       "3                     leave me alone  negative       0.600000             3   \n",
       "4                           sons of   negative       0.214286             3   \n",
       "\n",
       "   Num_word_text  difference_in_words  \n",
       "0              7                    0  \n",
       "1             10                    8  \n",
       "2              5                    3  \n",
       "3              5                    2  \n",
       "4             14                   11  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Common words in our Target-Selected Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3e109_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3e109_row1_col1 {\n",
       "  background-color: #3383be;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3e109_row2_col1 {\n",
       "  background-color: #57a0ce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3e109_row3_col1 {\n",
       "  background-color: #9ac8e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row4_col1 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row5_col1 {\n",
       "  background-color: #caddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row6_col1 {\n",
       "  background-color: #d3e4f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row7_col1 {\n",
       "  background-color: #d9e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row8_col1 {\n",
       "  background-color: #dae8f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row9_col1 {\n",
       "  background-color: #dfebf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row10_col1 {\n",
       "  background-color: #e3eef9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row11_col1 {\n",
       "  background-color: #e9f2fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row12_col1 {\n",
       "  background-color: #eaf3fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row13_col1 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row14_col1 {\n",
       "  background-color: #eff6fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row15_col1 {\n",
       "  background-color: #f2f8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row16_col1 {\n",
       "  background-color: #f4f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row17_col1 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3e109_row18_col1, #T_3e109_row19_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3e109\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3e109_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_3e109_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3e109_row0_col0\" class=\"data row0 col0\" >i</td>\n",
       "      <td id=\"T_3e109_row0_col1\" class=\"data row0 col1\" >7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3e109_row1_col0\" class=\"data row1 col0\" >to</td>\n",
       "      <td id=\"T_3e109_row1_col1\" class=\"data row1 col1\" >5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3e109_row2_col0\" class=\"data row2 col0\" >the</td>\n",
       "      <td id=\"T_3e109_row2_col1\" class=\"data row2 col1\" >4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3e109_row3_col0\" class=\"data row3 col0\" >a</td>\n",
       "      <td id=\"T_3e109_row3_col1\" class=\"data row3 col1\" >3538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3e109_row4_col0\" class=\"data row4 col0\" >my</td>\n",
       "      <td id=\"T_3e109_row4_col1\" class=\"data row4 col1\" >2783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3e109_row5_col0\" class=\"data row5 col0\" >you</td>\n",
       "      <td id=\"T_3e109_row5_col1\" class=\"data row5 col1\" >2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3e109_row6_col0\" class=\"data row6 col0\" >and</td>\n",
       "      <td id=\"T_3e109_row6_col1\" class=\"data row6 col1\" >2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3e109_row7_col0\" class=\"data row7 col0\" >it</td>\n",
       "      <td id=\"T_3e109_row7_col1\" class=\"data row7 col1\" >2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3e109_row8_col0\" class=\"data row8 col0\" >is</td>\n",
       "      <td id=\"T_3e109_row8_col1\" class=\"data row8 col1\" >2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3e109_row9_col0\" class=\"data row9 col0\" >in</td>\n",
       "      <td id=\"T_3e109_row9_col1\" class=\"data row9 col1\" >1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3e109_row10_col0\" class=\"data row10 col0\" >for</td>\n",
       "      <td id=\"T_3e109_row10_col1\" class=\"data row10 col1\" >1854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3e109_row11_col0\" class=\"data row11 col0\" >im</td>\n",
       "      <td id=\"T_3e109_row11_col1\" class=\"data row11 col1\" >1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3e109_row12_col0\" class=\"data row12 col0\" >of</td>\n",
       "      <td id=\"T_3e109_row12_col1\" class=\"data row12 col1\" >1638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3e109_row13_col0\" class=\"data row13 col0\" >me</td>\n",
       "      <td id=\"T_3e109_row13_col1\" class=\"data row13 col1\" >1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3e109_row14_col0\" class=\"data row14 col0\" >on</td>\n",
       "      <td id=\"T_3e109_row14_col1\" class=\"data row14 col1\" >1488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3e109_row15_col0\" class=\"data row15 col0\" >so</td>\n",
       "      <td id=\"T_3e109_row15_col1\" class=\"data row15 col1\" >1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3e109_row16_col0\" class=\"data row16 col0\" >have</td>\n",
       "      <td id=\"T_3e109_row16_col1\" class=\"data row16 col1\" >1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3e109_row17_col0\" class=\"data row17 col0\" >that</td>\n",
       "      <td id=\"T_3e109_row17_col1\" class=\"data row17 col1\" >1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3e109_row18_col0\" class=\"data row18 col0\" >but</td>\n",
       "      <td id=\"T_3e109_row18_col1\" class=\"data row18 col1\" >1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3e109_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3e109_row19_col0\" class=\"data row19 col0\" >good</td>\n",
       "      <td id=\"T_3e109_row19_col1\" class=\"data row19 col1\" >1251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5c15518790>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\n",
    "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n",
    "#              width=700, height=700,color='Common_words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOPS!While we cleaned our dataset we didnt remove the stop words and hence we can see the most coomon word is 'to' . Let's try again after removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def remove_stopword(x):\n",
    "    return [y for y in x if y not in stopwords.words('english')]\n",
    "train['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0e038_row0_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e038_row1_col1 {\n",
       "  background-color: #6c55a5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e038_row2_col1 {\n",
       "  background-color: #9692c4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e038_row3_col1 {\n",
       "  background-color: #a9a7cf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0e038_row4_col1 {\n",
       "  background-color: #c2c3df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row5_col1 {\n",
       "  background-color: #c3c4e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row6_col1 {\n",
       "  background-color: #c5c6e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row7_col1 {\n",
       "  background-color: #dadaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row8_col1, #T_0e038_row9_col1 {\n",
       "  background-color: #efedf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row10_col1 {\n",
       "  background-color: #f2f0f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row11_col1 {\n",
       "  background-color: #f6f4f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row12_col1 {\n",
       "  background-color: #f7f5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row13_col1 {\n",
       "  background-color: #faf8fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row14_col1, #T_0e038_row15_col1 {\n",
       "  background-color: #faf9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row16_col1 {\n",
       "  background-color: #fbfafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0e038_row17_col1, #T_0e038_row18_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0e038\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0e038_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_0e038_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_0e038_row0_col0\" class=\"data row0 col0\" >good</td>\n",
       "      <td id=\"T_0e038_row0_col1\" class=\"data row0 col1\" >1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_0e038_row1_col0\" class=\"data row1 col0\" >day</td>\n",
       "      <td id=\"T_0e038_row1_col1\" class=\"data row1 col1\" >1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_0e038_row2_col0\" class=\"data row2 col0\" >love</td>\n",
       "      <td id=\"T_0e038_row2_col1\" class=\"data row2 col1\" >909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_0e038_row3_col0\" class=\"data row3 col0\" >happy</td>\n",
       "      <td id=\"T_0e038_row3_col1\" class=\"data row3 col1\" >852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_0e038_row4_col0\" class=\"data row4 col0\" >like</td>\n",
       "      <td id=\"T_0e038_row4_col1\" class=\"data row4 col1\" >774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_0e038_row5_col0\" class=\"data row5 col0\" >get</td>\n",
       "      <td id=\"T_0e038_row5_col1\" class=\"data row5 col1\" >772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_0e038_row6_col0\" class=\"data row6 col0\" >dont</td>\n",
       "      <td id=\"T_0e038_row6_col1\" class=\"data row6 col1\" >765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_0e038_row7_col0\" class=\"data row7 col0\" >go</td>\n",
       "      <td id=\"T_0e038_row7_col1\" class=\"data row7 col1\" >700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_0e038_row8_col0\" class=\"data row8 col0\" >cant</td>\n",
       "      <td id=\"T_0e038_row8_col1\" class=\"data row8 col1\" >613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_0e038_row9_col0\" class=\"data row9 col0\" >work</td>\n",
       "      <td id=\"T_0e038_row9_col1\" class=\"data row9 col1\" >612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_0e038_row10_col0\" class=\"data row10 col0\" >going</td>\n",
       "      <td id=\"T_0e038_row10_col1\" class=\"data row10 col1\" >592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_0e038_row11_col0\" class=\"data row11 col0\" >today</td>\n",
       "      <td id=\"T_0e038_row11_col1\" class=\"data row11 col1\" >564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_0e038_row12_col0\" class=\"data row12 col0\" >got</td>\n",
       "      <td id=\"T_0e038_row12_col1\" class=\"data row12 col1\" >558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_0e038_row13_col0\" class=\"data row13 col0\" >one</td>\n",
       "      <td id=\"T_0e038_row13_col1\" class=\"data row13 col1\" >538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_0e038_row14_col0\" class=\"data row14 col0\" >time</td>\n",
       "      <td id=\"T_0e038_row14_col1\" class=\"data row14 col1\" >534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_0e038_row15_col0\" class=\"data row15 col0\" >thanks</td>\n",
       "      <td id=\"T_0e038_row15_col1\" class=\"data row15 col1\" >532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_0e038_row16_col0\" class=\"data row16 col0\" >lol</td>\n",
       "      <td id=\"T_0e038_row16_col1\" class=\"data row16 col1\" >528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_0e038_row17_col0\" class=\"data row17 col0\" >really</td>\n",
       "      <td id=\"T_0e038_row17_col1\" class=\"data row17 col1\" >520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0e038_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_0e038_row18_col0\" class=\"data row18 col0\" >u</td>\n",
       "      <td id=\"T_0e038_row18_col1\" class=\"data row18 col1\" >519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5c14cae3d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([item for sublist in train['temp_list'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(20))\n",
    "temp = temp.iloc[1:,:]\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Common words in Text\n",
    "\n",
    "Let's also look at the most common words in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\n",
    "train['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_63f98_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63f98_row1_col1 {\n",
       "  background-color: #4292c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63f98_row2_col1 {\n",
       "  background-color: #63a8d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_63f98_row3_col1 {\n",
       "  background-color: #79b5d9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row4_col1 {\n",
       "  background-color: #92c4de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row5_col1 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row6_col1 {\n",
       "  background-color: #b8d5ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row7_col1 {\n",
       "  background-color: #bad6eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row8_col1, #T_63f98_row9_col1 {\n",
       "  background-color: #bed8ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row10_col1 {\n",
       "  background-color: #c4daee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row11_col1 {\n",
       "  background-color: #cddff1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row12_col1 {\n",
       "  background-color: #d3e4f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row13_col1 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row14_col1 {\n",
       "  background-color: #d7e6f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row15_col1 {\n",
       "  background-color: #d8e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row16_col1 {\n",
       "  background-color: #dae8f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row17_col1 {\n",
       "  background-color: #dbe9f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row18_col1 {\n",
       "  background-color: #ddeaf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row19_col1 {\n",
       "  background-color: #dfecf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row20_col1 {\n",
       "  background-color: #eef5fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row21_col1 {\n",
       "  background-color: #f6faff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_63f98_row22_col1, #T_63f98_row23_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_63f98\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63f98_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_63f98_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_63f98_row0_col0\" class=\"data row0 col0\" >day</td>\n",
       "      <td id=\"T_63f98_row0_col1\" class=\"data row0 col1\" >2044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_63f98_row1_col0\" class=\"data row1 col0\" >good</td>\n",
       "      <td id=\"T_63f98_row1_col1\" class=\"data row1 col1\" >1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_63f98_row2_col0\" class=\"data row2 col0\" >get</td>\n",
       "      <td id=\"T_63f98_row2_col1\" class=\"data row2 col1\" >1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_63f98_row3_col0\" class=\"data row3 col0\" >like</td>\n",
       "      <td id=\"T_63f98_row3_col1\" class=\"data row3 col1\" >1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_63f98_row4_col0\" class=\"data row4 col0\" >go</td>\n",
       "      <td id=\"T_63f98_row4_col1\" class=\"data row4 col1\" >1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_63f98_row5_col0\" class=\"data row5 col0\" >dont</td>\n",
       "      <td id=\"T_63f98_row5_col1\" class=\"data row5 col1\" >1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_63f98_row6_col0\" class=\"data row6 col0\" >love</td>\n",
       "      <td id=\"T_63f98_row6_col1\" class=\"data row6 col1\" >1122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_63f98_row7_col0\" class=\"data row7 col0\" >work</td>\n",
       "      <td id=\"T_63f98_row7_col1\" class=\"data row7 col1\" >1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_63f98_row8_col0\" class=\"data row8 col0\" >going</td>\n",
       "      <td id=\"T_63f98_row8_col1\" class=\"data row8 col1\" >1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_63f98_row9_col0\" class=\"data row9 col0\" >today</td>\n",
       "      <td id=\"T_63f98_row9_col1\" class=\"data row9 col1\" >1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_63f98_row10_col0\" class=\"data row10 col0\" >got</td>\n",
       "      <td id=\"T_63f98_row10_col1\" class=\"data row10 col1\" >1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_63f98_row11_col0\" class=\"data row11 col0\" >cant</td>\n",
       "      <td id=\"T_63f98_row11_col1\" class=\"data row11 col1\" >1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_63f98_row12_col0\" class=\"data row12 col0\" >happy</td>\n",
       "      <td id=\"T_63f98_row12_col1\" class=\"data row12 col1\" >976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_63f98_row13_col0\" class=\"data row13 col0\" >one</td>\n",
       "      <td id=\"T_63f98_row13_col1\" class=\"data row13 col1\" >971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_63f98_row14_col0\" class=\"data row14 col0\" >lol</td>\n",
       "      <td id=\"T_63f98_row14_col1\" class=\"data row14 col1\" >948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_63f98_row15_col0\" class=\"data row15 col0\" >time</td>\n",
       "      <td id=\"T_63f98_row15_col1\" class=\"data row15 col1\" >942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_63f98_row16_col0\" class=\"data row16 col0\" >know</td>\n",
       "      <td id=\"T_63f98_row16_col1\" class=\"data row16 col1\" >930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_63f98_row17_col0\" class=\"data row17 col0\" >u</td>\n",
       "      <td id=\"T_63f98_row17_col1\" class=\"data row17 col1\" >923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_63f98_row18_col0\" class=\"data row18 col0\" >really</td>\n",
       "      <td id=\"T_63f98_row18_col1\" class=\"data row18 col1\" >908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row19\" class=\"row_heading level0 row19\" >20</th>\n",
       "      <td id=\"T_63f98_row19_col0\" class=\"data row19 col0\" >back</td>\n",
       "      <td id=\"T_63f98_row19_col1\" class=\"data row19 col1\" >891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row20\" class=\"row_heading level0 row20\" >21</th>\n",
       "      <td id=\"T_63f98_row20_col0\" class=\"data row20 col0\" >see</td>\n",
       "      <td id=\"T_63f98_row20_col1\" class=\"data row20 col1\" >797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row21\" class=\"row_heading level0 row21\" >22</th>\n",
       "      <td id=\"T_63f98_row21_col0\" class=\"data row21 col0\" >well</td>\n",
       "      <td id=\"T_63f98_row21_col1\" class=\"data row21 col1\" >744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row22\" class=\"row_heading level0 row22\" >23</th>\n",
       "      <td id=\"T_63f98_row22_col0\" class=\"data row22 col0\" >new</td>\n",
       "      <td id=\"T_63f98_row22_col1\" class=\"data row22 col1\" >740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63f98_level0_row23\" class=\"row_heading level0 row23\" >24</th>\n",
       "      <td id=\"T_63f98_row23_col0\" class=\"data row23 col0\" >night</td>\n",
       "      <td id=\"T_63f98_row23_col1\" class=\"data row23 col1\" >737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbd8e1c40>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([item for sublist in train['temp_list1'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(25))\n",
    "temp = temp.iloc[1:,:]\n",
    "temp.columns = ['Common_words','count']\n",
    "temp.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first two common word was I'm so I removed it and took data from second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n",
    "#              width=700, height=700,color='Common_words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO we can see the Most common words in Selected text and Text are almost the same,which was obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most common words Sentiments Wise\n",
    "\n",
    "Let's look at the most common words in different sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_sent = train[train['sentiment']=='positive']\n",
    "Negative_sent = train[train['sentiment']=='negative']\n",
    "Neutral_sent = train[train['sentiment']=='neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7fbba_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbba_row1_col1 {\n",
       "  background-color: #026f2e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbba_row2_col1 {\n",
       "  background-color: #107a37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7fbba_row3_col1 {\n",
       "  background-color: #7cc87c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row4_col1 {\n",
       "  background-color: #86cc85;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row5_col1 {\n",
       "  background-color: #aadda4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row6_col1 {\n",
       "  background-color: #cbeac4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row7_col1 {\n",
       "  background-color: #d1edcb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row8_col1 {\n",
       "  background-color: #d4eece;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row9_col1 {\n",
       "  background-color: #d9f0d3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row10_col1 {\n",
       "  background-color: #ddf2d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row11_col1 {\n",
       "  background-color: #eaf7e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row12_col1 {\n",
       "  background-color: #ebf7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row13_col1 {\n",
       "  background-color: #edf8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row14_col1 {\n",
       "  background-color: #f0f9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row15_col1 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row16_col1 {\n",
       "  background-color: #f4fbf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row17_col1 {\n",
       "  background-color: #f5fbf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row18_col1 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7fbba_row19_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7fbba\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7fbba_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_7fbba_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7fbba_row0_col0\" class=\"data row0 col0\" >good</td>\n",
       "      <td id=\"T_7fbba_row0_col1\" class=\"data row0 col1\" >826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7fbba_row1_col0\" class=\"data row1 col0\" >happy</td>\n",
       "      <td id=\"T_7fbba_row1_col1\" class=\"data row1 col1\" >730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7fbba_row2_col0\" class=\"data row2 col0\" >love</td>\n",
       "      <td id=\"T_7fbba_row2_col1\" class=\"data row2 col1\" >697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7fbba_row3_col0\" class=\"data row3 col0\" >day</td>\n",
       "      <td id=\"T_7fbba_row3_col1\" class=\"data row3 col1\" >456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7fbba_row4_col0\" class=\"data row4 col0\" >thanks</td>\n",
       "      <td id=\"T_7fbba_row4_col1\" class=\"data row4 col1\" >439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7fbba_row5_col0\" class=\"data row5 col0\" >great</td>\n",
       "      <td id=\"T_7fbba_row5_col1\" class=\"data row5 col1\" >364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7fbba_row6_col0\" class=\"data row6 col0\" >fun</td>\n",
       "      <td id=\"T_7fbba_row6_col1\" class=\"data row6 col1\" >287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7fbba_row7_col0\" class=\"data row7 col0\" >nice</td>\n",
       "      <td id=\"T_7fbba_row7_col1\" class=\"data row7 col1\" >267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7fbba_row8_col0\" class=\"data row8 col0\" >mothers</td>\n",
       "      <td id=\"T_7fbba_row8_col1\" class=\"data row8 col1\" >259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7fbba_row9_col0\" class=\"data row9 col0\" >hope</td>\n",
       "      <td id=\"T_7fbba_row9_col1\" class=\"data row9 col1\" >245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_7fbba_row10_col0\" class=\"data row10 col0\" >awesome</td>\n",
       "      <td id=\"T_7fbba_row10_col1\" class=\"data row10 col1\" >232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_7fbba_row11_col0\" class=\"data row11 col0\" >im</td>\n",
       "      <td id=\"T_7fbba_row11_col1\" class=\"data row11 col1\" >185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_7fbba_row12_col0\" class=\"data row12 col0\" >thank</td>\n",
       "      <td id=\"T_7fbba_row12_col1\" class=\"data row12 col1\" >180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_7fbba_row13_col0\" class=\"data row13 col0\" >like</td>\n",
       "      <td id=\"T_7fbba_row13_col1\" class=\"data row13 col1\" >167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_7fbba_row14_col0\" class=\"data row14 col0\" >best</td>\n",
       "      <td id=\"T_7fbba_row14_col1\" class=\"data row14 col1\" >154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_7fbba_row15_col0\" class=\"data row15 col0\" >wish</td>\n",
       "      <td id=\"T_7fbba_row15_col1\" class=\"data row15 col1\" >152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_7fbba_row16_col0\" class=\"data row16 col0\" >amazing</td>\n",
       "      <td id=\"T_7fbba_row16_col1\" class=\"data row16 col1\" >135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_7fbba_row17_col0\" class=\"data row17 col0\" >really</td>\n",
       "      <td id=\"T_7fbba_row17_col1\" class=\"data row17 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_7fbba_row18_col0\" class=\"data row18 col0\" >better</td>\n",
       "      <td id=\"T_7fbba_row18_col1\" class=\"data row18 col1\" >125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7fbba_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_7fbba_row19_col0\" class=\"data row19 col0\" >cool</td>\n",
       "      <td id=\"T_7fbba_row19_col1\" class=\"data row19 col1\" >119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbbaf7820>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MosT common positive words\n",
    "top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\n",
    "temp_positive = pd.DataFrame(top.most_common(20))\n",
    "temp_positive.columns = ['Common_words','count']\n",
    "temp_positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n",
    "#              width=700, height=700,color='Common_words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_74d56_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row1_col1 {\n",
       "  background-color: #820711;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row2_col1 {\n",
       "  background-color: #c2161b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row3_col1 {\n",
       "  background-color: #f44f39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row4_col1 {\n",
       "  background-color: #fa6648;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row5_col1 {\n",
       "  background-color: #fb7252;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row6_col1 {\n",
       "  background-color: #fc8a6a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_74d56_row7_col1 {\n",
       "  background-color: #fcb79c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row8_col1 {\n",
       "  background-color: #fcbca2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row9_col1 {\n",
       "  background-color: #fcbfa7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row10_col1 {\n",
       "  background-color: #fcc1a8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row11_col1 {\n",
       "  background-color: #fdd0bc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row12_col1 {\n",
       "  background-color: #fed8c7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row13_col1 {\n",
       "  background-color: #fee2d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row14_col1 {\n",
       "  background-color: #feeae0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row15_col1 {\n",
       "  background-color: #ffede5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row16_col1 {\n",
       "  background-color: #ffeee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row17_col1 {\n",
       "  background-color: #fff4ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_74d56_row18_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_74d56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_74d56_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_74d56_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_74d56_row0_col0\" class=\"data row0 col0\" >miss</td>\n",
       "      <td id=\"T_74d56_row0_col1\" class=\"data row0 col1\" >358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_74d56_row1_col0\" class=\"data row1 col0\" >sad</td>\n",
       "      <td id=\"T_74d56_row1_col1\" class=\"data row1 col1\" >343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_74d56_row2_col0\" class=\"data row2 col0\" >sorry</td>\n",
       "      <td id=\"T_74d56_row2_col1\" class=\"data row2 col1\" >300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_74d56_row3_col0\" class=\"data row3 col0\" >bad</td>\n",
       "      <td id=\"T_74d56_row3_col1\" class=\"data row3 col1\" >246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_74d56_row4_col0\" class=\"data row4 col0\" >hate</td>\n",
       "      <td id=\"T_74d56_row4_col1\" class=\"data row4 col1\" >230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_74d56_row5_col0\" class=\"data row5 col0\" >dont</td>\n",
       "      <td id=\"T_74d56_row5_col1\" class=\"data row5 col1\" >221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_74d56_row6_col0\" class=\"data row6 col0\" >cant</td>\n",
       "      <td id=\"T_74d56_row6_col1\" class=\"data row6 col1\" >201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_74d56_row7_col0\" class=\"data row7 col0\" >sick</td>\n",
       "      <td id=\"T_74d56_row7_col1\" class=\"data row7 col1\" >166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_74d56_row8_col0\" class=\"data row8 col0\" >like</td>\n",
       "      <td id=\"T_74d56_row8_col1\" class=\"data row8 col1\" >162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_74d56_row9_col0\" class=\"data row9 col0\" >sucks</td>\n",
       "      <td id=\"T_74d56_row9_col1\" class=\"data row9 col1\" >159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_74d56_row10_col0\" class=\"data row10 col0\" >feel</td>\n",
       "      <td id=\"T_74d56_row10_col1\" class=\"data row10 col1\" >158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_74d56_row11_col0\" class=\"data row11 col0\" >tired</td>\n",
       "      <td id=\"T_74d56_row11_col1\" class=\"data row11 col1\" >144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_74d56_row12_col0\" class=\"data row12 col0\" >really</td>\n",
       "      <td id=\"T_74d56_row12_col1\" class=\"data row12 col1\" >137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_74d56_row13_col0\" class=\"data row13 col0\" >good</td>\n",
       "      <td id=\"T_74d56_row13_col1\" class=\"data row13 col1\" >127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_74d56_row14_col0\" class=\"data row14 col0\" >bored</td>\n",
       "      <td id=\"T_74d56_row14_col1\" class=\"data row14 col1\" >115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_74d56_row15_col0\" class=\"data row15 col0\" >day</td>\n",
       "      <td id=\"T_74d56_row15_col1\" class=\"data row15 col1\" >110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_74d56_row16_col0\" class=\"data row16 col0\" >hurts</td>\n",
       "      <td id=\"T_74d56_row16_col1\" class=\"data row16 col1\" >108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_74d56_row17_col0\" class=\"data row17 col0\" >work</td>\n",
       "      <td id=\"T_74d56_row17_col1\" class=\"data row17 col1\" >99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_74d56_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_74d56_row18_col0\" class=\"data row18 col0\" >get</td>\n",
       "      <td id=\"T_74d56_row18_col1\" class=\"data row18 col1\" >97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbd8e1c70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MosT common negative words\n",
    "top = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\n",
    "temp_negative = pd.DataFrame(top.most_common(20))\n",
    "temp_negative = temp_negative.iloc[1:,:]\n",
    "temp_negative.columns = ['Common_words','count']\n",
    "temp_negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0d3fe_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row1_col1 {\n",
       "  background-color: #ab1016;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row2_col1 {\n",
       "  background-color: #f24734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row3_col1 {\n",
       "  background-color: #f6553c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row4_col1 {\n",
       "  background-color: #f96245;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row5_col1 {\n",
       "  background-color: #fa6849;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row6_col1 {\n",
       "  background-color: #fc8060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row7_col1 {\n",
       "  background-color: #fc8565;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_0d3fe_row8_col1, #T_0d3fe_row9_col1 {\n",
       "  background-color: #fc9474;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row10_col1 {\n",
       "  background-color: #fca486;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row11_col1 {\n",
       "  background-color: #fcab8f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row12_col1 {\n",
       "  background-color: #fcb095;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row13_col1 {\n",
       "  background-color: #fcb99f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row14_col1 {\n",
       "  background-color: #fdccb8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row15_col1 {\n",
       "  background-color: #fee4d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row16_col1 {\n",
       "  background-color: #feeae0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row17_col1 {\n",
       "  background-color: #ffece4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_0d3fe_row18_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0d3fe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0d3fe_level0_col0\" class=\"col_heading level0 col0\" >Common_words</th>\n",
       "      <th id=\"T_0d3fe_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_0d3fe_row0_col0\" class=\"data row0 col0\" >get</td>\n",
       "      <td id=\"T_0d3fe_row0_col1\" class=\"data row0 col1\" >612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_0d3fe_row1_col0\" class=\"data row1 col0\" >go</td>\n",
       "      <td id=\"T_0d3fe_row1_col1\" class=\"data row1 col1\" >569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_0d3fe_row2_col0\" class=\"data row2 col0\" >day</td>\n",
       "      <td id=\"T_0d3fe_row2_col1\" class=\"data row2 col1\" >492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_0d3fe_row3_col0\" class=\"data row3 col0\" >dont</td>\n",
       "      <td id=\"T_0d3fe_row3_col1\" class=\"data row3 col1\" >482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_0d3fe_row4_col0\" class=\"data row4 col0\" >going</td>\n",
       "      <td id=\"T_0d3fe_row4_col1\" class=\"data row4 col1\" >472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_0d3fe_row5_col0\" class=\"data row5 col0\" >work</td>\n",
       "      <td id=\"T_0d3fe_row5_col1\" class=\"data row5 col1\" >467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_0d3fe_row6_col0\" class=\"data row6 col0\" >like</td>\n",
       "      <td id=\"T_0d3fe_row6_col1\" class=\"data row6 col1\" >445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_0d3fe_row7_col0\" class=\"data row7 col0\" >got</td>\n",
       "      <td id=\"T_0d3fe_row7_col1\" class=\"data row7 col1\" >441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_0d3fe_row8_col0\" class=\"data row8 col0\" >today</td>\n",
       "      <td id=\"T_0d3fe_row8_col1\" class=\"data row8 col1\" >427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_0d3fe_row9_col0\" class=\"data row9 col0\" >lol</td>\n",
       "      <td id=\"T_0d3fe_row9_col1\" class=\"data row9 col1\" >427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_0d3fe_row10_col0\" class=\"data row10 col0\" >time</td>\n",
       "      <td id=\"T_0d3fe_row10_col1\" class=\"data row10 col1\" >413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row11\" class=\"row_heading level0 row11\" >12</th>\n",
       "      <td id=\"T_0d3fe_row11_col0\" class=\"data row11 col0\" >know</td>\n",
       "      <td id=\"T_0d3fe_row11_col1\" class=\"data row11 col1\" >407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row12\" class=\"row_heading level0 row12\" >13</th>\n",
       "      <td id=\"T_0d3fe_row12_col0\" class=\"data row12 col0\" >back</td>\n",
       "      <td id=\"T_0d3fe_row12_col1\" class=\"data row12 col1\" >402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row13\" class=\"row_heading level0 row13\" >14</th>\n",
       "      <td id=\"T_0d3fe_row13_col0\" class=\"data row13 col0\" >one</td>\n",
       "      <td id=\"T_0d3fe_row13_col1\" class=\"data row13 col1\" >394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row14\" class=\"row_heading level0 row14\" >15</th>\n",
       "      <td id=\"T_0d3fe_row14_col0\" class=\"data row14 col0\" >u</td>\n",
       "      <td id=\"T_0d3fe_row14_col1\" class=\"data row14 col1\" >376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row15\" class=\"row_heading level0 row15\" >16</th>\n",
       "      <td id=\"T_0d3fe_row15_col0\" class=\"data row15 col0\" >see</td>\n",
       "      <td id=\"T_0d3fe_row15_col1\" class=\"data row15 col1\" >349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row16\" class=\"row_heading level0 row16\" >17</th>\n",
       "      <td id=\"T_0d3fe_row16_col0\" class=\"data row16 col0\" >cant</td>\n",
       "      <td id=\"T_0d3fe_row16_col1\" class=\"data row16 col1\" >339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row17\" class=\"row_heading level0 row17\" >18</th>\n",
       "      <td id=\"T_0d3fe_row17_col0\" class=\"data row17 col0\" >home</td>\n",
       "      <td id=\"T_0d3fe_row17_col1\" class=\"data row17 col1\" >335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0d3fe_level0_row18\" class=\"row_heading level0 row18\" >19</th>\n",
       "      <td id=\"T_0d3fe_row18_col0\" class=\"data row18 col0\" >want</td>\n",
       "      <td id=\"T_0d3fe_row18_col1\" class=\"data row18 col1\" >319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bc47dc2b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MosT common Neutral words\n",
    "top = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\n",
    "temp_neutral = pd.DataFrame(top.most_common(20))\n",
    "temp_neutral = temp_neutral.loc[1:,:]\n",
    "temp_neutral.columns = ['Common_words','count']\n",
    "temp_neutral.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n",
    "#              width=700, height=700,color='Common_words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see words like get,go,dont,got,u,cant,lol,like are common in all three segments . That's interesting because words like dont and cant are more of negative nature and words like lol are more of positive nature.Does this mean our data is incorrectly labelled , we will have more insights on this after N-gram analysis\n",
    "* It will be interesting to see the word unique to different sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Look at Unique Words in each Segment\n",
    "\n",
    "We will look at unique words in each segment in the Following Order:\n",
    "* Positive\n",
    "* Negative\n",
    "* Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = [word for word_list in train['temp_list1'] for word in word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def words_unique(sentiment,numwords,raw_words):\n",
    "    '''\n",
    "    Input:\n",
    "        segment - Segment category (ex. 'Neutral');\n",
    "        numwords - how many specific words do you want to see in the final result; \n",
    "        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n",
    "    Output: \n",
    "        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n",
    "\n",
    "    '''\n",
    "    allother = []\n",
    "    for item in train[train.sentiment != sentiment]['temp_list1']:\n",
    "        for word in item:\n",
    "            allother .append(word)\n",
    "    allother  = list(set(allother ))\n",
    "    \n",
    "    specificnonly = [x for x in raw_text if x not in allother]\n",
    "    \n",
    "    mycounter = Counter()\n",
    "    \n",
    "    for item in train[train.sentiment == sentiment]['temp_list1']:\n",
    "        for word in item:\n",
    "            mycounter[word] += 1\n",
    "    keep = list(specificnonly)\n",
    "    \n",
    "    for word in list(mycounter):\n",
    "        if word not in keep:\n",
    "            del mycounter[word]\n",
    "    \n",
    "    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n",
    "    \n",
    "    return Unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 20 unique words in Positive Tweets are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4f713_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4f713_row1_col1 {\n",
       "  background-color: #d1edcb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4f713_row2_col1 {\n",
       "  background-color: #e5f5e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4f713_row3_col1, #T_4f713_row4_col1, #T_4f713_row5_col1 {\n",
       "  background-color: #ebf7e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4f713_row6_col1, #T_4f713_row7_col1, #T_4f713_row8_col1, #T_4f713_row9_col1, #T_4f713_row10_col1, #T_4f713_row11_col1 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4f713_row12_col1, #T_4f713_row13_col1, #T_4f713_row14_col1, #T_4f713_row15_col1, #T_4f713_row16_col1, #T_4f713_row17_col1, #T_4f713_row18_col1, #T_4f713_row19_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4f713\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4f713_level0_col0\" class=\"col_heading level0 col0\" >words</th>\n",
       "      <th id=\"T_4f713_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4f713_row0_col0\" class=\"data row0 col0\" >congratulations</td>\n",
       "      <td id=\"T_4f713_row0_col1\" class=\"data row0 col1\" >29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4f713_row1_col0\" class=\"data row1 col0\" >thnx</td>\n",
       "      <td id=\"T_4f713_row1_col1\" class=\"data row1 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4f713_row2_col0\" class=\"data row2 col0\" >appreciated</td>\n",
       "      <td id=\"T_4f713_row2_col1\" class=\"data row2 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4f713_row3_col0\" class=\"data row3 col0\" >shared</td>\n",
       "      <td id=\"T_4f713_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4f713_row4_col0\" class=\"data row4 col0\" >presents</td>\n",
       "      <td id=\"T_4f713_row4_col1\" class=\"data row4 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4f713_row5_col0\" class=\"data row5 col0\" >greetings</td>\n",
       "      <td id=\"T_4f713_row5_col1\" class=\"data row5 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4f713_row6_col0\" class=\"data row6 col0\" >blessings</td>\n",
       "      <td id=\"T_4f713_row6_col1\" class=\"data row6 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4f713_row7_col0\" class=\"data row7 col0\" >mothersday</td>\n",
       "      <td id=\"T_4f713_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4f713_row8_col0\" class=\"data row8 col0\" >mcr</td>\n",
       "      <td id=\"T_4f713_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4f713_row9_col0\" class=\"data row9 col0\" >coolest</td>\n",
       "      <td id=\"T_4f713_row9_col1\" class=\"data row9 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4f713_row10_col0\" class=\"data row10 col0\" >honored</td>\n",
       "      <td id=\"T_4f713_row10_col1\" class=\"data row10 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_4f713_row11_col0\" class=\"data row11 col0\" >goood</td>\n",
       "      <td id=\"T_4f713_row11_col1\" class=\"data row11 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_4f713_row12_col0\" class=\"data row12 col0\" >wango</td>\n",
       "      <td id=\"T_4f713_row12_col1\" class=\"data row12 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_4f713_row13_col0\" class=\"data row13 col0\" >actress</td>\n",
       "      <td id=\"T_4f713_row13_col1\" class=\"data row13 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_4f713_row14_col0\" class=\"data row14 col0\" >mint</td>\n",
       "      <td id=\"T_4f713_row14_col1\" class=\"data row14 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_4f713_row15_col0\" class=\"data row15 col0\" >dayyyy</td>\n",
       "      <td id=\"T_4f713_row15_col1\" class=\"data row15 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_4f713_row16_col0\" class=\"data row16 col0\" >ciara</td>\n",
       "      <td id=\"T_4f713_row16_col1\" class=\"data row16 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_4f713_row17_col0\" class=\"data row17 col0\" >twin</td>\n",
       "      <td id=\"T_4f713_row17_col1\" class=\"data row17 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_4f713_row18_col0\" class=\"data row18 col0\" >kudos</td>\n",
       "      <td id=\"T_4f713_row18_col1\" class=\"data row18 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4f713_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_4f713_row19_col0\" class=\"data row19 col0\" >hurray</td>\n",
       "      <td id=\"T_4f713_row19_col1\" class=\"data row19 col1\" >5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbd93ba30>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unique_Positive= words_unique('positive', 20, raw_text)\n",
    "print(\"The top 20 unique words in Positive Tweets are:\")\n",
    "Unique_Positive.style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "# plt.figure(figsize=(16,10))\n",
    "# my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "# plt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('DoNut Plot Of Unique Positive Words')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 unique words in Negative Tweets are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cb10a_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cb10a_row1_col1 {\n",
       "  background-color: #fb694a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cb10a_row2_col1, #T_cb10a_row3_col1, #T_cb10a_row4_col1, #T_cb10a_row5_col1 {\n",
       "  background-color: #fdd4c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cb10a_row6_col1, #T_cb10a_row7_col1, #T_cb10a_row8_col1, #T_cb10a_row9_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cb10a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cb10a_level0_col0\" class=\"col_heading level0 col0\" >words</th>\n",
       "      <th id=\"T_cb10a_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cb10a_row0_col0\" class=\"data row0 col0\" >ache</td>\n",
       "      <td id=\"T_cb10a_row0_col1\" class=\"data row0 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cb10a_row1_col0\" class=\"data row1 col0\" >suffering</td>\n",
       "      <td id=\"T_cb10a_row1_col1\" class=\"data row1 col1\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cb10a_row2_col0\" class=\"data row2 col0\" >allergic</td>\n",
       "      <td id=\"T_cb10a_row2_col1\" class=\"data row2 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cb10a_row3_col0\" class=\"data row3 col0\" >cramps</td>\n",
       "      <td id=\"T_cb10a_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cb10a_row4_col0\" class=\"data row4 col0\" >saddest</td>\n",
       "      <td id=\"T_cb10a_row4_col1\" class=\"data row4 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cb10a_row5_col0\" class=\"data row5 col0\" >pissing</td>\n",
       "      <td id=\"T_cb10a_row5_col1\" class=\"data row5 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cb10a_row6_col0\" class=\"data row6 col0\" >sob</td>\n",
       "      <td id=\"T_cb10a_row6_col1\" class=\"data row6 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cb10a_row7_col0\" class=\"data row7 col0\" >dealing</td>\n",
       "      <td id=\"T_cb10a_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cb10a_row8_col0\" class=\"data row8 col0\" >devastated</td>\n",
       "      <td id=\"T_cb10a_row8_col1\" class=\"data row8 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cb10a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cb10a_row9_col0\" class=\"data row9 col0\" >noes</td>\n",
       "      <td id=\"T_cb10a_row9_col1\" class=\"data row9 col1\" >6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbd94caf0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unique_Negative= words_unique('negative', 10, raw_text)\n",
    "print(\"The top 10 unique words in Negative Tweets are:\")\n",
    "Unique_Negative.style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "# plt.figure(figsize=(16,10))\n",
    "# my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "# plt.rcParams['text.color'] = 'black'\n",
    "# plt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('DoNut Plot Of Unique Negative Words')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 unique words in Neutral Tweets are:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72286_row0_col1 {\n",
       "  background-color: #7f2704;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_72286_row1_col1 {\n",
       "  background-color: #fd8c3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_72286_row2_col1, #T_72286_row3_col1 {\n",
       "  background-color: #fdd0a2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_72286_row4_col1, #T_72286_row5_col1, #T_72286_row6_col1, #T_72286_row7_col1, #T_72286_row8_col1, #T_72286_row9_col1 {\n",
       "  background-color: #fff5eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72286\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_72286_level0_col0\" class=\"col_heading level0 col0\" >words</th>\n",
       "      <th id=\"T_72286_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_72286_row0_col0\" class=\"data row0 col0\" >settings</td>\n",
       "      <td id=\"T_72286_row0_col1\" class=\"data row0 col1\" >9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_72286_row1_col0\" class=\"data row1 col0\" >explain</td>\n",
       "      <td id=\"T_72286_row1_col1\" class=\"data row1 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_72286_row2_col0\" class=\"data row2 col0\" >mite</td>\n",
       "      <td id=\"T_72286_row2_col1\" class=\"data row2 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_72286_row3_col0\" class=\"data row3 col0\" >hiya</td>\n",
       "      <td id=\"T_72286_row3_col1\" class=\"data row3 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_72286_row4_col0\" class=\"data row4 col0\" >reader</td>\n",
       "      <td id=\"T_72286_row4_col1\" class=\"data row4 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_72286_row5_col0\" class=\"data row5 col0\" >pr</td>\n",
       "      <td id=\"T_72286_row5_col1\" class=\"data row5 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_72286_row6_col0\" class=\"data row6 col0\" >sorta</td>\n",
       "      <td id=\"T_72286_row6_col1\" class=\"data row6 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_72286_row7_col0\" class=\"data row7 col0\" >fathers</td>\n",
       "      <td id=\"T_72286_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_72286_row8_col0\" class=\"data row8 col0\" >enterprise</td>\n",
       "      <td id=\"T_72286_row8_col1\" class=\"data row8 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_72286_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_72286_row9_col0\" class=\"data row9 col0\" >guessed</td>\n",
       "      <td id=\"T_72286_row9_col1\" class=\"data row9 col1\" >5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5bbdf138e0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unique_Neutral= words_unique('neutral', 10, raw_text)\n",
    "print(\"The top 10 unique words in Neutral Tweets are:\")\n",
    "Unique_Neutral.style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# from palettable.colorbrewer.qualitative import Pastel1_7\n",
    "# plt.figure(figsize=(16,10))\n",
    "# my_circle=plt.Circle((0,0), 0.7, color='white')\n",
    "# plt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\n",
    "# p=plt.gcf()\n",
    "# p.gca().add_artist(my_circle)\n",
    "# plt.title('DoNut Plot Of Unique Neutral Words')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By Looking at the Unique Words of each sentiment,we now have much more clarity about the data,these unique words are very strong determiners of Sentiment of tweets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's Time For WordClouds\n",
    "\n",
    "We will be building wordclouds in the following order:\n",
    "\n",
    "* WordCloud of Neutral Tweets\n",
    "* WordCloud of Positive Tweets\n",
    "* WordCloud of Negative Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n",
    "#                    title = None, title_size=40, image_color=False):\n",
    "#     stopwords = set(STOPWORDS)\n",
    "#     more_stopwords = {'u', \"im\"}\n",
    "#     stopwords = stopwords.union(more_stopwords)\n",
    "\n",
    "#     wordcloud = WordCloud(background_color=color,\n",
    "#                     stopwords = stopwords,\n",
    "#                     max_words = max_words,\n",
    "#                     max_font_size = max_font_size, \n",
    "#                     random_state = 42,\n",
    "#                     width=400, \n",
    "#                     height=200,\n",
    "#                     mask = mask)\n",
    "#     wordcloud.generate(str(text))\n",
    "    \n",
    "#     plt.figure(figsize=figure_size)\n",
    "#     if image_color:\n",
    "#         image_colors = ImageColorGenerator(mask);\n",
    "#         plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
    "#         plt.title(title, fontdict={'size': title_size,  \n",
    "#                                   'verticalalignment': 'bottom'})\n",
    "#     else:\n",
    "#         plt.imshow(wordcloud);\n",
    "#         plt.title(title, fontdict={'size': title_size, 'color': 'black', \n",
    "#                                   'verticalalignment': 'bottom'})\n",
    "#     plt.axis('off');\n",
    "#     plt.tight_layout()  \n",
    "# d = '/kaggle/input/masks-for-wordclouds/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added more words like im , u (that we say were there in the most common words,disturbing our analysis) as stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WORDCLOUD OF NEUTRAL TWEETS\n",
    "\n",
    "We Have already visualized our Most Common Negative words ,but Wordclouds Provide us much more clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\n",
    "# plot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "This is the first kaggle competition , I am participating in and this might be the case with lot of us.Due to the unique structure of the problem statement, it is hard for any first timer or a competitions noob to answer the question\"Which Model to Use\"?.My initial thoughts was this competition is not for me and I am done here,but then I remembered something, I was at the KaggleDays Meetup Delhi this year and I had this wonderful oppurtunity to meet Grandmaster Abhishek Thakur and during the Q&A session I asked him that kaggle competitions are so diverse ,unique ,require a lot of background knowledge and thus is scary to participate, to which he replied and I quote \"Scary Yes!But so is walking into a dark room,you will never learn if you won't participate\".\n",
    "\n",
    "So here I am fighting my way through this competition and trying to learn different things and I urge everyone to do the same , I might not be so well established to give advices but I really wanted to share that story to motivate people.\n",
    "\n",
    "After going through the discussion forums,taking advices from experts and watching Abhishek Sir's tutorial last night ,this problem can be modelled as following:-\n",
    "* Named Entity Recognition\n",
    "* Q&A Problem\n",
    "* I also found a simple approach shared by Nick in his beautiful kernel where he has the concept of Gini Impurity to give weights to words present in tweets and then predicting using the weight of those words : https://www.kaggle.com/nkoprowicz/a-simple-solution-using-only-word-counts/notebook .Do check it out.\n",
    "* Other Modelling Ideas :- https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139803 --> Here is a very Nice Idea\n",
    "* Another useful Idea :- https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139335\n",
    "\n",
    "Resources :\n",
    "* For Modelling Problem as NER : https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb\n",
    "* For Modelling Problem AS Q&A : https://www.kaggle.com/jonathanbesomi/question-answering-starter-pack ---> This is a complete Guide and From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1)Modelling the Problem as NER\n",
    "\n",
    "Named Entity Recognition (NER) is a standard NLP problem which involves spotting named entities (people, places, organizations etc.) from a chunk of text, and classifying them into a predefined set of categories.\n",
    "For understanding NER here is very good article : https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n",
    "\n",
    "We will be using spacy for creating our own customised NER model or models (seperate for each Sentiment).The motivation for this approach is off course the kernel shared by Rohit Singh,so if you find his kernel useful please upvote it.\n",
    "\n",
    "What will be different with my solution:\n",
    "* I will use text as selected_text for all neutral tweets due to their high jaccard similarity\n",
    "* Also I will use text as selected_text for all tweets having number of words less than 3 in text as explained before\n",
    "* I will train two different models for Positive and Negtive tweets\n",
    "* I will not preprocess the data because the selected text contains raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "df_submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['Num_words_text']>=3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Full Understanding of the how to train spacy NER with custom inputs, please read the spacy documentation along with the code presentation in this notebook : https://spacy.io/usage/training#ner Follow along from Updating Spacy NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_model(output_dir, nlp, new_model_name):\n",
    "#     ''' This Function Saves model to \n",
    "#     given output directory'''\n",
    "    \n",
    "#     output_dir = f'../working/{output_dir}'\n",
    "#     if output_dir is not None:        \n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.makedirs(output_dir)\n",
    "#         nlp.meta[\"name\"] = new_model_name\n",
    "#         nlp.to_disk(output_dir)\n",
    "#         print(\"Saved model to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# # pass model = nlp if you want to train on top of existing model \n",
    "\n",
    "# def train(train_data, output_dir, n_iter=20, model=None):\n",
    "#     \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "#     \"\"\n",
    "#     if model is not None:\n",
    "#         nlp = spacy.load(output_dir)  # load existing spaCy model\n",
    "#         print(\"Loaded model '%s'\" % model)\n",
    "#     else:\n",
    "#         nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "#         print(\"Created blank 'en' model\")\n",
    "    \n",
    "#     # create the built-in pipeline components and add them to the pipeline\n",
    "#     # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "#     if \"ner\" not in nlp.pipe_names:\n",
    "#         ner = nlp.create_pipe(\"ner\")\n",
    "#         nlp.add_pipe(ner, last=True)\n",
    "#     # otherwise, get it so we can add labels\n",
    "#     else:\n",
    "#         ner = nlp.get_pipe(\"ner\")\n",
    "    \n",
    "#     # add labels\n",
    "#     for _, annotations in train_data:\n",
    "#         for ent in annotations.get(\"entities\"):\n",
    "#             ner.add_label(ent[2])\n",
    "\n",
    "#     # get names of other pipes to disable them during training\n",
    "#     other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "#     with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "#         # sizes = compounding(1.0, 4.0, 1.001)\n",
    "#         # batch up the examples using spaCy's minibatch\n",
    "#         if model is None:\n",
    "#             nlp.begin_training()\n",
    "#         else:\n",
    "#             nlp.resume_training()\n",
    "\n",
    "\n",
    "#         for itn in tqdm(range(n_iter)):\n",
    "#             random.shuffle(train_data)\n",
    "#             batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n",
    "#             losses = {}\n",
    "#             for batch in batches:\n",
    "#                 texts, annotations = zip(*batch)\n",
    "#                 nlp.update(texts,  # batch of texts\n",
    "#                             annotations,  # batch of annotations\n",
    "#                             drop=0.5,   # dropout - make it harder to memorise data\n",
    "#                             losses=losses, \n",
    "#                             )\n",
    "#             print(\"Losses\", losses)\n",
    "#     save_model(output_dir, nlp, 'st_ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_model_out_path(sentiment):\n",
    "#     '''\n",
    "#     Returns Model output path\n",
    "#     '''\n",
    "#     model_out_path = None\n",
    "#     if sentiment == 'positive':\n",
    "#         model_out_path = 'models/model_pos'\n",
    "#     elif sentiment == 'negative':\n",
    "#         model_out_path = 'models/model_neg'\n",
    "#     return model_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(sentiment):\n",
    "    '''\n",
    "    Returns Trainong data in the format needed to train spacy NER\n",
    "    '''\n",
    "    train_data = []\n",
    "    for index, row in df_train.iterrows():\n",
    "        if row.sentiment == sentiment:\n",
    "            selected_text = row.selected_text\n",
    "            text = row.text\n",
    "            start = text.find(selected_text)\n",
    "            end = start + len(selected_text)\n",
    "            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models for Positive and Negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "sentiment = 'positive'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "# model_path = get_model_out_path(sentiment)\n",
    "# For DEmo Purposes I have taken 3 iterations you can train the model as you want\n",
    "# train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "sentiment = 'negative'\n",
    "\n",
    "train_data = get_training_data(sentiment)\n",
    "# model_path = get_model_out_path(sentiment)\n",
    "\n",
    "# train(train_data, model_path, n_iter=3, model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with the trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_entities(text, model):\n",
    "#     doc = model(text)\n",
    "#     ent_array = []\n",
    "#     for ent in doc.ents:\n",
    "#         start = text.find(ent.text)\n",
    "#         end = start + len(ent.text)\n",
    "#         new_int = [start, end, ent.label_]\n",
    "#         if new_int not in ent_array:\n",
    "#             ent_array.append([start, end, ent.label_])\n",
    "#     selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n",
    "#     return selected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_texts = []\n",
    "# MODELS_BASE_PATH = '../input/tse-spacy-model/models/'\n",
    "\n",
    "# if MODELS_BASE_PATH is not None:\n",
    "#     print(\"Loading Models  from \", MODELS_BASE_PATH)\n",
    "#     model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n",
    "#     model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n",
    "        \n",
    "#     for index, row in df_test.iterrows():\n",
    "#         text = row.text\n",
    "#         output_str = \"\"\n",
    "#         if row.sentiment == 'neutral' or len(text.split()) <= 2:\n",
    "#             selected_texts.append(text)\n",
    "#         elif row.sentiment == 'positive':\n",
    "#             selected_texts.append(predict_entities(text, model_pos))\n",
    "#         else:\n",
    "#             selected_texts.append(predict_entities(text, model_neg))\n",
    "        \n",
    "# df_test['selected_text'] = selected_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_submission['selected_text'] = df_test['selected_text']\n",
    "# df_submission.to_csv(\"submission.csv\", index=False)\n",
    "# display(df_submission.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Notes\n",
    "Kaggle always provide a lot of days for a competition which one can utilize to learn and grow.As Promised I have presented my first model,along with explanation,you can read spacy's documentation and Rohit singh's kernel as all the code comes from their.If you understand any part of code feel free to comment and ask,I will try to resolve it.\n",
    "As This is my first competition I am also learning along the way ,I will be back with more original ideas and some great more models as I learn more and more about question/answering , different other texhniques , various forms of BERT and Data itself\n",
    "\n",
    "** Thanks for the enormous love and appreciation , I'm Sorry that I have not updated the kernel with Q and A approach,I'm Still learning all the techniques required , will update soon!**\n",
    "<br><br>STAY TUNED!\n",
    "\n",
    "<span style=\"color:Red\"> I hope you Liked my kernel. An upvote is a gesture of appreciation and encouragement that fills me with energy to keep improving my efforts ,be kind to show one ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
